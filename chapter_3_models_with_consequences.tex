
%!TEX root = main.tex

\chapter{Models with consequences}\label{ch:2p_statmodels}

In chapter \ref{ch:tech_prereq} we introduced a collection of tools for constructing probabilistic models. Tools by themselves aren't enough to construct models: we also need a purpose. \emph{Why are we constructing probabilistic models}? Our provisional answer to this question is: we construct probabilistic models to help us compare different choices we could make on the basis of the outcomes we anticipate that they will bring about. We aren't claiming that this is the only reason to create a probabilistic model, but comparing different choices is an important job that lots of people regularly need to undertake, and it is a job for which causal models are often employed.

If we are going to buld models that facilitate the comparison of different choices on the basis of their consequences, then they must have a few properties:

\begin{itemize}
    \item We want a set of choices $C$ with at least a partial order on it, because this is how we mathematically represent ``comparison''
    \item By supposition, we don't have a partial order on $C$ at the outset, otherwise our problem is already solved
    \item However, we do have a partial order on \emph{consequences}, which are elements of some set $F$
    \item In order to use the partial order on $F$ to induce a partial order on $C$, we need to associate one or more elements of $F$ with each element of $C$
\end{itemize}

At a very general level, a model that helps us to compare choices is a set-valued function $C\to \mathscr{P}(F)$. In order to say more about ``models for mathematically-assisted decisions'', we need to make some more specific assumptions about how these models are constructed - for example, we might take the set of consequences $F$ to be a set of probability distributions on a common sample space. However, even before we do this, the requirement for a domain of choices $C$ arises purely because we want to compare things mathematically.

In practice, we will take the consequences $F$ to be a set of probability distributions on a common sample space. There is a large literature on whether this is always an appropriate way to represent consequences, and we will address a small slice of it in Section \ref{sec:how_represent_conseqeunces}, but arguing that this is always a reasonable choice is not our objective here. Rather, we observe that there is a long history of using probability theory for the purpose of representing uncertain knowledge, and probability theory in conjunction with the principle of expected utility is often used to compare the desirability of uncertain outcomes.

While it doesn't often enter into the reasoning we present in the upcoming chapters, we spend some time here considering how probabilistic models are related to the ``real world phenomena'' that they are supposed to be models of. In particular, \emph{variables} are ``points of attachment'' between the model and the real world -- they point to the parts of the real world that correspond to features of the model. There are many standard accounts of how variables accomplish this in regular statistical models, but we need to elaborate on this account slightly to account for the inclusion of a domain $C$ of choices that are each associated with their own consequences. In Section \ref{sec:variable}, we present both the standard account of variables and how we propose to elaborate this account to include a domain of choices.

\subsection{TL;DR}

We model the consequences of a set of choices $C$, and we do this with a map $\prob{P}_\cdot:C\kto \Omega$ for some sample space $\Omega$. The range of this map $\prob{P}_C:=\{\prob{P}_\alpha|\alpha\in C\}$ is a probability set.

In Chapter \ref{ch:evaluating_decisions}, we consider maps from the choice set $C$ to unique probability measures. A straightforward generalisation of this scheme is to map elements of $C$ to \emph{probability sets} rather than unique probability measures. We can still construct a probability set from the range of $\prob{P}_\cdot$, in this case it is the union $\prob{P}_C=\cup_{\alpha\in C} \prob{P}_\alpha$. In Chapter \ref{ch:sdt}, we consider this generalisation.


\section{Variables}\label{sec:variable}

In probability theory, it is standard to assume the existence of a probability space $(\mu,\Omega,\sigalg{F})$ and to define \emph{random variables} as measurable functions from $(\Omega,\sigalg{F})$ to $(\mathbb{R},\mathcal{B}(\mathbb{R}))$. However, variables aren't \emph{just} functions -- they're also typically understood to correspond to some measured aspect of the real world. For example, \citet{pearl_causality:_2009} offers the following two, purportedly equivalent, definitions of variables:
\begin{quote}
By a \emph{variable} we will mean an attribute, measurement or inquiry that may take on one of several possible outcomes, or values, from a specified domain. If we have beliefs (i.e., probabilities) attached to the possible values that a variable may attain, we will call that variable a random variable.
\end{quote}

\begin{quote}
This is a minor generalization of the textbook definition, according to which a random variable is a mapping from the sample space (e.g., the set of elementary events) to the real line. In our definition, the mapping is from the sample space to any set of objects called ``values,'' which may or may not be ordered.
\end{quote}

However, these quotes are describing different things -- in fact, they're not even describing the same \emph{kind} of thing. The first is talking about a \emph{measurement}, which is something we can do in the real world that produces as a result an element of a mathematical set. The second is talking about a \emph{function}, which is a purely mathematical object with a domain and a codomain and a mapping from the former into the latter.

The way we address this distinction is: a procedure that takes place in the real world and yields as results elements of a mathematical set is called a \emph{measurement procedure}. We suppose for a given problem that there is a ``complete measurement procedure'' $\proc{S}$, and the result of every specific measurement procedure of interest can be reconstructed from the result of the complete measurement procedure by applying a function to the latter result. The function $\RV{X}$ that yields the result of a specific measurement procedure $\proc{X}$ given the result of the complete measurement procedure $\proc{S}$ is the \emph{variable} associated with the measurement procedure $\proc{X}$.

In this way, the variable $\RV{X}$ -- which is by itself just a mathematical function -- is made relevant to the real-world by combining it with a total measurement procedure $\proc{S}$.

We can even use this scheme to address situations where it is possible to make different choices. We can simply posit a sub-procedure $\proc{C}$ that yields the choice $\alpha$ that we eventually make. However, modelling this can be tricky. If we want to use the consequence model to help make the decision, then it seems that the model of the decision procedure $\proc{C}$ will need to be self-referential. Furthermore, even if we have a model of $\proc{C}$ that says we will certainly decide on a particular element $\alpha^*$, we still need to map every element of $C$ to a consequence because this is what enables the comparison of elements of C. Thus, modelling $\proc{C}$ makes the model more complicated, and it's not obvious that this is answering the question that we are interested in. This complication is not obviously intractable, but we do not address it here. Instead, we simply assume that we have a collection $\proc{S}_\alpha$ of total measurement procedures that all yield elements of the same set, and each of which are executed if the choice made is $\alpha$.

\subsection{Variables and measurement procedures}

We illustrate this approach with the example of Newton's second law in the form $\RV{F}=\RV{MA}$. This model relates ``variables'' $\RV{F}$, $\RV{M}$ and $\RV{A}$. As \citet{feynman_feynman_1979} noted, in order to understand this law, we must bring some pre-existing understanding of force, mass and acceleration independent of the law itself. Furthermore, we contend, this knowledge cannot be expressed in any purely mathematical statement. In order to say what the net force on a given object is, even a highly knowledgeable physicist will have to go and do some measurements, which is a procedure that they carry out involving interacting with the real world somehow and obtaining as a result a vector representing the net forces on that object.

That is, the variables $\RV{F}$, $\RV{M}$ and $\RV{A}$ are referring to the \emph{results of measurement procedures}. We will introduce a separate notation to refer to these measurement procedures -- $\proc{F}$ is the procedure for measuring force, $\proc{M}$ and $\proc{A}$ for mass and acceleration respectively. A measurement procedure $\proc{F}$ is akin to \citet{menger_random_2003}'s notion of variables as ``consistent classes of quantities'' that consist of pairing between real-world objects and quantities of some type. Force $\proc{F}$ itself is not a well-defined mathematical thing, as measurement procedures are not mathematically well-defined. At the same time, the set of values it may yield \emph{are} well-defined mathematical things. No actual procedure can be guaranteed to return elements of a mathematical set known in advance -- anything can fail -- but we assume that we can study procedures reliable enough that we don't lose much by making this assumption.

Note that, because $\proc{F}$ is not a purely mathematical thing, we cannot perform mathematical reasoning with $\proc{F}$ directly. Rather, we introduce a variable $\RV{F}$ which, as we will see, is a well-defined mathematical object, assert that it corresponds to $\proc{F}$ and conduct our reasoning using $\RV{F}$.

\subsection{Measurement procedures}\label{sec:mprocs}

\begin{definition}[Measurement procedure]
A \emph{measurement procedure} $\proc{B}$ is a procedure that involves interacting with the real world somehow and delivering an element of a mathematical set $X$ as a result. A procedure $\proc{B}$ is said to takes values in a set $B$.
\end{definition}

We adopt the convention that the procedure name $\proc{B}$ and the set of values $B$ share the same letter.

\begin{definition}[Values yielded by procedures]
$\proc{B}\yields x$ is the proposition that the the procedure $\proc{B}$ will yield the value $x\in X$. $\proc{B}\yields A$ for $A\subset X$ is the proposition $\lor_{x\in A} \proc{B}\yields x$.
\end{definition}

\begin{definition}[Equivalence of procedures]\label{def:equality}
Two procedures $\proc{B}$ and $\proc{C}$ are equal if they both take values in $X$ and $\proc{B}\yields x\iff \proc{C}\yields x$ for all $x\in X$.
\end{definition}

If two involve different measurement actions in the real world but necessarily yield the same result, we say they are equivalent.

It is worth noting that this notion of equivalence identifies procedures with different real-world actions. For example, ``measure the force'' and ``measure everything, then discard everything but the force'' are often different -- in particular, it might be possible to measure the force only before one has measured everything else. Thus the result yielded by the first procedure could be available before the result of the second. However, if the first is carried out in the course of carrying out the second, they both yield the same result in the end and so we treat them as equivalent. 

Measurement procedures are like functions without well-defined domains. Just like we can compose functions with other functions to create new functions, we can compose measurement procedures with functions to produce new measurement procedures.

\begin{definition}[Composition of functions with procedures]
Given a procedure $\proc{B}$ that takes values in some set $B$, and a function $f:B\to C$, define the ``composition'' $f\circ \proc{B}$ to be any procedure $\proc{C}$ that yields $f(x)$ whenever $\proc{B}$ yields $x$. We can construct such a procedure by describing the steps: first, do $\proc{B}$ and secondly, apply $f$ to the value yielded by $\proc{B}$.
\end{definition}

For example, $\proc{MA}$ is the composition of $h:(x,y)\mapsto xy$ with the procedure $(\proc{M},\proc{A})$ that yields the mass and acceleration of the same object. Measurement procedure composition is associative:

\begin{align}
    (g\circ f)\circ\proc{B}\text{ yields } x &\iff B\text{ yields } (g\circ f)^{-1}(x) \\
    &\iff B\text{ yields } f^{-1}(g^{-1}(x))\\
    &\iff f\circ B \text{ yields } g^{-1}(x)\\
    &\iff g\circ(f\circ B)\text{ yields } x
\end{align}


One might wonder whether there is also some kind of ``tensor product'' operation that takes a standalone $\proc{M}$ and a standalone $\proc{A}$ and returns a procedure $(\proc{M},\proc{A})$. Unlike function composition, this would be an operation that acts on two procedures rather than a procedure and a function. Thus this ``append'' combines real-world operations somehow, which might introduce additional requirements (we can't just measure mass and acceleration; we need to measure the mass and acceleration of the same object at the same time), and may be under-specified. For example, measuring a subatomic particle's position and momentum can be done separately, but if we wish to combine the two procedures then we can get different results depending on the order in which we combine them.

Our approach here is to suppose that there is some complete measurement procedure $\proc{S}$ to be modeled, which takes values in the observable sample space $(\Psi,\sigalg{E})$ and for all measurement procedures of interest there is some $f$ such that the procedure is equivalent to $f\circ \proc{S}$ for some $f$. In this manner, we assume that any problems that arise from a need to combine real world actions have already been solved in the course of defining $\proc{S}$.

Given that measurement processes are in practice finite precision and with finite range, $\Psi$ will generally be a finite set. We can therefore equip $\Psi$ with the collection of measurable sets given by the power set $\sigalg{E}:=\mathscr{P}(\Psi)$, and $(\Psi,\sigalg{E})$ is a standard measurable space. $\sigalg{E}$ stands for a complete collection of logical propositions we can generate that depend on the results yielded by the measurement procedure $\proc{S}$.

One could also consider measurement procedures to produce results in $(\mathbb{R},\mathcal{B}(\mathbb{R}))$ (i.e. the reals with the Borel sigma-algebra) or a set isomorphic to it. This choice is often made in practice, and following standard practice we also often consider variables to take values in sets isomorphic to $(\mathbb{R},\mathcal{B}(\mathbb{R}))$. However, for measurement in particular this seems to be a choice of convenience rather than necessity -- for any measurement with finite precision and range, it is possible to specify a finite set of possible results.

\subsection{Observable variables}

Our \emph{complete} procedure $\proc{S}$ represents a large collection of subprocedures of interest, each of which can be obtained by composition of some function with $\proc{S}$. We call the pair consisting of a subprocedure of interest $\proc{X}$ along with the variable $\RV{X}$ used to obtain it from $\proc{S}$ an \emph{observable variable}.

\begin{definition}[Observable variable]
Given a measurement procedure $\proc{S}$ taking values in $(\Psi,\sigalg{E})$, an observable variable is a pair $(\RV{X}\circ \proc{S},\RV{X})$ where $\RV{X}:(\Psi,\sigalg{E})\to (X,\sigalg{X})$ is a measurable function and $\proc{X}:=\RV{X}\circ \proc{S}$ is the measurement procedure induced by $\RV{X}$ and $\proc{S}$.
\end{definition}

For the model $\RV{F}=\RV{MA}$, for example, suppose we have a complete measurement procedure $\proc{S}$ that yields a triple (force, mass, acceleration) taking values in the sets $X$, $Y$, $Z$ respectively. Then we can define the ``force'' variable $(\proc{F},\RV{F})$ where $\proc{F}:=\RV{F}\circ \proc{S}$ and $\RV{F}:X\times Y\times Z\to X$ is the projection function onto $X$.

A measurement procedure yields a particular value when it is completed. We will call a proposition of the form ``$\proc{X}$ yields $x$'' an \emph{observation}. Note that $\proc{X}$ need not be a complete procedure here. Given the complete procedure $\proc{S}$, a variable $\RV{X}:\Psi\to X$ and the corresponding procedure $\proc{X}=\RV{X}\circ\proc{S}$, the proposition ``$\proc{X}$ yields $x$'' is equivalent to the proposition ``$\proc{S}$ yields a value in $\RV{X}^{-1}(x)$''. Because of this, we define the \emph{event} $\RV{X}\yields x$ to be the set $\RV{X}^{-1}(x)$.

\begin{definition}[Event]
Given the complete procedure $\proc{S}$ taking values in $\Psi$ and an observable variable $(\RV{X}\circ \proc{S},\RV{X})$ for $\RV{X}:\Psi\to X$, the \emph{event} $\RV{X}\yields x$ is the set $\RV{X}^{-1}(x)$ for any $x\in X$.
\end{definition}

If we are given an observation ``$\proc{X}$ yields $x$'', then the corresponding event $\RV{X}\yields x$ is \emph{compatible with this observation}.

It is common to use the symbol $=$ instead of $\bowtie$ to stand for ``yields'', but we want to avoid this because $\RV{Y}=y$ already has a meaning, namely that $\RV{Y}$ is a constant function everywhere equal to $y$.

An \emph{impossible event} is the empty set. If $\RV{X}\yields x=\emptyset$ this means that we have identified no possible outcomes of the measurement process $\proc{S}$ compatible with the observation ``$\proc{X}$ yields $x$''. 

\subsection{Model variables}

Observable variables are special in the sense that they are tied to a particular measurement procedure $\proc{S}$. However, the measurement procedure $\proc{S}$ does not enter into our mathematical reasoning; it guides our construction of a mathematical model, but once this is done mathematical reasoning proceeds entirely with mathematical objects like sets and functions, with no further reference to the measurement procedure.

A \emph{model variable} is simply a measurable function with domain $(\Psi,\sigalg{E})$.

Model variables do not have to be derived from observable variables. We may instead choose a sample space for our model $(\Omega,\sigalg{F})$ that does not correspond to the possible values that $\proc{S}$ might yield. In that case, we require a surjective model variable $\RV{S}:\Omega\to \Psi$ called the complete observable variable, and every observable variable $(\RV{X}'\circ \proc{S},\RV{X}')$ is associated with the model variable $\RV{X}:=\RV{X}'\circ \RV{S}$.

An \emph{unobserved variable} is a variable whose set of possible values is not constrained by the results of the measurement procedure.

\begin{definition}[Unobserved variable]\label{def:unobserved_variable}
Given a sample space $(\Omega,\sigalg{F})$ and a complete observable variable $\RV{S}:\Omega\to\Psi$, a model variable $\RV{Y}:\Omega\to Y$ is \emph{unobserved} if $\RV{Y}(\RV{S}\yields s)=Y$ for all $s\in \Psi$.
\end{definition}

\subsection{Variable sequences and partial order}

Given $\RV{Y}:\Omega\to X$, we can define a sequence of variables: $(\RV{X},\RV{Y}):=\omega\mapsto (\RV{X}(\omega),\RV{Y}(\omega))$. $(\RV{X},\RV{Y})$ has the property that $(\RV{X},\RV{Y})\yields (x,y)= \RV{X}\yields x\cap \RV{Y}\yields y$, which supports the interpretation of $(\RV{X},\RV{Y})$ as the values yielded by $\RV{X}$ and $\RV{Y}$ together.

Define the partial order on variables $\varlessthan$ where $\RV{X}\varlessthan \RV{Y}$ can be read ``$\RV{X}$ is completely determined by $\RV{Y}$''.

\begin{definition}[Variables determined by another variable]\label{def:variable_po}
Given a sample space $(\Omega,\sigalg{F})$ and variables $\RV{X}:\Omega\to X$, $\RV{Y}:\Omega\to Y$, $\RV{X}\varlessthan \RV{Y}$ if there is some $f:Y\to X$ such that $\RV{X}=f\circ \RV{Y}$.
\end{definition}

Clearly, $\RV{X}\varlessthan(\RV{X},\RV{Y})$ for any $\RV{X}$ and $\RV{Y}$.

\subsection{Decision procedures}\label{sec:actions}

The kind of problem we want to solve requires us to compare the consequences of different choices from a set of possibilities $C$. We take the \emph{consequences of} $\alpha\in C$ to refer to the values obtained by some measurement procedure $\proc{S}_\alpha$ associated with the choice $\alpha$.

As we have said, what exactly a ``measurement procedure'' is is a bit vague -- it's ``what we actually do to get the numbers we associate with variables''. It seems we could describe the above in terms of a single measurement procedure $\proc{S}$, which involves:

\begin{enumerate}
    \item Choose $\alpha$
    \item Proceed according to $\proc{S}_\alpha$
\end{enumerate}

However, $\proc{S}$ is problematic to model. The model is often part of the process of choosing $\alpha$, and so a model of $\proc{S}$ that involves the step ``choose $\alpha$'' will be self-referential. Because of this, we don't try to model $\proc{S}$, and whether this changes anything is an open question.

\begin{definition}[Decision procedure]
A decision procedure is a collection $\{\proc{S}_\alpha\}_{\alpha\in C}$ of measurement procedures.
\end{definition}

Like measurement procedures, a decision procedure $\{\proc{S}_\alpha\}_{\alpha\in A}$ isn't a well-defined mathematical object; it's not really a ``set'', because the contents are real-world actions.

\section{Representation theorems}\label{sec:how_represent_conseqeunces}

We have chosen to represent decision problems with probability functions $C\kto \Omega$ for some sample space $(\Omega,\sigalg{F})$ of ``consequences''. We haven't offered a deep justification for this choice. One question we might be inclined to ask is: what are we missing out on by making this choice? Representation theorems can help us to answer this question. A representation theorem proposes a collection of axioms regulating the kinds of preferences or beliefs we want our models to admit, and demonstrates that certain families of models can represent all preferences or beliefs consistent with these axioms. In particular, the representation theorems of Savage and Jeffreys both show that preferences among choices that satisfy their respective axiomatisations can be modeled with probability sets and utilities. Thus the question of what we're missing out on can be given the answer: we're missing out on the representation of preferences that satisfy neither set of axioms.

The following discussion will often make reference to \emph{complete preference relations}. A preference relation is a relation $\succ,\prec,\sim$ on a set $A$ such that for any $a,b,c$ in $A$ we have:
\begin{itemize}
    \item Exactly one of $a\succ b$, $a\prec b$, $a\sim b$ holds
    \item $(a\succ b)\iff(b\prec a)$
    \item $a\succ b$ and $b\succ c$ implies $a\succ c$
\end{itemize}

This definition is meant to correspond to the common sense idea of having preferences over some set of things, where $\succ$ can be read as ``strictly better than'', $\prec$ read as ``strictly worse than'' and $\sim$ read as ``as good as''. Given any two things from the set, I can say which one I prefer, or if I prefer neither (and all of these are mutually exclusive). If I prefer $a$ to $a'$ then I think $a'$ is worse than $a$. Furthermore, if I prefer $a$ to $a'$ and $a'$ to $a''$ then I prefer $a$ to $a''$.

In addition, we define $a\preceq b$ to mean $a\prec b$ or $a \sim b$.

\subsection{von Neumann-Morgenstern utility}

\citet{von_neumann_theory_1944} proved that when the \emph{vNM axioms} hold (not defined here; see the original reference or \citet{steele_decision_2020}), an agent's preferences between ``lotteries'' (which for our purposes are probability distributions in $\Delta(\Omega)$) can be represented as the comparison of the expected value under each lottery of a utility function $u$ unique up to affine transformation. That is, for lotteries $\prob{P}_\alpha$ and $\prob{P}_{\alpha'}$, there exists some $u:\Omega\to \mathbb{R}$ unique up to affine transformation such that $\mathbb{E}_{\prob{P}_\alpha}[u]> \mathbb{E}_{\prob{P}_{\alpha'}}[u]$ if and only if $\prob{P}_{\alpha} \succ \prob{P}_{\alpha'}$.

In vNM theory, the set of lotteries is is the set of all probability measures on $\Omega$. The von Neumann-Morgenstern theorem thus answers a slightly different question than the one we are interested in: it doesn't tell us when it is OK to use probability sets to represent uncertainty over the consequences of decisions, but instead it tells us when, given preferences over $\Delta(\Omega)$, these preferences can be represented by an essentially unique utility function $u$.

\subsection{Savage's decision theory}

Unlike con Neumann-Morgenstern's theory, \citet{savage_foundations_1954} decision theory doesn't assume that probability models should be used to represent uncertainty over consequences. Instead, Savage decision theory posits as basic elements a measurable set of \emph{states} $(S,\sigalg{S})$, and sets of \emph{acts} $C$ (analogous to choices in our language) and \emph{consequences} $F$. Furthermore, it is taken as a given that a known map $T:S\times C\to F$ is available, and the set $\{T(\cdot,\alpha)|\alpha\in C\}$ is equal to the set of all functions $S\to F$. The preference relation $\succ$ is over acts $C$, and if the preference relation along with the map $T$ satisfies the \emph{savage axioms}, then there exists a unique probability function $\prob{P}\in \Delta(S)$ and a utility $u:F\to \mathbb{R}$ unique up to affine transformation such that
\begin{align}
    \alpha\preceq \alpha' \iff \int_S u(T(s,\alpha))\prob{P}(\mathrm{d}s) \leq \int_S u(T(s,\alpha'))\prob{P}(\mathrm{d}s)
\end{align}

Note that if we equip acts and consequences with measures $(C,\sigalg{C})$ and $(F,\sigalg{F})$, $T$ and $\prob{P}$ together induce the probability function $\prob{Q}_\cdot:C\kto F$ given by
\begin{align}
    \prob{Q}_\alpha &:= \int_S T(s,\alpha)\prob{P}(\mathrm{d}s)\\
                    &=\prob{P}^{\RV{T}_\alpha}
\end{align}
where $\RV{T}_\alpha:S\to F$ is the function $s\mapsto T(s,\alpha)$. If so, we can then re-state Savage's criterion for preferences as
\begin{align}
    \alpha\succ \alpha' \iff \prob{Q}_\alpha u > \prob{Q}_{\alpha'} u
\end{align}
 If $\prob{Q}$ depends measurably on $S$, then it is a Markov kernel.

\todo[inline]{this is a theorem}

Thus Savage's theorem establishes that the relationship between acts and consequences can be represented by a probability function, and furthermore this probability function is unique. 

\subsubsection{Savage axioms}

Careful analysis of Savage's theorem is outside the scope of this work, but given the relevant of Savage's representation theorem we will reproduce the axioms from \citet{savage_foundations_1954} with a small amount of commentary. Keep in mind that Savage's theorem establishes that the following are sufficient for representation with a probability set, not necessary, and furthermore the probability set representation of preferences satisfying these axioms is unique. Thus we might be able to reject one or more axioms and still accept probability sets as a model of our decision problem (though I do not know which can be rejected, or what they might be replaced with).

Given acts $C$, states $(S,\sigalg{S})$ and consequences $F$ and a map $T:S\times C\to F$, let all greek letters $\alpha,\beta$ etc. be elements of $C$. Savage's axioms are:
\begin{enumerate}[P1:]
    \item There is a complete preference relation $\preceq$ on $C$
    \begin{enumerate}[D1:]
        \item $\alpha\preceq \beta$ given $B\in \sigalg{S}$ if and only if $\alpha'\preceq \beta'$ for every $\alpha'$ and $\beta'$ such that $T(\alpha,s)=T(\alpha',s)$ for $s\in B$ and $T(\alpha',r)=T(\beta',r)$ for $r\not\in B$, and $\beta'\preceq \alpha'$ either for every such pair or for none.
    \end{enumerate}
    \item For every $\alpha,\beta$ and $B\in \sigalg{S}$, $\alpha\preceq \beta$ given $B$ or $\beta\preceq \alpha$ given $B$
    \begin{enumerate}[D2:]
        \item for $q,q'\in F$, $q\preceq q'$ if and only if $\alpha\preceq \alpha'$ where $T(\alpha,s)=q$ and $T(\alpha',s)=q'$ for all $s\in S$
        \item $B\in \sigalg{S}$ is null if and only if $\alpha\preceq \beta$ given B for every $\alpha,\beta\in C$
    \end{enumerate}
    \item If $T(\alpha,s)=q$ and $T(\alpha',s)=q'$ for every $s\in B$, $B\in \sigalg{S}$ non-null, then $\alpha\preceq \alpha'$ given $B$ if and only if $q\preceq q'$
    \begin{enumerate}[D4:]
        \item For $A,B\in \sigalg{S}$, $A\leqslant B$ if and only if $\alpha_A\preceq \alpha_B$ or $q\preceq q'$ for all $\alpha_A,\alpha_B\in C$, $q,q'\in F$ such that $T(\alpha_A,s) = q$ for $s\in A$, $T(\alpha_A,s')=q'$ for $s'\not\in A$, $T(\alpha_B,s)=q$ for $s\in B$, $T(\alpha_B,s')=q'$ for $s'\not\in B$. Read $\leqslant$ as ``is less probable than''
    \end{enumerate}
    \item For every $A,B\in\sigalg{S}$, $A\leqslant B$ or $B\leqslant A$
    \item For some $\alpha,\beta$, $\alpha\prec \beta$
    \item Suppose $\alpha\not\preceq \beta$. Then for every $\gamma$ there is a finite partition of $S$ such that if $\alpha'$ agrees with $\alpha$ and $\beta'$ agrees with $\beta$ except on some element $B$ of the partition, $\alpha'$ and $\beta'$ being equal to $\gamma$ on $B$, then $\alpha\not\preceq \beta'$ and $\alpha'\not\preceq \beta$
    \begin{enumerate}[D5:]
        \item $\alpha\preceq q$ for $q\in F$ given $B$ if and only if $\alpha\preceq \beta$ given $B$ where $T(\beta,s)=q$ for all $s\in S$
    \end{enumerate}
    \item If $\alpha\preceq T(\beta,s)$ given $B$ for every $s\in B$, then $\alpha\preceq \beta$ given $B$
    \begin{enumerate}[P7':]
        \item The proposition given by inverting every expression in D5 and P7
    \end{enumerate}
\end{enumerate}

Our initial proposition was that the consequences $F$ are a set of things we know how to rank by preference, and acts $C$ are the things we want to rank. This is not exactly Savage's setup -- he assumes a preference relation over $C$ to begin with. Furthermore, Savage assumes that the set of acts corresponds to the set of function $S\to F$. Because we have a complete preference relation on $C$, the richness of $C$ can be used in conjunction with the other axioms to tease out a unique probability measure and essentially unique utility function. However, it is not obviously necessary that we must start with a predefined set of states $S$, and it seems overly demanding given $S$ to require a model that expresses preferences over every function $S\to F$. 

We can understand P1 as a requirement that we want the model to answer any question we have about comparing two different acts, no matter what states $S$ we might restrict our attention to. I can imagine that a mathematical model that allowed us to compare some pairs of acts and choose between the remaining noncomparable ones in an ad-hoc manner could be useful in some situations (for example: the extra effort to make the relation complete seems unlikely to pay off), but P1 rules this out.

D1 formalises the idea of one act $\alpha$ being not preferred to another $\beta$ given the knowledge that the true state lies in the set $B$ (in short: ``given $B$'' or ``conditional on $B$''). P2 is sometimes called the ``sure thing principle''. Roughly: for any $\alpha, \beta$ if $\alpha$ is better than $\beta$ on some states and no worse on any other, then it must be better than $\beta$. This can be viewed as a constraint on the kind of thing a state is -- the choice that we make cannot affect which state is likely to be the ``true'' state.

D4 + P4 defines the ``probability preorder'' $\leqslant$ on $(S,\sigalg{S})$ and assumes it is complete.

P5 is the requirement that the preference relation is non-trivial; not everything is equally desirable. This doesn't seem like it should be a practical requirement to me; we might hope that a model can distinguish between some of our options, but that doesn't mean we should assume it can. Savage claims that this requirement is ``innocuous'' because any exception must be trivial, but I'm not sure I agree.

P6 is a requirement of continuity; for any $\alpha\preceq \beta$, we can divide $S$ finely enough to squeeze a ``small slice'' of any third outcome $\gamma$ into the gap between the two.

P7 in combination with the other axioms forces preferences to be bounded.

\subsection{Jeffrey's decision theory}

Jeffrey's decision theory is an alternative to Savage's that offers a slightly different axiomatisation. It is set out in \citet{jeffrey_logic_1990}, and the key representation theorem proved in \citet{bolker_functions_1966}. Two key differences between the theories are:
\begin{itemize}
    \item Jeffrey's theory considers preferences to be a function $\sigalg{F}\to \mathbb{R}$ defined over a complete atomless Bolean algebra $\underline{\sigalg{F}}$ of propositions, and holds that choices are a subset of $\underline{\sigalg{F}}$
    \item The Bolker-Jeffrey representation theorem yields the existence of a nonunique pair of a probability measure $\prob{P}$ over $$\underline{\sigalg{F}}$$ and a desirability $\mathrm{dex}$ also defined on $\underline{\sigalg{F}}$
\end{itemize}

We are not trying to derive models from preferences, so we don't see the second difference as particuarly important. Recall that our fundamental problem is relating a set $C$ of things we can choose to a set $F$ of things we can compare. Jeffrey's theory uses a different strategy to accomplish this than Savages'; where Savage employs the function $T:C\times S\to F$ and axioms that constrain the preference relation on $C$, Jeffrey embeds the choices in the algebra $$\underline{\sigalg{F}}$$ and proposes axioms that constrain preferences on $$\underline{\sigalg{F}}$$. The ultimate result is, for our purposes, very similar.

The Bolker-Jeffrey representation theorem concludes: assuming a measurable set $(F,\sigalg{F})$ of consequences, if we have a complete preference relation on $\underline{\sigalg{F}}$ that satisfies the \emph{Bolker axioms} then there exists a desirability $\text{des}:$\underline{\sigalg{F}}\to\mathbb{R}$ and a probability distribution $\prob{P}\in \Delta($\underline{\sigalg{F}})$ such that for $A,B\in $\underline{\sigalg{F}}$ and finite partition $D_1,...,D_n\in $\underline{\sigalg{F}}$ (the proof is given by \citet{bolker_functions_1966}):
\begin{align}
    (A preceq B) \iff \sum_{i}^n \text{des}(D_i) \prob{P}_A(D_i) \leq \sum_{i}^n \text{des}(D_i) \prob{P}_A(D_i) \label{eq:ev_dec_theory}
\end{align}
where $\prob{P}_A(D_i):=\frac{\prob{P}(A\cap D_i)}{\prob{P}(A)}$ for $\prob{P}(A)>0$, undefined otherwise (so if $A\succ B$, then $\prob{P}(A)>0$).

\todo[inline]{this is a theorem}

Now, Jeffrey says that \emph{choices} are special elements of $\sigalg{F}$ that we have the power to ``make true''. In this case, we have some $C\subset\underline{\sigalg{F}}$ of choices that we want to compare, and the obvious probability function $\prob{P}_\cdot: C\to \Delta(\underline{\sigalg{F}})$ given by $\alpha\mapsto \prob{P}_\alpha$. We are still in a slightly different position to Savage's original theory, as our ``utility function'' is a function defined on $\sigalg{F}$ rather than on $F$. However, we're interested in questions about the construction of the probability function $\prob{P}_\cdot$, and so this difference is not relevant to our work.

\subsubsection{Bolker axioms}

$\underline{\sigalg{F}}$ a complete, atomless Boolean algebra with the impossible proposition. An example of such a set is constructed from the set of Lebesgue measurable sets on $[0,1]$ identifying any two sets that differ by a set of measure zero identified \citet{bolker_simultaneous_1967}. This is not a $\sigma$-algebra.
 
\begin{enumerate}[A1:]
    \item $\preceq$ is a complete preference relation
    \item $\underline{\sigalg{F}}$ is a complete, atomless Boolean algebra with the impossible proposition removed
    \item For $A,B\in \underline{\sigalg{F}}$, if $A\cap B=\emptyset$, then
    \begin{enumerate}[a)]
        \item If $A\succ B$ then $A\succ A\cup B \succ B$
        \item If $A\sim B$ then $A\sim A\cup B \sim B$
    \end{enumerate}
    \item Given $A\cap B=\emptyset$ and $A\sim B$, if $A\cup G\sim B\cup G$ for some $G$ where $A\cap G=B\cap G=\emptyset$ and $G\not\sim A$, then $A\cup G\sim B\cup G$ for every such $G$
    \begin{enumerate}[D1:]
        \item The supremum (infimum) of a subset $W\subset \underline{\sigalg{F}}$ is a set $G$ ($D$) such that for all $A\in W$, $G\subset A$ ($A\subset D$), and for any $E$ that also has this property, $G\subset E$ ($E\subset D$)
    \end{enumerate}
    \item Given $W:= \{W_i\}_{i\in M\subset \mathbb{N}}$ with $i<j\implies W_j\subset W_i$ and $W\subset \underline{\sigalg{F}}$ with supremum $G$ (infimum $D$), whenever $A\prec G \prec B$ ($A\prec D\prec B$) then there exists some $k\in M$ such that $i\geq k$ ($i\leq k$) implies $A\prec W_i \prec B$.
\end{enumerate}

The underlying set of events $\underline{\sigalg{F}}$ is a rather strange set here, and the construction rules out the case where we have prior knowledge of preferences over elements of some set of consequences $F$ that we are trying to import to the set of choices $C$. It may be more natural to consider preferences over subsets rather than preferences over elements of $F$ -- a preference like ``I prefer winning the bet to losing the bet'' picks out all the states in which I win and all the states in which I lose, and says the former is preferable to the latter. 

Overall, the algebra $\underline{\sigalg{F}}$ seems to be more like the kinds of things over which we might regularly express preferences than Savage's set of acts $C$.  However, I have a hard time understanding the significance of ruling atoms out of $\underline{\sigalg{F}}$. In subsequent work, we follow the standard probabilistic practice of assuming a $\sigma$-algebra rather than a complete atomless boolean algebra.

Like Savage's theory, A1 requires the preference relation to be complete.

A3 is the assumption that the desirability of disjunctions of events lies between the desirability of each event; it is sometimes called ``averaging''. It notably rules out the following: if $A\succ B$ we cannot have $A\cup B\sim A$. In the Jeffrey-Bolker theory, propositions all have positive probabilities.

A4 allows a probability order to be defined on $\underline{\sigalg{F}}$. The conditions $A\cap B=\emptyset$, $A\sim B$, $A\cup G\sim B\cup G$ for some $G$ where $A\cap G=B\cap G=\emptyset$ and $G\not\sim A$ can be seen as a test for $A$ and $B$ being ``equally probable''. A4 requires that if $A$ and $B$ are rated as equally probable by one such test, then they are rated as equally probable by all such tests.

A5 is an axiom of continuity.
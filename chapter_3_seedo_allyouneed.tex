
%!TEX root = main.tex

\chapter{Chapter 3: See-do models}

Consider the following problem: you are presented with a collection $\RV{H}$ of hypotheses about how the world might function and a vector $\mathbf{x}$ of observational data which you know could have taken values in some space $X$. You want to determine which hypothesis $\RV{H}\in \RV{H}$ best describes the world. However you ultimately solve the problem, the next step you take will probably be to determine for each $\RV{H}\in \RV{H}$ a probability distribution $\kernel{P}_\RV{H}\in \Delta(\sigalg{X})$ that indicates how likely you would be to observe the various elements of $X$ were $\RV{H}$ in fact the case. This is a \emph{statistical model} -- an indexed set of probability distributions $\{\prob{P}_\RV{H}|\RV{H}\in \RV{H}\}$. Statistical models are ubiquitous in the field of statistics -- they are found in statistical decision theory where the elements of $\RV{H}$ are typically called ``states''\citep{wald_statistical_1950}, in Bayesian inference where the elements of $\RV{H}$ may be called ``parameters'' \citep{freedman_asymptotic_1963} and in frequentist inference where elements of $\RV{H}$ they may be called ``hypotheses'' \citep{fisher_statistical_1992}. 

These different approaches to statistics may have different notions of what the ``best hypothesis'' $\RV{H}$ is, may employ different estimation methods and may not even agree about what ``distributed according to $\kernel{P}_\RV{H}$'' means. Nonetheless, the interpretation of the statistical model in each case is roughly the same: supposing $\RV{H}\in\RV{H}$ is true, the data will be distributed according to $\kernel{P}_\RV{H}$. A statistical model takes a hypothesis and tells you what you are likely to \emph{see}.

Sometimes we are interested in modelling situations where we can also make some choices that also affect the eventual consequences. For example, I might hypothesise $\RV{H}_1$: the switch on the wall controls my light, $\RV{H}_2$: the switch on the wall does not control my light. Then, given $\RV{H}_1$ I can choose to toggle the switch, and I will see my light turn on, or I can choose not to toggle the switch and I will not see my light turn on. Given $\RV{H}_2$, neither choice will result in a light turned on. Choices are clearly different to hypotheses: the choice I make depends on what I want to happen, while whether or not a hypothesis is true has no regard for my ambitions.

A ``statistical model with choices'' is simply a map $\prob{T}:D\times \RV{H}\to \Delta(\sigalg{E})$ for some set of choices $D$, hypotheses $\RV{H}$ and outcome space $(E,\sigalg{E})$. We can also distinguish two types of outcomes: \emph{observations} which are given prior to a choice being made and \emph{consequences} which happen after a choice is made. Observations cannot be affected by the choices made, while consequences are not subject to this restriction. That is, observations are what we might \emph{see} before making a choice, which depends on the hypothesis alone, and if we are lucky we may be able to invert this dependence to learn something about the hypothesis from observations. On the other hand, the consequences of what we \emph{do} depends jointly on the hypothesis and the choice we make and we judge which choices are more desirable on the basis of which consequences we expect them to produce. 

What we are studying is a family of models that generalises of statistical models to include hypotheses, choices, observations and consequences. These models are referred to as \emph{see-do models}. Hypotheses, observations, consequences and choices are not individually new ideas. \emph{Statistical decision problems} \citep{wald_statistical_1950,savage_foundations_1972} extend statistical models with decisions and \emph{losses}. Like consequences, losses depend on which choices are made. However, unlike consequences, losses must be ordered and reflect the preferences of a decision maker. \emph{Influence diagrams} are directed graphs created to represent decision problems that feature ``choice nodes'', ``chance nodes'' and ``utility nodes''. An influence diagram may be associated with a particular probability distribution \cite{nilsson_evaluating_2013} or with a set of probability distributions \cite{dawid_influence_2002}.

See-do models have deep roots in decision theory. Decision theory asks, out of a set of available acts, which ones ought to be chosen. See-do models answer an intermediate question: out of a set of available acts, what are the consequences of each? This question is described by \citet{pearl_causality:_2009} as an ``interventional'' question. To model questions described by Pearl as ``counterfactual'', we can use a special kind of see-do model with \emph{parallel choices}. Parallel choices model sequences of experiments where taking the same action repeatedly deterministically results in the same outcome, and where the result of a sequence of actions doesn't depend on the order in which the actions are taken. Parallel choices can arguably model a kind of commonsense counterfactuals as expressed in the question ``what would have happened if I chose $b$ instead of $a$?''. Whether or not this interpretation is compelling, we show that \emph{potential outcomes} \citep{rubin_causal_2005} exist in a see-do model if and only if it is a model of parallel choices.

\todo[inline]{Interestingly, it seems to be possible to construct a see-do model where the ``hypothesis'' is a quantum state, and quantum mechanics + locality seems to rule out parallel choices in such models in a manner similar to Bell's theorem. ``Seems to'' because I haven't actually proven any of these things.}

\section{Definition}

\todo[inline]{Terminology question: The variables $\RV{H}$ and $\RV{D}$ aren't \emph{random} in the commonsense understanding of the word. They're also defined on a \emph{kernel space} rather than a \emph{probability space}. They're currently called random variables simply by virtue of being measurable functions on the outcome space. I'm not a huge fan of ``quasirandom variables'', but it does capture the idea that these things are very similar to random variables but not exactly the same.}

\begin{definition}[See-Do model]\label{def:seedo}
A \emph{see-do model} $\langle\kernel{T},\RV{H},\RV{D},\RV{X},\RV{Y}\rangle$ is a kernel space (Definition \ref{def:kernel_space}) $(\kernel{T},H\times D,X\times Y)$ along with four random variables: the \emph{hypothesis} $\RV{H}:H\times D\times X\times Y\to H$, the \emph{choice} $\RV{D}:H\times D\times X\times Y\to D$, the \emph{observations} $\RV{X}:H\times D\times X\times Y\to X$ and the \emph{consequences} $\RV{Y}:H\times D\times X\times Y\to Y$, all given by the obvious projection maps. 

The spaces $H$, $D$, $X$ and $Y$ are the hypothesis, choice, observation and consequence spaces respectively.

A see-do model has the additional property that, holding the hypothesis fixed, the observations are independent of the choices - i.e. $\RV{X}\CI_{\kernel{T}} \RV{D}|\RV{H}$. We require that $H\times D$ is countable.
\end{definition}


\begin{theorem}[Observation and Consequence maps]\label{th:obs_cmaps}
Any see-do model $(\kernel{T},\RV{H},\RV{D},\RV{X},\RV{Y})$ can be uniquely represented by the following pair of Markov kernels:
\begin{itemize}
    \item The \emph{observation map} $\kernel{T}^{\RV{X}|\RV{H}}$
    \item The \emph{consequence map} $\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$
\end{itemize}

Furthermore
\begin{align}
\kernel{T} = \begin{tikzpicture} \path (0,0) node (T) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        + (0.,-1.15) node[copymap] (copy2) {}
        ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
        ++ (0.7,0) node[copymap] (copy1) {}
        +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
        ++ (1.9,0) node (X) {$\RV{X}$}
        +  (0,-1) node (Y) {$\RV{Y}$}
        + (0,0.5) node (H) {$\RV{H}$}
        + (0,-1.5) node (D2) {$\RV{D}$};
        \draw (T) -- (O) -- (X);
        \draw (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
        \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
        \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
        \draw (C) -- (Y);
        \draw (copy0) to [out = 65, in = 180] (H);
        \draw (copy2) to [out = -65, in = 180] (D2);
    \end{tikzpicture}
\end{align}
\end{theorem}

\todo[inline]{Maybe moves proofs out of main text}

\begin{proof}
By \ref{th:representaiton}, 

\begin{align}
\kernel{T} = \begin{tikzpicture} \path (0,0) node (T) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        + (0.,-1.15) node[copymap] (copy2) {}
        ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}\RV{D}}$}
        ++ (0.7,0) node[copymap] (copy1) {}
        +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
        ++ (1.9,0) node (X) {$\RV{X}$}
        +  (0,-1) node (Y) {$\RV{Y}$}
        + (0,0.5) node (H) {$\RV{H}$}
        + (0,-1.5) node (D2) {$\RV{D}$};
        \draw (T) -- (O) -- (X);
        \draw[name path=P1] (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
        \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
        \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
        \draw (C) -- (Y);
        \draw (copy0) to [out = 65, in = 180] (H);
        \draw (copy2) to [out = -65, in = 180] (D2);
        \draw[name path=P2] (copy2) to [out = 65, in = 180] ($(O.west)+(0,-0.15)$);
    \end{tikzpicture}
\end{align}


By the assumption $\RV{X}\CI_{\kernel{T}} \RV{D}|\RV{H}$ and version 2 of conditional independence from Theorem \ref{th:ci_equivalence},

\begin{align}
\kernel{T} &= \begin{tikzpicture} \path (0,0) node (T) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        + (0.,-1.15) node[copymap] (copy2) {}
        ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
        ++ (0.7,0) node[copymap] (copy1) {}
        +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
        ++ (1.9,0) node (X) {$\RV{X}$}
        +  (0,-1) node (Y) {$\RV{Y}$}
        + (0,0.5) node (H) {$\RV{H}$}
        + (0,-1.5) node (D2) {$\RV{D}$};
        \draw (T) -- (O) -- (X);
        \draw (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
        \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
        \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
        \draw (C) -- (Y);
        \draw (copy0) to [out = 65, in = 180] (H);
        \draw (copy2) to [out = -65, in = 180] (D2);
        \draw[-{Rays[n=8]}] (copy2) to [out = 65, in = 180] ($(O.west)+(-0.2,-0.5)$);
    \end{tikzpicture}\\
    &= \begin{tikzpicture} \path (0,0) node (T) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        + (0.,-1.15) node[copymap] (copy2) {}
        ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
        ++ (0.7,0) node[copymap] (copy1) {}
        +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
        ++ (1.9,0) node (X) {$\RV{X}$}
        +  (0,-1) node (Y) {$\RV{Y}$}
        + (0,0.5) node (H) {$\RV{H}$}
        + (0,-1.5) node (D2) {$\RV{D}$};
        \draw (T) -- (O) -- (X);
        \draw (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
        \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
        \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
        \draw (C) -- (Y);
        \draw (copy0) to [out = 65, in = 180] (H);
        \draw (copy2) to [out = -65, in = 180] (D2);
    \end{tikzpicture}
\end{align}

\end{proof}

\todo[inline]{Not quite sure if this is the right place for the following definition}

The independence of observations and choices is preserved when we take the product of a see-do model and a \emph{prior} over hypotheses. Such a product produces a \emph{Bayesian see-do model}:

\begin{definition}[Bayesian See-Do Model]
A Bayesian See-Do Model $\langle\kernel{U},\RV{D},\RV{X},\RV{Y}\rangle$ is a Markov kernel space $(\kernel{U},D,X\times Y)$ with the property $\RV{X}\CI_{\kernel{U}}\RV{D}$, along with choices $\RV{D}$, observations $\RV{X}$ and consequences $\RV{Y}$, defined as before.
\end{definition}

\begin{theorem}[A see-do model with a prior is a Bayesian see-do model]
The product of a see-do model $\kernel{T}$ and a prior $\gamma\in \Delta(\sigalg{H})$
\begin{align}
    \kernel{U} &:= (\gamma\otimes \mathrm{Id}^D)\kernel{T}
\end{align}
Is a Bayesian see-do model.
\end{theorem}

\todo[inline]{Maybe moves proofs out of main text}

\begin{proof}

It nees to be shown that $\RV{X}\CI_{\kernel{U}}\RV{D}$.

By definition
\begin{align}
\kernel{U}^{\RV{X}|\RV{D}} &= \kernel{U}\kernel{F}^{\RV{X}}\\
                            &= (\gamma\otimes \mathrm{Id}^D)\kernel{T}\kernel{F}^{\RV{X}}\\
                            &= \begin{tikzpicture} \path (0,0) node[dist] (T) {$\gamma$}
                                    + (0,-1.15) node (D) {$\RV{D}$}
                                    ++ (0.5,0) node[copymap] (copy0) {}
                                    + (0.,-1.15) node[copymap] (copy2) {}
                                    ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
                                    ++ (0.7,0) node[copymap] (copy1) {}
                                    +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
                                    ++ (1.9,0) node (X) {$\RV{X}$}
                                    +  (0,-1) node (Y) {};
                                    \draw (T) -- (O) -- (X);
                                    \draw (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
                                    \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
                                    \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
                                    \draw[-{Rays[n=8]}] (C) -- (Y);
                                \end{tikzpicture}\\
                            &= \begin{tikzpicture} \path (0,0) node[dist] (T) {$\gamma$}
                                    + (0,-1.15) node (D) {$\RV{D}$}
                                    ++ (0.5,0) coordinate (copy0)
                                    ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
                                    ++ (0.7,0) coordinate (copy1)
                                    ++ (1.9,0) node (X) {$\RV{X}$}
                                    +  (0,-1) node (Y) {};
                                    \draw (T) -- (O) -- (X);
                                    \draw[-{Rays[n=8]}] (D) -- (Y);
                                \end{tikzpicture}
\end{align}

Which implies $\RV{X}\CI_{\kernel{U}} \RV{D}$ by version (2) of conditional indpendence (Theorem \ref{th:ci_equivalence}).
\end{proof}


\begin{definition}[Hypothesis sufficiency]
The hypothesis $\RV{H}$ is \emph{sufficient} for a see-do model if the consequence map has no dependence on observations $\RV{X}$ conditional on $\RV{H}$. That is, $\RV{Y}\CI_\kernel{T} \RV{X}|\RV{D}\RV{H}$. 

A hypothesis sufficient see-do model can be specified with:

\begin{itemize}
    \item Hypothesis space $\RV{H}$, choices $D$, observations $X$ and consequences $Y$
    \item Observation map $\kernel{T}^{\RV{X}|\RV{H}}$
    \item Reduced consequence map $\kernel{T}^{\RV{Y}|\RV{H}\RV{D}}$
\end{itemize}
\end{definition}

Given observations $\RV{X}$, assumed to be an IID sequence $\RV{X}_1,\RV{X}_2,...$ conditional on $\RV{H}$, a common ``causal inference problem'' is to estimate the ``true'' distribution of observations $\kernel{T}^{\RV{X}_i|\RV{H}}_{h^*}$ and from this to estimate the consequence map $\kernel{T}^{\RV{Y}|\RV{H}\RV{D}}_{h^*\cdot}$, if this is possible. This problem only makes sense if hypothesis sufficiency is assumed -- once $h^*$ is given, the consequence map of interest has no further dependence on $\RV{X}$. We show that all decision problems can be modeled by a hypothesis sufficient see-do model.


\subsubsection{Examples of hypothesis sufficient and insufficient see-do models}

Suppose we are betting on the outcome of the flip of a possibly biased coin with payout 1 for a correct guess and 0 for an incorrect guess, and we are given $N$ previous flips of the coin to inspect. This situation can be modeled by a hypothesis sufficient see-do model. Define $\kernel{B}:(0,1)\to \Delta(\{0,1\})$ by $\kernel{B}:\RV{H}\mapsto \mathrm{Bernoulli}(\RV{H})$. Then define $\prescript{1}{}{\kernel{T}}$ by:

\begin{itemize}
    \item $D=\{0,1\}$
    \item $X=\{0,1\}^N$
    \item $Y=\{0,1\}$
    \item $H=(0,1)$
    \item $\prescript{1}{}{\kernel{T}}^{\RV{X}|\RV{H}}:\splitter{0.1}^N\kernel{B}$
    \item $\prescript{1}{}{\kernel{T}}^{\RV{Y}|\RV{D}\RV{H}}:(\RV{H},d)\mapsto \mathrm{Bernoulli}(1-|d-\RV{H}|)$
\end{itemize}

In this model, the chance $\RV{H}$ of the coin landing on heads is as much as we can hope to know about how our bet will work out.

Suppose instead that in addition to the $N$ prior flips, we manage to look at the outcome of the flip on which we will bet. In this case, the situation can be modeled by the following hypothesis insufficient see-do model $\prescript{2}{}{\kernel{T}}$:

\begin{itemize}
    \item $D=\{0,1\}$
    \item $X=\{0,1\}^{N+1}$
    \item $Y=\{0,1\}$
    \item $H=(0,1)$
    \item $\prescript{2}{}{\kernel{T}}^{\RV{X}|\RV{H}}:\splitter{0.1}^{N+1}\kernel{B}$
    \item $\prescript{2}{}{\kernel{T}}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}:(\RV{H},\mathbf{x},d)\mapsto \delta_{1-|d-x_{N+1}|}$
\end{itemize}

In this case, even if we are told the value of $\RV{H}$, we still benefit from using the observed data when making our decision.

It appears that it might be possible to model the second situation with a hypothesis sufficient model by including the result of the $N+1$th flip in the hypothesis. Define the new hypothesis space $H'=(0,1)\times\{0,1\}$ and define $\prescript{3}{}{\kernel{T}}$ by:

\begin{itemize}
    \item $D=\{0,1\}$
    \item $X=\{0,1\}^{N+1}$
    \item $Y=\{0,1\}$
    \item $H'=(0,1)\times\{0,1\}$
    \item $\prescript{3}{}{\kernel{T}}^{\RV{X}|\RV{H}'}:(\splitter{0.1}^N\kernel{B}\otimes \delta_{x_{N+1}}$
    \item $\prescript{3}{}{\kernel{T}}^{\RV{Y}|\RV{H}'\RV{D}}:(h,x_{N+1},d)\mapsto \delta_{1-|d-x_{N+1}|}$
\end{itemize}

However, $\RV{X}_{N+1}$ is related to the previous flips $\vecRV{X}_{<N}$ and $\prescript{3}{}{\kernel{T}}$ ignores this fact.  In particular, given any $\RV{H}'=(h,\_)$, $\RV{X}_{N+1}$ as well as $\RV{X}_{i}$, $i\leq N$ should all distributed according to Bernoulli($h$). Thus $\prescript{2}{}{\kernel{T}}$ is preferable to $\prescript{3}{}{\kernel{T}}$ because it represents more of the knowledge we have about the problem.

If a see-do model is employed in a \emph{decision problem} -- defined in the next section -- there is an alternative way to avoid hypothesis insufficiency that does not require throwing out some of the model structure.

\todo[inline]{The importance of this is that counterfactual questions are usually \emph{not} decision problems and so they do not have the possibility of avoiding insufficiency available; also \emph{in practice} counterfactual problems are usually hypothesis insufficient while decision problems are usually not.}

\subsection{Causal questions and decision functions}

\citet{pearl_book_2018} has proposed three types of causal question:
\begin{enumerate}
    \item Association: How are $\RV{W}$ and $\RV{Z}$ related? How would observing $\RV{W}$ change my beliefs about $\RV{Z}$?
    \item Intervention: What would happen if I do ... ? How can I make ... happen?
    \item Counterfactual: What if I had done ... instead of what I actually did?
\end{enumerate}

\emph{Causal decision problems} are, roughly speaking, ``interventional'' problems. In English, a causal decision problem roughly asks

\begin{quote}
    Given that I have data $\RV{X}$ and I know which values of $\RV{Y}$ I would like to see and some knowledge about how the world works, which of my available choices $D$ should I select?
\end{quote}

Note that this presupposes somewhat more than Pearl's prototypical interventional questions. First, it supposes that we have \emph{preferences} over the values that $\RV{Y}$ might take, which we need not have to answer the question ``What would happen if I do ...?''. Secondly, and crucially to our theory, causal decision problem suppose that we are given data and a set of choices. 
\end{definition}

We will return to the question of preferences. For now, we will focus on the idea that a causal decision problem is about selecting a choice given data. That is, however the selection is made, the answer to a causal decision problem is always a \emph{decision function} $\kernel{D}:X\to \Delta(\sigalg{D})$.

\subsubsection{Avoiding insufficiency with decision functions}

Given that 

\subsubsection{Decision rules}

See-do models encode the relationship between observed data and consequences of decisions. In order to actually make decisions, we also require preferences over consequences. We suppose that a \emph{utility function} is given, and evaluate the desirability of consequences using \emph{expected utility}. A see-do model along with a utility allows us to evaluate the desirability of \emph{decisions rules} according to each hypothesis.

\begin{definition}[Utility function]
Given a See-Do Model $\kernel{T}:\RV{H}\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$, a \emph{utility function} $u$ is a measurable function $Y\to \mathbb{R}$. 
\end{definition}

\begin{definition}[Expected utility]
Given a utility function $u:Y\to \mathbb{R}$ and probability measures $\mu,\nu\in \Delta(\sigalg{Y})$, the \emph{expected utility} of $\mu$ is $\mathbb{E}_{\mu}[u]$.

$\mu$ is \emph{preferred} to $\nu$ if $\mathbb{E}_{\mu}[u]\geq \mathbb{E}_{\nu}[u]$, and \emph{strictly preferred} if $\mathbb{E}_{\mu}[u]>\mathbb{E}_{\nu}[u]$.
\end{definition}

\begin{definition}[Decision rule]
Given a see-to map $\kernel{T}:\RV{H}\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$, a \emph{decision rule} is a Markov kernel $X\to \Delta(\sigalg{D})$. A \emph{deterministic decision rule} is a decision rule that is deterministic.

\todo[inline]{Define deterministic Markov kernels}
\end{definition}

Expected utility together with a decision rule gives rise to the definition of \emph{risk}, which connects CSDT to classical statistical decision theory (SDT). For historical reasons, risks are minimised while utilities are maximised.

\begin{definition}[Risk]
Given a see-to map $\kernel{T}:\RV{H}\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$, a utility $u:Y\to \mathbb{R}$ and the set of decision rules $\mathscr{U}$, the \emph{risk} is a function $l:\RV{H}\times \mathscr{U}\to \mathbb{R}$ given by

\begin{align}
    R(\RV{H},\kernel{U}) := - \int_X  \kernel{U}_x \kernel{T}^{\RV{Y}|\RV{D}\RV{X}\RV{H}}_{\cdot,x,\RV{H}} u d\kernel{T}^{\RV{X}|\RV{H}}_\RV{H}(x)
\end{align}

for $\RV{H}\in \RV{H}$, $\kernel{U}\in \mathscr{U}$. Here $\kernel{U}_x \kernel{T}^{\RV{Y}|\RV{D}\RV{X}\RV{H}}_{\cdot,x,\RV{H}} u$ is the product of the measure $\kernel{U}_x$, the kernel $\kernel{T}^{\RV{Y}|\RV{D}\RV{X}\RV{H}}_{\cdot,x,\RV{H}}:D\to \Delta(\sigalg{Y})$ and the function $u$.
\end{definition}

The loss induces a partial order on decision rules. If for all $\RV{H}$, $l(\RV{H},\kernel{U})\leq l(\RV{H},\kernel{U}')$ then $\kernel{U}$ is at least as good as $\kernel{U}'$. If, furthermore, there is some $\RV{H}_0$ such that $l(\RV{H}_0,\kernel{U})<l(\RV{H}_0,\kernel{U}')$ then $\kernel{U}$ is preferred to $\kernel{U}'$.

\begin{definition}[Induced statistical decision problem]
A see-do model $\kernel{T}:\RV{H}\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$ along with a utility $u$ induces the \emph{statistical decision problem} $(\RV{H},\mathscr{U},R)$ with states $\RV{H}$, decisions $\mathscr{U}$ and risks $R$.

\todo[inline]{Statistical decision problems usually define the risk via the loss, but it is only possible to define a loss with a hypothesis sufficient model. We don't actually need a loss, though: the complete class theorem still holds via the induced risk and Bayes risk}

\end{definition}


A key difference between CSDT and other approaches to causal inference is that diagrams in CSDT feature two coupled maps $\kernel{O}$ and $\kernel{C}$, while most other approaches to causal inference represent both $\kernel{O}$ and $\kernel{C}$ in one diagram. \citet{lattimore_replacing_2019} is the only other example I am aware of that represents both $\kernel{O}$ and $\kernel{C}$. Nevertheless, ``one-picture'' causal models such as Causal Bayesian Networks, Single World Intervention Graphs \emph{do} represent observational distributions and interventional maps, and the two differ (see Section \ref{sec:single_double_representation})

A causal hypothesis class $\RV{H}$ induces a binary relation between observed probability distributions $\prob{O}_\RV{H}$ and consequence maps $\prob{C}_\RV{H}$. This approach is very agnostic about the actual relation induced -- we do not even insist that the range of the observed data $X$ is the same as the range of possible consequences $Y$ (though we will generally limit our attention to cases where the two coincide). 

In common with \citet{heckerman_decision-theoretic_1995}, decisions (or ``acts'') are primitive elements of See-Do Models. In contrast to our work, \citet{heckerman_decision-theoretic_1995} only discuss deterministic \emph{consequence maps}, while See-Do Models represent relations between consequence maps and observed probability.

Decisions are similar to the ``regime indicators'' found in \citet{dawid_decision-theoretic_2020}. They coincide precisely if we suppose that the observation and consequence spaces coincide ($X=Y$) and there exists an ``idle'' decision $d^*\in D$ such that $\kernel{C}_{(\cdot,d^*)} = \kernel{O}_{\cdot}$. However, in general we don't require that $\kernel{O}$ and $\kernel{C}$ are related in this manner. This assumption will be revisited in \todo[inline]{A section I haven't written yet}.

\subsection{D-causation}

While we take $D$ to be a primitive element of causal decision problems, and therefore a primitive of See-Do Models. Causes are not primitive, but we can offer a secondary notion of causation. We call this $D$-causation to stress the fact that it arises in a theory of causal inference in which the set $D$ of available decisions is primitive. A similar idea is discussed extensively in \citet{heckerman_decision-theoretic_1995}. The main differences are that what we call ``consequence maps'' map decisions to probability distributions over possible consequences while Heckerman and Shachter work with ``states'' that map decisions deterministically to consequences. In addition, while we define $D$-causation relative to a particular consequence map $\kernel{C}_\RV{H}$, Heckerman and Shachter define it with respect to a \emph{set} of states.

Section \ref{sec:cbns_without_d} explores the difficulty of defining ``objective causation'' without reference to a set of basic decisions, acts or operations. $D$ need not be interpreted as the set of decisions an agent may make, but whatever interpretation it is assigned, all existing examples of causal models seem to require a ``domain set''.

See Section \ref{ssec:random_variables} for the definition of random variables.

\todo[inline]{Add definition of conditional independence, revise wire label definitions}

One way to motivate the notion of $D$-causation is to observe that for many decision problems, the full set $D$ may be extremely large. Suppose I aim to have my light switched on, and there is a switch that controls the light. Often, the relevant choice of acts for such a problem would appear to be $D_0=\{\text{flip the switch},\text{don't flip the switch}\}$. However, in principle I have a much larger range of options to choose from. For simplicity's sake, suppose I have instead the following set of options:

\begin{align*}
D_1:=&\{``\text{walk to the switch and press it with my thumb}'', \\
    &``\text{trip over the lego on the floor, hop to the light switch and stab my finger at it}'',\\
    &``\text{stay in bed}''\}
\end{align*}

If having the light turned on is all that matters, I could consider any acts in $D_1$ to be equivalent if they have the same ultimate impact on the position of the light switch. $D_0$ is a quotient over $D_1$ under this equivalence relation. 

If I hypothesize that, relative to $D_1$, the ultimate state of the light switch is all that matters to determine the ultimate state of the light, I can say that the light switch $D_1$-causes the state of the light. Given this $D_1$-causation, the $D_1$ decision problem can (subject to my hypothesis) be reduced to a $D_0$ decision between states of the light switch.

If I consider an even larger set of possible acts $D_2$, I might not accept the hypothesis of $D_2$-causation. Let $D_2$ be the following acts:

\begin{align*}
D_2:=&\{``\text{walk to the switch and press it with my thumb}'', \\
    &``\text{trip over the lego on the floor, hop to the light switch and stab my finger at it}'',\\
    &``\text{stay in bed}'',
    &``\text{toggle the mains power, then flip the light switch}''\}
\end{align*}

In this case, it would be unreasonable to hypothesize that all acts that left the light switch in the ``on'' position would also result in the light being ``on''. Thus the switch does not $D_2$-cause the light to be on.

Formally, $D$-causation is defined in terms of conditional independence:

\begin{definition}[$D$-causation]\label{def:d_cause}
Given a consequence map $\kernel{C}_\RV{H}:D\to \Delta(\mathcal{Y})$, random variables $\RV{Y}_1:Y\times D\to Y_1$, $\RV{Y}_2:Y\times D\to Y_2$ and domain variable $\RV{D}:Y\times D\to D$ (Definition \ref{def:domain_variable}), $\RV{Y}_1$ $D$-causes $\RV{Y}_2$ iff $\RV{Y}_2\CI_{\kernel{C}_\RV{H}} \RV{D}|\RV{Y}_1$.
\end{definition}

\subsection{D-causation vs Heckerman and Shachter}

Heckerman and Shachter study deterministic ``consequence maps''. Furthermore, what we call hypotheses $\RV{H}\in\RV{H}$, Heckerman and Schachter call states $s\in S$. One could consider a state to be a hypothesis that is specific enough to yield a deterministic map from decisions to outcomes. Heckerman and Shachter's notion of causation is defined by \emph{limited unresponsiveness} rather than \emph{conditional independence}, which depends on a partition of states rather than a particular hypothesis.

\begin{definition}[Limited unresponsiveness]
    Given states $S$, deterministic consequence maps $\kernel{C}_s:D\to \Delta(F)$ for each $s\in A$ and a random variables $\RV{X}:F\to X$, $\RV{Y}:F\to Y$, $\RV{Y}$ is unresponsive to $\RV{D}$ in states limited by $\RV{X}$ if $\kernel{C}_{(s,d)}^{\RV{X}|\RV{D}}=\kernel{C}_{(s,d')}^{\RV{X}|\RV{D}\RV{S}}\implies \kernel{C}_{(s,d)}^{\RV{Y}|\RV{D}\RV{S}}=\kernel{C}_{(s,d')}^{\RV{Y}|\RV{D}\RV{S}}$ for all $d,d'\in D$, $s\in S$. Write $\RV{Y}\not\hookleftarrow_{\RV{X}} \RV{D}$
\end{definition}

\begin{lemma}[Limited unresponsiveness implies $D$-causation]
For deterministic consequence maps, $\RV{Y}\not\hookleftarrow_{\RV{X}} \RV{D} $ implies $\RV{X}$ $D$-causes $\RV{Y}$ in every state $s\in S$.
\end{lemma}

\begin{proof}
By the assumption of determinism, for each $s\in S$ and $d\in D$ there exists $x(s,d)$ and $y(s,d)$ such that $\kernel{C}^{\RV{X}\RV{Y}|\RV{D}\RV{S}}_{d,s} = \delta_{x(s,d)}\otimes\delta_{y(s,d)}$.

By the assumption of limited unresponsiveness, for all $d,d'$ such that $x(s,d)=x(s,d')$, $y(s,d)=y(s,d')$ also. Define $f:X\times S\to Y$ by $(s,x)\mapsto y(s,[x(s,\cdot)]^{-1}(x(s,d)))$ where $[x(s,\cdot)]^{-1}(a)$ is an arbitrary element of $\{d|x(s,d)=a\}$. For all $s,d$, $f(x(s,d),s)=y(s,d)$. Define $\kernel{M}:X\times D\times S\to \Delta(\mathcal{Y})$ by $(x,d,s)\mapsto \delta_{f(x,s)}$. $\kernel{M}$ is a version of $\kernel{C}^{\RV{Y}|\RV{X},\RV{D},\RV{S}}$ because, for all $A\in \mathcal{X}$, $B\in \mathcal{Y}$, $s\in S$, $d\in D$:

\begin{align}
    \kernel{C}^{\RV{X}|\RV{D}\RV{S}}_{(d,s)}\splitter{0.1}(\kernel{M}\otimes\mathrm{Id}) &= \int_A \kernel{M}(x',d,s;B) d\delta_{x(s,d)}(x') \\
                                                                                        &= \int_A \delta_{f(x',s)}(B) d\delta_{x(s,d)}(x') \\
                                                                                        &= \delta_{f(x(s,d),s)}(B)\delta_{x(s,d)}(A) \\
                                                                                        &= \delta_{y(s,d)}(B)\delta_{x(s,d)}(A)\\
                                                                                        &= \delta_{x(s,d)}\otimes\delta_{y(s,d)}(A\times B)
\end{align}

$\kernel{M}$ is also independent of $\RV{D}$, given the obvious labeling of inputs. Therefore $\RV{Y}\CI_{\kernel{C}_s}\RV{D}|\RV{X}$.
\end{proof}

However, despite limited unresponsiveness implying $D$-causation within every state, it does not imply $D$-causation in mixtures of states. Suppose $D=\{0,1\}$ where $1$ stands for ``toggle light switch'' and $0$ stands for ``do nothing''. Suppose $S=\{[0,0],[0,1],[1,0],[1,1]\}$ where $[0,0]$ represents ``switch initially off, mains off'' the other states generalise this in the obvious way. Finally, $\RV{F}\in\{0,1\}$ is the final position of the switch and $\RV{L}\in\{0,1\}$ is the final state of the light. We have

\begin{align}
    \kernel{C}^{\RV{L}\RV{F}|\RV{D}\RV{S}}_{d,[i,m]} = \delta_{(d\text{ XOR }i)\text{ AND }m}\otimes \delta_{(d\text{ XOR }i)\text{ AND }m}
\end{align}

Within states $[0,0]$ and $[1,0]$, the light is always off, so $\RV{F}=a\implies \RV{L}=0$ for any $a$. In states $[0,1]$ and $[1,1]$, $\RV{F}=1\implies \RV{L}=1$ and $\RV{F}=0\implies \RV{L}=0$. Thus $\RV{L}\not\hookleftarrow_{\RV{F}} \RV{D}$. However, suppose we take a mixture of consequence maps:
\begin{align}
    \kernel{C}_\gamma &= \frac{1}{4}\kernel{C}_{\cdot,[0,0]} + \frac{1}{4}\kernel{C}_{\cdot,[0,1]} + \frac{1}{2}\kernel{C}_{\cdot,[1,1]}\\
    \kernel{C}^{\RV{F}\RV{L}|\RV{D}}_\gamma &= \frac{1}{4} \left[\begin{matrix}
                        1 & 0\\ 0 & 1
                      \end{matrix}\right]\otimes \left[\begin{matrix}
                        1 & 0\\ 1 & 0
                      \end{matrix}\right] + \frac{1}{4} \left[\begin{matrix}
                        1 & 0\\ 0 & 1
                      \end{matrix}\right]\otimes \left[\begin{matrix}
                        1 & 0\\ 0 & 1
                      \end{matrix}\right] + \frac{1}{2}\left[\begin{matrix}
                        0 & 1\\ 1 & 0
                      \end{matrix}\right]\otimes \left[\begin{matrix}
                        0 & 1\\ 1 & 0
                      \end{matrix}\right]
\end{align}

Then

\begin{align}
    [1,0]\kernel{C}^{\RV{F}\RV{L}|\RV{D}}_{\gamma} &= \frac{1}{4}[0,1]\otimes[1,0]+\frac{1}{4}[0,1]\otimes[0,1]+\frac{1}{2}[1,0]\otimes[1,0]\\
    [1,0]\splitter{0.1}(\kernel{C}^{\RV{F}|\RV{D}}_\gamma\otimes \kernel{C}^{\RV{L}|\RV{D}}_\gamma) &= (\frac{1}{2}[0,1]+\frac{1}{2}[1,0])\otimes(\frac{1}{4}[0,1]+\frac{3}{4}[1,0])\\
    \implies [1,0]\kernel{C}^{\RV{F}\RV{L}|\RV{D}}_{\gamma} &\neq [1,0] \splitter{0.1} (\kernel{C}^{\RV{F}|\RV{D}}_\gamma\otimes \kernel{C}^{\RV{L}|\RV{D}}_\gamma)
\end{align}

Thus under hypothesis mixture $\gamma$, $\RV{F}$ does not $D$-cause $\RV{L}$ even though $\RV{F}$ $D$-causes $\RV{L}$ in all states $S$. The definition of $D$-causation was motivated by the idea that we could reduce a difficult decision problem with a large set $D$ to a simpler problem with a smaller ``effective'' set of decisions by exploiting conditional independence. Even if $\RV{X}$ $D$-causes $\RV{Y}$ in every $\RV{H}\in S$, $\RV{X}$ does not necessarily $D$-cause $\RV{Y}$ in mixtures of states in $S$. For this reason, we do not say that $\RV{X}$ $D$-causes $\RV{Y}$ in $S$ if $\RV{X}$ $D$-causes $\RV{Y}$ in every $\RV{H}\in S$, and in this way we differ substantially from \citet{heckerman_decision-theoretic_1995}.

Instead, we simply extend the definition of $D$-causation to mixtures of hypotheses: if $\gamma\in \Delta(\RV{H})$ is a mixture of hypotheses, define $\kernel{C}_\gamma:= (\gamma\otimes\textbf{Id})\kernel{C}$. Then $\RV{X}$ $D$-causes $\RV{Y}$ relative to $\gamma$ iff $\RV{Y}\CI_{\kernel{C}_\gamma} \RV{D}|\RV{X}$.

Theorem \ref{th:univ_d_causation} shows that under some conditions, $D$-causation can hold for arbitrary mixtures over subsets of the hypothesis class $\RV{H}$.

\begin{theorem}[Universal $D$-causation]\label{th:univ_d_causation}
If $\kernel{C}^{\RV{X}|\RV{D}}_{\RV{H}} = \kernel{C}^{\RV{X}|\RV{D}}_{\RV{H}'}$ for all $\RV{H},\RV{H}'\in S\subset \RV{H}$ and $\RV{X}$ $D$-causes $\RV{Y}$ in all $\RV{H}\in S$, then $\RV{X}$ $D$-causes $\RV{Y}$ with respect to all mixed consequence maps $\kernel{C}_\gamma$ for all $\gamma\in \Delta(\RV{H})$ with $\gamma(S)=1$.
\end{theorem}

\begin{proof}

For $\gamma\in \Delta(\RV{H})$, define the mixture

\begin{align}
\kernel{C}_\gamma := \begin{tikzpicture}
    \path (0,0) node[dist] (g) {$\gamma$}
    + (0,-0.45) node (D) {$\RV{D}$}
    ++ (1,-0.3) node[kernel] (C) {$\kernel{C}$}
    ++ (1,0) node (F) {$\RV{F}$};
    \draw (g) to [out=0,in=180] ($(C.west) + (0,0.15)$) (D) -- ($(C.west) + (0,-0.15)$) (C) -- (F);
\end{tikzpicture}
\end{align}

Because $\kernel{C}_\RV{H}^{\RV{X}|\RV{D}} = \kernel{C}_{\RV{H}'}^{\RV{X}|\RV{D}}$ for all $\RV{H},\RV{H}'\in \RV{H}$, we have

\begin{align}
\begin{tikzpicture}
    \path (0,0) node[dist] (g) {$\gamma$}
    + (0.7,-0.15) node[copymap] (copy0) {}
    + (0,-0.45) node (D) {$\RV{D}$}
    ++ (1.5,-0.3) node[kernel] (C) {$\kernel{C}^{\RV{X}|\RV{D}\RV{H}}$}
    ++ (1,0) node (X) {$\RV{X}$}
    + (0,0.5) node (T) {$\RV{H}$};
    \draw (g) to [out=0,in=180] (copy0) -- ($(C.west) + (0,0.15)$) (D) -- ($(C.west) + (0,-0.15)$);
    \draw (C) -- (X);
    \draw (copy0) to [out=90,in=180] (T);
\end{tikzpicture} &= \begin{tikzpicture}
    \path (0,0) node[dist] (g) {$\gamma$}
    + (0,0.5) node[dist] (g2) {$\gamma$}
    + (0.7,-0.15) node[copymap] (copy0) {}
    + (0,-0.45) node (D) {$\RV{D}$}
    ++ (1.5,-0.3) node[kernel] (C) {$\kernel{C}^{\RV{X}|\RV{D}\RV{H}}$}
    ++ (1,0) node (X) {$\RV{X}$}
    + (0,0.3) node (T) {$\RV{H}$};
    \draw (g) to [out=0,in=180] (copy0) -- ($(C.west) + (0,0.15)$) (D) -- ($(C.west) + (0,-0.15)$);
    \draw (C) -- (X);
    \draw (g2) to [out=0,in=180] (T);
\end{tikzpicture} \label{eq:decompose_condi_x}
\end{align}

Also

\begin{align}
    \kernel{C}_\gamma^{\RV{XY}|\RV{D}} &= \begin{tikzpicture}
    \path (0,0) node[dist] (g) {$\gamma$}
    + (0,-0.45) node (D) {$\RV{D}$}
    ++ (1,-0.3) node[kernel] (C) {$\kernel{C}$}
    ++ (1,0) node[kernel] (F) {$\kernel{F}^{\RV{X}\utimes\RV{Y}}$}
    ++ (1,0.15) node (X) {$\RV{X}$}
    + (0,-0.3) node (Y) {$\RV{Y}$};
    \draw (g) to [out=0,in=180] ($(C.west) + (0,0.15)$) (D) -- ($(C.west) + (0,-0.15)$) (C) -- (F);
    \draw ($(F.east) + (0,0.15)$) -- (X) ($(F.east) + (0,-0.15)$) -- (Y);
\end{tikzpicture}\\
    &= \begin{tikzpicture}
    \path (0,0) node[dist] (g) {$\gamma$}
    + (0,-0.45) node (D) {$\RV{D}$}
    ++ (1,-0.3) node[kernel] (C) {$\kernel{C}^{\RV{XY}|\RV{D}\RV{H}}$}
    ++ (1,0.15) node (X) {$\RV{X}$}
    + (0,-0.3) node (Y) {$\RV{Y}$};
    \draw (g) to [out=0,in=180] ($(C.west) + (0,0.15)$) (D) -- ($(C.west) + (0,-0.15)$);
    \draw ($(C.east) + (0,0.15)$) -- (X) ($(C.east) + (0,-0.15)$) -- (Y);
\end{tikzpicture}\\
 &= \begin{tikzpicture}
    \path (0,0) node[dist] (g) {$\gamma$}
    + (0,-0.45) node (D) {$\RV{D}$}
    + (0.7,-0.45) node[copymap] (copy0) {}
    + (0.7,-0.15) node[copymap] (copy1) {}
    ++ (1.4,-0.3) node[kernel] (C) {$\kernel{C}^{\RV{X}|\RV{D}\RV{H}}$}
    + (0,0.6) coordinate (via0)
    + (0,-0.6) coordinate (via1)
    ++ (0.9,0) node[copymap] (copy2) {}
    ++ (0.7,0) node[kernel] (Yx) {$\kernel{C}^{\RV{Y}|\RV{X}\RV{D}\RV{H}}$}
    ++ (1.2,0.15) node (X) {$\RV{Y}$}
    + (0,-0.5) node (Y) {$\RV{X}$};
    \draw (g) to [out=0,in=180] (copy1) -- ($(C.west) + (0,0.15)$) (D) -- ($(C.west) + (0,-0.15)$) (C)--(Yx);
    \draw (copy0) to [out=-90,in=180] (via1) to [out=0,in=180] ($(Yx.west) + (0,-0.15)$) (copy1) to [out=90,in=180] (via0) to [out=0,in=180] ($(Yx.west) + (0,0.15)$);
    \draw ($(Yx.east) + (0,0.15)$) -- (X) (copy2) to [out=-90,in=180] (Y);
 \end{tikzpicture}\\
 &\overset{\RV{Y}\CI \RV{D}|\RV{X}\RV{H}}{=} \begin{tikzpicture}
    \path (0,0) node[dist] (g) {$\gamma$}
    + (0,-0.45) node (D) {$\RV{D}$}
    + (0.7,-0.15) node[copymap] (copy1) {}
    ++ (1.4,-0.3) node[kernel] (C) {$\kernel{C}^{\RV{X}|\RV{D}\RV{H}}$}
    ++ (0.9,0.1) node[copymap] (copy2) {}
    ++ (0.7,0.3) node[kernel] (Yx) {$\kernel{C}^{\RV{Y}|\RV{X}\RV{H}}$}
    ++ (1.2,0.15) node (X) {$\RV{Y}$}
    + (0,-0.5) node (Y) {$\RV{X}$};
    \draw (g) to [out=0,in=180] (copy1) -- ($(C.west) + (0,0.15)$) (D) -- ($(C.west) + (0,-0.15)$) (C) to [out=0,in=180] (copy2) to [out=0,in=180] (Yx);
    \draw (copy1) to [out=90,in=180] ($(Yx.west) + (0,0.15)$);
    \draw ($(Yx.east) + (0,0.15)$) -- (X) (copy2) to [out=-90,in=180] (Y);
 \end{tikzpicture} \\
 &\overset{\ref{eq:decompose_condi_x}}{=} \begin{tikzpicture}
    \path (0,0) node[dist] (g) {$\gamma$}
    + (0,-0.45) node (D) {$\RV{D}$}
    + (0.7,-0.15) node[copymap] (copy1) {}
    ++ (1.4,-0.3) node[kernel] (C) {$\kernel{C}^{\RV{X}|\RV{D}\RV{H}}$}
    + (1,0.6) node[dist] (g2) {$\gamma$}
    ++ (0.9,0.1) node[copymap] (copy2) {}
    ++ (1,0.3) node[kernel] (Yx) {$\kernel{C}^{\RV{Y}|\RV{X}\RV{H}}$}
    ++ (1.2,0.15) node (X) {$\RV{Y}$}
    + (0,-0.5) node (Y) {$\RV{X}$};
    \draw (g) to [out=0,in=180] (copy1) -- ($(C.west) + (0,0.15)$) (D) -- ($(C.west) + (0,-0.15)$) (C) to [out=0,in=180] (copy2) to [out=0,in=180] (Yx);
    \draw (g2) to [out=0,in=180] ($(Yx.west) + (0,0.15)$);
    \draw ($(Yx.east) + (0,0.15)$) -- (X) (copy2) to [out=-90,in=180] (Y);
 \end{tikzpicture}\\
 &= \overset{\ref{eq:decompose_condi_x}}{=} \begin{tikzpicture}
    \path (0,0) node (g) {}
    + (0,-0.45) node (D) {$\RV{D}$}
    + (0.7,-0.45) node[copymap] (copy1) {}
    ++ (1.4,-0.3) node[kernel] (C) {$\kernel{C}_\gamma^{\RV{X}|\RV{D}\RV{H}}$}
    + (1,0.6) node[dist] (g2) {$\gamma$}
    ++ (0.9,0.1) node[copymap] (copy2) {}
    ++ (1,0.3) node[kernel] (Yx) {$\kernel{C}^{\RV{Y}|\RV{X}\RV{H}}$}
    + (-0.5,0.6) coordinate (stop0)
    ++ (1.2,0.15) node (X) {$\RV{Y}$}
    + (0,-0.5) node (Y) {$\RV{X}$};
    \draw (D) -- ($(C.west) + (0,-0.15)$) (C) to [out=0,in=180] (copy2) to [out=0,in=180] (Yx);
    \draw (g2) to [out=0,in=180] ($(Yx.west) + (0,0.15)$);
    \draw ($(Yx.east) + (0,0.15)$) -- (X) (copy2) to [out=-90,in=180] (Y);
    \draw[-{Rays[n=8]}] (copy1) to [out=90,in=180] (stop0);
 \end{tikzpicture}\label{eq:is_conditional}
\end{align}
Equation \ref{eq:is_conditional} establishes that $(\gamma\otimes\textbf{Id}_X\otimes\stopper{0.3}_D)\kernel{C}^{\RV{Y}|\RV{X}\RV{H}}$ is a version of $\kernel{C}_\gamma^{\RV{Y}|\RV{X}\RV{D}}$, and thus $\RV{Y}\CI_{\kernel{C}_\gamma} \RV{D}|\RV{X}$.

This can also be derived from the semi-graphoid rules:

\begin{align}
    \RV{H}\CI \RV{D} \land \RV{H}\CI \RV{X} | \RV{D} &\implies \RV{H}\CI \RV{XD}\\
    &\implies \RV{H}\CI \RV{D}|\RV{X}\\
    \RV{D} \CI \RV{H}|\RV{X} \land \RV{D}\CI \RV{Y}|\RV{X}\RV{H} &\implies \RV{D}\CI \RV{Y}|\RV{X}\\
    &\implies \RV{Y}\CI\RV{D}|\RV{X}
\end{align}
\end{proof}

\subsection{Properties of D-causation}

If $\RV{X}$ D-causes $\RV{Y}$ relative to $\kernel{C}_\RV{H}$, then the following holds:

\begin{align}
    \kernel{C}_{\RV{H}}^{\RV{X}|\RV{D}} &= \begin{tikzpicture}
    \path (0,0) node (D) {$\RV{D}$}
    ++ (0.9,0) node[kernel] (Xd) {$\kernel{C}^{\RV{X}|\RV{D}}$}
    ++ (1.3,0) node[kernel] (Yd) {$\kernel{C}^{\RV{Y}|\RV{X}}$}
    ++ (0.9,0) node (Y) {$\RV{Y}$};
    \draw (D) -- (Xd) -- (Yd) -- (Y); 
    \end{tikzpicture}
\end{align}

This follows from version (2) of Definition \ref{def:conditional_independence}:

\begin{align}
    \kernel{C}_\RV{H}^{\RV{X}|\RV{D}} &= \begin{tikzpicture}
    \path (0,0) node (D) {$\RV{D}$}
    ++ (0.7,0) node[copymap] (copy0) {}
    ++ (0.7,0) node[kernel] (Xd) {$\kernel{C}^{\RV{X}|\RV{D}}$}
    + (0,0.5) coordinate (via1)
    ++ (1.3,0) node[kernel] (Yd) {$\kernel{C}^{\RV{Y}|\RV{X}\RV{D}}$}
    ++ (0.9,0) node (Y) {$\RV{Y}$};
    \draw (D) -- (Xd) -- (Yd) -- (Y);
    \draw (copy0) to [out=90,in=180] (via1) to [out=0,in=180] ($(Yd.west)+(0,0.15)$); 
    \end{tikzpicture}\\
     &= \begin{tikzpicture}
    \path (0,0) node (D) {$\RV{D}$}
    ++ (0.7,0) node[copymap] (copy0) {}
    ++ (0.7,0) node[kernel] (Xd) {$\kernel{C}^{\RV{X}|\RV{D}}$}
    + (1.3,0.5) coordinate (via1)
    ++ (1.3,0) node[kernel] (Yd) {$\kernel{C}^{\RV{Y}|\RV{X}}$}
    ++ (0.9,0) node (Y) {$\RV{Y}$};
    \draw (D) -- (Xd) -- (Yd) -- (Y);
    \draw[-{Rays[n=8]}] (copy0) to [out=90,in=180] (via1); 
    \end{tikzpicture}\\
    &= \begin{tikzpicture}
    \path (0,0) node (D) {$\RV{D}$}
    ++ (0.9,0) node[kernel] (Xd) {$\kernel{C}^{\RV{X}|\RV{D}}$}
    ++ (1.3,0) node[kernel] (Yd) {$\kernel{C}^{\RV{Y}|\RV{X}}$}
    ++ (0.9,0) node (Y) {$\RV{Y}$};
    \draw (D) -- (Xd) -- (Yd) -- (Y); 
    \end{tikzpicture}
\end{align}

D-causation is not transitive: if $\RV{X}$ D-causes $\RV{Y}$ and $\RV{Y}$ D-causes $\RV{Z}$ then $\RV{X}$ doesn't necessarily D-cause $\RV{Z}$.

%!TEX root = main.tex

\chapter{Chapter 3: Two player statistical models and see-do models}

\todo[inline]{These are ``todo'' notes. All such notes that involve theoretical development are also collected in an unordered list of outstanding theoretical questions}

\todo[inline]{The basic claim of this chapter is that see-do models are the basic type of thing that everyone who is studying ``causal inference'' is working with, even if they don't know it themselves}

In this chapter I introduce two types of model. Models of the first type are called \emph{two player statistical models} and the second type are a special class of the first called \emph{see-do models}. Fundamentally, each of these is just a particular kind of stochastic function. The reason we are interested in these kinds of stochastic functions is that is that almost all causal models are instances of see-do models. Before introducing two player models and discussing what makes them causal, it is worth briefly considering models in statistics and machine learning generally.

A \emph{world model} is something I will informally define as a family of ``descriptions'' indexed by hypotheses $\{R_h|h\in H\}$. The set $H$ represents hypotheses or proposals for how the world ought to be described, and each proposal $h\in H$ entails some description of the world $\prob{R}_h$. Some examples of world models:

\begin{itemize}
    \item A linear regressor may take some data $\mathbf{x}$ and $\mathbf{y}$ and returns a parameter $\beta\in B$ with the property that $(\mathbf{y}-\mathbf{x}^T \beta)^2$ is small. A normal way to interpret the parameter $\beta$ is to consider it to be a proposal about how some phenomenon of interest should be described, with this description explicitly given by the function $f:x\mapsto \beta x$.
    \item A neural network used in classification may take data $\mathbf{x}$ and labels $\mathbf{y}$ and returns parameters $\mathbf{w}\in W$ with the property that $-\mathbf{y} \log \mathbf{x}+(1-y)\log(1-\mathbf{x})$ is small. Each $\mathbf{w}$ is a proposal for how to classify data and the classification rule associated with each $\mathbf{w}$ is a function $x\mapsto f(\mathbf{w},x)$.
    \item A crude description of a general election pre-poll result can be given by the ``true fraction'' $\theta$ of voters for each candidate and, under some unreasonably strong sampling assumptions, and the results of the survey for each $\theta$ can be described by $\prod_N\prob{P}_\theta^\RV{X}$ where $N$ is the number of voters surveyed and $\RV{X}$ is the vote choice of each.
\end{itemize}

In the first two examples the ``description'' that goes with each hypothesis is a function, while in the third example the descriptions are probability measures. In almost all practical cases, these descriptions of the world do not tell us exactly how the world will turn out under each hypothesis, but at best offer us a prediction that is as good as we can hope for. Probability is the tool that is very widely used to formalise such ``descriptions with uncertainty''. Say I have two different linear regressors: one which minimises squared error on the training data and one that always returns $\beta=10$. I want to ask which one produces descriptions that are more fit for my purpose. It is pointless to ask which one is correct because, in general, I cannot know that either will offer a description that is even approximately correct. However, I can consider a second level world model $\{\prob{P}^{\RV{X}\RV{Y}}_\alpha|\alpha\in A\}$ in which the phenomenon of interest is described by a family of probability measures, and then I can ask, given an $\alpha$, which $\beta$ is my regressor likely to return and how closely will $x\mapsto \beta x$ be to $\mathbb{E}_{\prob{P}_\alpha}[\RV{Y}|\RV{X}]$ for each likely choice. Generally, if I need to model a world with uncertainty I will need a world model that is an indexed family of probability measures.

A world model that consists of a family of probability measures $\{\prob{P}_h|h\in H\}$ is a \emph{statistical model} or \emph{statistical experiment}. Because I almost always need to Statistical models can be found everywhere in theoretical statistics and machine learning \cite{fisher_statistical_1992,le_cam_comparison_1996,freedman_asymptotic_1963,de_finetti_foresight_1992,vapnik_nature_2013,wald_statistical_1950}. A key point about statistical models -- even if I can only state it somewhat vaguely -- is that the truth of any hypothesis $h\in H$ has no dependence on what I might want to be true. As a user of statistical models, I have no authority to choose a hypothesis -- this is Nature's choice alone. 

I can sometimes make choices that will affect the way that the future turns out. I might have some set $D$ of choices I can make, and for each $d\in D$ I require a description of the results of my choice. Just as the results of hypotheses are often uncertain, so are the results of choices. I might be motivated to choose a probability measure $\prob{P}_d$ to describe them, maybe because it is common to do so or because I find arguments for subjective expected utility theory compelling \citep{steele_decision_2020}. A family of probability measures indexed by a set of choices $\{\prob{P}_d|d\in D\}$ will be called a \emph{consequence model}.

Statistical models and consequence models are both families of probability measures indexed by arbitrary sets, which we have called hypotheses $H$ and choices $D$ respectively. Their general types are the same, and the only difference is in the interpretation of the sets $H$ and $D$. The difference can be informally summarised in this manner: I do not get to tell Nature what choice $h\in H$ she makes, and Nature does not get to tell me what choice $d\in D$ I make. It will often be the case that I have multiple choices that can affect how the world turns out \emph{and} I have multiple hypotheses about how each choice will affect the world. In this case, I will have a \emph{two-player statistical model} $\{\prob{P}_{h,d}|h\in H,d\in D\}$. 

So far I have explained the distinction between ``player 1'' and ``player 2'' in vague metaphorical terms. If I am using a two-player statistical model in the context of a well defined problem such as ``given data, what choice should I make?'' then we can say precisely what $H$ and $D$ are and what role each plays in the problem. However, the field of causal inference includes other types of problem so-called counterfactual problems which involve a choice set $D$ that plays a different role to the choice set in decision problems. Thus, while I will argue that causal models are two-player statistical models, and the second player is what distinguishes them from ordinary statistical models, the same kind of model can be used with different interpretations of what the second player's choices represent.

Decision problems involving often involve some data $\RV{X}$ is observed, then a choice is made, then the consequences $\RV{Y}$ are observed. In such a model, the observed data $\RV{X}$ cannot be affected by the choice. These models will be called \emph{see-do} models to capture the assumption that there is an order in which seeing and doing happen.

In this chapter I will introduce two-player statistical models with a focus on how they relate to ordinary statistics, while in the next chapter I will explore the zoo of causal modelling approaches and the types of two player models associated with each.

\section{Two player statistical models and see-do models}

Two player statistical models were introduced as doubly indexed sets of probability measures $\{\prob{P}_{h,d}|h\in H,d\in D\}$. If each $\prob{P}_{h,d}\in \Delta(\sigalg{E})$ for some measurable space $(E,\sigalg{E})$, the indexed set is equivalent to a function $H\times D\to \Delta(\sigalg{E})$. In the following work, we will make two simplifying assumptions:

\begin{enumerate}
    \item A two player statistical model can be represented by a \emph{Markov kernel} $\kernel{T}:H\times D\to \Delta(\sigalg{E})$
    \item The kernel space $(\kernel{T},(H\times D,\sigalg{H}\otimes\sigalg{D}),(E,\sigalg{E}))$ admits disintegrations $\kernel{T}^{\RV{Y}|\RV{XDH}}$ for arbitrary random variables $\RV{X},\RV{Y}$ on $H\times D\times E$ and domain variable $\RV{D}\utimes\RV{H}$
\end{enumerate}

The first condition amounts to the additional requirement that $(h,d)\mapsto \kernel{T}_{h,d}(A)$ is measurable for every $A\in \sigalg{H}\otimes\sigalg{D}\otimes\sigalg{E}$, and sufficient for the second condition is that $D\times H$ is countable and $X\times Y$ standard measurable (though this is not necessary, see Theorem \ref{th:existence_continous}).

\begin{definition}[Two player statistical model]\label{def:2p_stat}
A \emph{two-player statistical model} is a Markov kernel $\kernel{T}:H\times D\to \Delta(\sigalg{E})$ such that, for any random variables $\RV{X}: H\times D\times E\to X$ and $\RV{Y}:H\times D\times E\to Y$, a disintegration $\kernel{K}^{\RV{Y}|\RV{XDH}}:X\times D\times H\to \Delta(\sigalg{Y})$ exists. Every two player statistical model has two distinguished random variables: the \emph{hypothesis} $\RV{H}:H\times D\times E\to H$ given by $(h,d,e)\mapsto h$ and the \emph{choice} $\RV{D}:H\times D\times E\to D$ given by $(h,d,e)\mapsto d$.
\end{definition}

\begin{definition}[See-Do model]\label{def:seedo}
A \emph{see-do model} is a two-player statistical model $\kernel{T}:H\times D\to \Delta(\sigalg{E})$ with two additional distinguished random variables: the \emph{observation} $\RV{X}: H\times D\times E\to X$ and the \emph{consequence} $\RV{Y}:H\times D\times E\to Y$. A see-do model must observe the conditional independence $\RV{X}\CI_\kernel{T} \RV{D}|\RV{H}$, i.e. the observation is independent of the choice conditional on the hypothesis.
\end{definition}

\subsection{Decomposability}

Decomposability is a property of see-do models that is relevant to the distinction between counterfacutal and regular models. As we will show, many causal problems allow the use of decomposable see-do models. However, certain types of counterfactual problem do not.

\begin{definition}[decomposability]\label{def:decomposability}
A see-do model $\kernel{T}:H\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$ is \emph{decomposable} iff $\RV{Y}\CI_\kernel{T} \RV{X}|\RV{D}\RV{H}$. That is, if the consequence is independent of the observations given the hypothesis and the choice.
\end{definition}

Decomposable see-do models can be represented as a pair $(\kernel{O},\kernel{C})$ where $\kernel{O}$ is a one-player statistical model we call the \emph{observation model} and $\kernel{C}$ is a two-player statistical model we call the \emph{consequence model} (Corollary \ref{corr:decomp_representation}. Most models in the causal inference literature are decomposable -- if the observed data can tell us nothing useful beyond the distribution of observations, then we have a decomposable model.

\begin{theorem}[Observation and Consequence models]\label{th:obs_cmaps}
Any see-do model $(\kernel{T},\RV{H},\RV{D},\RV{X},\RV{Y})$ can be uniquely represented by the following pair of Markov kernels:
\begin{itemize}
    \item The \emph{observation model} $\kernel{T}^{\RV{X}|\RV{H}}$
    \item The \emph{context-sensitive consequence model} $\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$
\end{itemize}

Furthermore
\begin{align}
\kernel{T} = \begin{tikzpicture} \path (0,0) node (T) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        + (0.,-1.15) node[copymap] (copy2) {}
        ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
        ++ (0.7,0) node[copymap] (copy1) {}
        +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
        ++ (1.9,0) node (X) {$\RV{X}$}
        +  (0,-1) node (Y) {$\RV{Y}$}
        + (0,0.5) node (H) {$\RV{H}$}
        + (0,-1.5) node (D2) {$\RV{D}$};
        \draw (T) -- (O) -- (X);
        \draw (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
        \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
        \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
        \draw (C) -- (Y);
        \draw (copy0) to [out = 65, in = 180] (H);
        \draw (copy2) to [out = -65, in = 180] (D2);
    \end{tikzpicture}
\end{align}
\end{theorem}

\todo[inline]{Maybe moves proofs out of main text}

\begin{proof}
By \ref{th:representaiton}, 

\begin{align}
\kernel{T} = \begin{tikzpicture} \path (0,0) node (T) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        + (0.,-1.15) node[copymap] (copy2) {}
        ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}\RV{D}}$}
        ++ (0.7,0) node[copymap] (copy1) {}
        +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
        ++ (1.9,0) node (X) {$\RV{X}$}
        +  (0,-1) node (Y) {$\RV{Y}$}
        + (0,0.5) node (H) {$\RV{H}$}
        + (0,-1.5) node (D2) {$\RV{D}$};
        \draw (T) -- (O) -- (X);
        \draw[name path=P1] (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
        \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
        \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
        \draw (C) -- (Y);
        \draw (copy0) to [out = 65, in = 180] (H);
        \draw (copy2) to [out = -65, in = 180] (D2);
        \draw[name path=P2] (copy2) to [out = 65, in = 180] ($(O.west)+(0,-0.15)$);
    \end{tikzpicture}
\end{align}


By the assumption $\RV{X}\CI_{\kernel{T}} \RV{D}|\RV{H}$ and version 2 of conditional independence from Theorem \ref{th:ci_equivalence},

\begin{align}
\kernel{T} &= \begin{tikzpicture} \path (0,0) node (T) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        + (0.,-1.15) node[copymap] (copy2) {}
        ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
        ++ (0.7,0) node[copymap] (copy1) {}
        +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
        ++ (1.9,0) node (X) {$\RV{X}$}
        +  (0,-1) node (Y) {$\RV{Y}$}
        + (0,0.5) node (H) {$\RV{H}$}
        + (0,-1.5) node (D2) {$\RV{D}$};
        \draw (T) -- (O) -- (X);
        \draw (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
        \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
        \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
        \draw (C) -- (Y);
        \draw (copy0) to [out = 65, in = 180] (H);
        \draw (copy2) to [out = -65, in = 180] (D2);
        \draw[-{Rays[n=8]}] (copy2) to [out = 65, in = 180] ($(O.west)+(-0.2,-0.5)$);
    \end{tikzpicture}\\
    &= \begin{tikzpicture} \path (0,0) node (T) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        + (0.,-1.15) node[copymap] (copy2) {}
        ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
        ++ (0.7,0) node[copymap] (copy1) {}
        +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
        ++ (1.9,0) node (X) {$\RV{X}$}
        +  (0,-1) node (Y) {$\RV{Y}$}
        + (0,0.5) node (H) {$\RV{H}$}
        + (0,-1.5) node (D2) {$\RV{D}$};
        \draw (T) -- (O) -- (X);
        \draw (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
        \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
        \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
        \draw (C) -- (Y);
        \draw (copy0) to [out = 65, in = 180] (H);
        \draw (copy2) to [out = -65, in = 180] (D2);
    \end{tikzpicture}
\end{align}

\end{proof}

\begin{corollary}\label{corr:decomp_representation}
A decomposable see-do model $\kernel{T}:H\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$ can be uniquely represented by
\begin{itemize}
    \item The \emph{observation model} $\kernel{T}^{\RV{X}|\RV{H}}$
    \item The \emph{consequence model} $\kernel{T}^{\RV{Y}|\RV{H}\RV{D}}$
\end{itemize}
\end{corollary}

\begin{proof}
Because $\kernel{T}$ is decomposable, $\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}= \stopper{0.2}_X\otimes \kernel{T}^{\RV{Y}|\RV{H}\RV{D}}$. Then by theorem \ref{th:representaiton} we have a unique representation of $\kernel{T}$.
\end{proof}

\subsubsection{Examples of decomposable and indecomposable see-do models}

Recall the previous example: suppose we are betting on the outcome of the flip of a possibly biased coin with payout 1 for a correct guess and 0 for an incorrect guess, and we are given $N$ previous flips of the coin to inspect. This situation can be modeled by a decomposable see-do model. Define $\kernel{B}:(0,1)\to \Delta(\{0,1\})$ by $\kernel{B}:\RV{H}\mapsto \mathrm{Bernoulli}(\RV{H})$. Then define $\prescript{1}{}{\kernel{T}}$ by:

\begin{itemize}
    \item $D=\{0,1\}$
    \item $X=\{0,1\}^N$
    \item $Y=\{0,1\}$
    \item $H=(0,1)$
    \item $\prescript{1}{}{\kernel{O}}:\splitter{0.1}^N\kernel{B}$
    \item $\prescript{1}{}{\kernel{C}}:(h,d)\mapsto \mathrm{Bernoulli}(1-|d-h|)$
\end{itemize}

In this model, the chance $\RV{H}$ of the coin landing on heads is as much as we can hope to know about how our bet will work out.

Suppose instead that in addition to the $N$ prior flips, we manage to look at the outcome of the flip on which we will bet. In this case, the situation can be modeled by the following indecomposable see-do model $\prescript{2}{}{\kernel{T}}$:

\begin{itemize}
    \item $D=\{0,1\}$
    \item $X=\{0,1\}^{N+1}$
    \item $Y=\{0,1\}$
    \item $H=(0,1)$
    \item $\prescript{2}{}{\kernel{T}}^{\RV{X}|\RV{H}}:\splitter{0.1}^{N+1}\kernel{B}$
    \item $\prescript{2}{}{\kernel{T}}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}:(h,\mathbf{x},d)\mapsto \delta_{1-|d-x_{N+1}|}$
\end{itemize}

In this case, even if we are told the value of $\RV{H}$, we still benefit from using the observed data when making our decision.

It is possible to model the second situation with a decomposable model by including the result of the $N+1$th flip in the hypothesis. Define the new hypothesis space $H'=H\times\{0,1\}$ and let $\RV{H}_0$ be the projection to the old hypothesis space $H$. Define $\prescript{3}{}{\kernel{T}}$ by:

\begin{itemize}
    \item $D=\{0,1\}$
    \item $X=\{0,1\}^{N+1}$
    \item $Y=\{0,1\}$
    \item $H'=(0,1)\times\{0,1\}$
    \item $\prescript{3}{}{\kernel{O}}:(\splitter{0.1}^N\kernel{B}\otimes \delta_{x_{N+1}}$
    \item $\prescript{3}{}{\kernel{C}}:(h,x_{N+1},d)\mapsto \delta_{1-|d-x_{N+1}|}$
\end{itemize}

However, $\prescript{2}{}{\kernel{T}}^{\RV{X}_{N+1}|\RV{H}} = \kernel{B}$ while $\prescript{3}{}{\kernel{T}}^{\RV{X}_{N+1}|\RV{H}_0}$ is undefined, so $\prescript{3}{}{\kernel{T}}$ is a substantially different model to $\prescript{2}{}{\kernel{T}}$.

If a see-do model is employed in a \emph{decision problem} -- defined later -- it is possible to recover decomposability in the sense that we can take an indecomposable model construct a decomposable model that is identical given an identification of the random variables in each.

\subsubsection{Exchangeability}

The starting point for two-player statistical models was one player statistical models. This was justified by the observation that statistical models are already widely accepted and by some informal arguments about the need to incorporate uncertainty. There are a number of ``representation theorems'' in the literature 

We can consider the hypothesis class in a one or two player statistical model to be an element of the prior knowledge we have to bring to the problem. An alternative view set out by \citet{de_finetti_foresight_1992} is that the hypothesis class

One justification for using statistical models -- by which I mean maps of the type $\kernel{O}:H\to \Delta(\sigalg{X})$ -- is to suppose that we simply have as prior knowledge a set of hypotheses and the fact that for each hypothesis, repeating our observations a large number of times in the appropriate way will yield a sequence that is described by the probability distribution we associate with that hypothesis. An alternative view, set out by \citet{de_finetti_foresight_1992}, is to treat random variables as predictions of uncertain events rather than properties of repeated observations of the system under observation. De Finetti's representation theorem shows that, starting from the assumption of \emph{exchangeability} (informally: indifference to the order in which observations arrive), the predictive model of future observations can be represented by the product of a \emph{prior} and a \emph{conditionally independent and identically distributed statistical model}.

In see-do models, exchangeability of observations additionally implies that the model is decomposable. In addition, I argue that a generalisation of exchangeability I call \emph{functional exchangeability} is a natural assumption to make when modelling counterfacutal suppositions.

\begin{definition}[Exchangeability]
Given $A\subseteq \mathbb{N}$, a sequence of random variables $\RV{X}_A:=\utimes_{i\in A} \RV{X}_i$ each taking values in $X$ on a probability space $(\prob{P},(\Omega,\sigalg{F}))$ is \emph{exchangeable} if for all $n\in A$, all permutations of indices $\sigma:[n]\to[n]$ and all  $B \in\sigalg{F}$, $\prob{P}^{\RV{X}_{[n]}}(B) =\prob{P}^{\RV{X}_{\sigma([n])}}(B)$.

\todo[inline]{Define infinite coupled copymaps WRT kolmogorov extension theorem}
\end{definition}

\subsection{Causal questions and decision functions}

\citet{pearl_book_2018} has proposed three types of causal question:
\begin{enumerate}
    \item Association: How are $\RV{W}$ and $\RV{Z}$ related? How would observing $\RV{W}$ change my beliefs about $\RV{Z}$?
    \item Intervention: What would happen if I do ... ? How can I make ... happen?
    \item Counterfactual: What if I had done ... instead of what I actually did?
\end{enumerate}

\emph{Causal decision problems} are, roughly speaking, ``interventional'' problems. In English, a causal decision problem roughly asks

\begin{quote}
    Given that I have data $\RV{X}$ and I know which values of $\RV{Y}$ I would like to see and some knowledge about how the world works, which of my available choices $D$ should I select?
\end{quote}

This type of question presupposes somewhat more than Pearl's prototypical interventional questions. First, it supposes that we have \emph{preferences} over the values that $\RV{Y}$ might take, which we need not have to answer the question ``What would happen if I do ...?''. Secondly, and crucially to our theory, causal decision problem suppose that we are given data and a set of choices. 

We will return to the question of preferences. For now, we will focus on the idea that a causal decision problem is about selecting a choice given data. That is, however the selection is made, the answer to a causal decision problem is always a \emph{decision function} $\kernel{D}:X\to \Delta(\sigalg{D})$.

A property that will be of interest when considering counterfactual models is \emph{decomposability}. A see-do model 



\begin{definition}[Consequence map]
Given a see-do model $(\kernel{T},\RV{H},\RV{D},\RV{X},\RV{Y})$, a \emph{consequence map} is a map $\kernel{C}:D\to \Delta(\sigalg{Y})$ where $D$ is a choice set and $Y$ is a consequence set.

The consequence model evaluated at any particular hypothesis $h\in H$, $\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}_{\cdot,h,\cdot}$ is a consequence map.
\end{definition}

\todo[inline]{Not quite sure if this is the right place for the following definition}

The independence of observations and choices is preserved when we take the product of a see-do model and a \emph{prior} over hypotheses. Such a product produces a \emph{Bayesian see-do model}:

\begin{definition}[Bayesian See-Do Model]
A Bayesian See-Do Model $\langle\kernel{U},\RV{D},\RV{X},\RV{Y}\rangle$ is a Markov kernel space $(\kernel{U},D,X\times Y)$ with the property $\RV{X}\CI_{\kernel{U}}\RV{D}$, along with choices $\RV{D}$, observations $\RV{X}$ and consequences $\RV{Y}$, defined as before.
\end{definition}

\begin{theorem}[A see-do model with a prior is a Bayesian see-do model]
The product of a see-do model $\kernel{T}$ and a prior $\gamma\in \Delta(\sigalg{H})$
\begin{align}
    \kernel{U} &:= (\gamma\otimes \mathrm{Id}^D)\kernel{T}
\end{align}
Is a Bayesian see-do model.
\end{theorem}

\todo[inline]{Maybe moves proofs out of main text}

\begin{proof}

It nees to be shown that $\RV{X}\CI_{\kernel{U}}\RV{D}$.

By definition
\begin{align}
\kernel{U}^{\RV{X}|\RV{D}} &= \kernel{U}\kernel{F}^{\RV{X}}\\
                            &= (\gamma\otimes \mathrm{Id}^D)\kernel{T}\kernel{F}^{\RV{X}}\\
                            &= \begin{tikzpicture} \path (0,0) node[dist] (T) {$\gamma$}
                                    + (0,-1.15) node (D) {$\RV{D}$}
                                    ++ (0.5,0) node[copymap] (copy0) {}
                                    + (0.,-1.15) node[copymap] (copy2) {}
                                    ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
                                    ++ (0.7,0) node[copymap] (copy1) {}
                                    +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
                                    ++ (1.9,0) node (X) {$\RV{X}$}
                                    +  (0,-1) node (Y) {};
                                    \draw (T) -- (O) -- (X);
                                    \draw (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
                                    \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
                                    \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
                                    \draw[-{Rays[n=8]}] (C) -- (Y);
                                \end{tikzpicture}\\
                            &= \begin{tikzpicture} \path (0,0) node[dist] (T) {$\gamma$}
                                    + (0,-1.15) node (D) {$\RV{D}$}
                                    ++ (0.5,0) coordinate (copy0)
                                    ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
                                    ++ (0.7,0) coordinate (copy1)
                                    ++ (1.9,0) node (X) {$\RV{X}$}
                                    +  (0,-1) node (Y) {};
                                    \draw (T) -- (O) -- (X);
                                    \draw[-{Rays[n=8]}] (D) -- (Y);
                                \end{tikzpicture}
\end{align}

Which implies $\RV{X}\CI_{\kernel{U}} \RV{D}$ by version (2) of conditional indpendence (Theorem \ref{th:ci_equivalence}).
\end{proof}
% Decisions are similar to the ``regime indicators'' found in \citet{dawid_decision-theoretic_2020}. They coincide precisely if we suppose that the observation and consequence spaces coincide ($X=Y$) and there exists an ``idle'' decision $d^*\in D$ such that $\kernel{C}_{(\cdot,d^*)} = \kernel{O}_{\cdot}$. However, in general we don't require that $\kernel{O}$ and $\kernel{C}$ are related in this manner. This assumption will be revisited in \todo[inline]{A section I haven't written yet}.

\subsubsection{Example}

Suppose we are betting on the outcome of the flip of a possibly biased coin with payout 1 for a correct guess and 0 for an incorrect guess, and we are given $N$ previous flips of the coin to inspect. This situation can be modeled by a decomposable see-do model. Define $\kernel{B}:(0,1)\to \Delta(\{0,1\})$ by $\kernel{B}:\RV{H}\mapsto \mathrm{Bernoulli}(\RV{H})$. Then define ${\kernel{T}}$ by:

\begin{itemize}
    \item Choice set: $D=\{0,1\}$
    \item Observation set: $X=\{0,1\}^N$
    \item Consequence set: $Y=\{0,1\}$
    \item Hypothesis set: $H=(0,1)$
    \item Observation map: ${\kernel{T}}^{\RV{X}|\RV{H}}:\splitter{0.1}^N\kernel{B}$
    \item Consequence model: ${\kernel{T}}^{\RV{Y}|\RV{D}\RV{H}}:(h,d)\mapsto \mathrm{Bernoulli}(1-|d-h|)$
\end{itemize}

In this model, the chance $\RV{H}$ of the coin landing on heads is as much as we can hope to know about the success of our bet. $\RV{H}$ may be inferred from observation by some standard method, and 



\subsubsection{Avoiding indecomposability with decision functions}

\todo[inline]{Show that a decision problem with a indecomposable model induces an equivalent decision problem with a decomposable model with an expanded set of choices, subject to some conditions.}

\subsubsection{Decision rules}

See-do models encode the relationship between observed data and consequences of decisions. In order to actually make decisions, we also require preferences over consequences. We suppose that a \emph{utility function} is given, and evaluate the desirability of consequences using \emph{expected utility}. A see-do model along with a utility allows us to evaluate the desirability of \emph{decisions rules} according to each hypothesis.

\begin{definition}[Utility function]
Given a See-Do Model $\kernel{T}:\RV{H}\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$, a \emph{utility function} $u$ is a measurable function $Y\to \mathbb{R}$. 
\end{definition}

\begin{definition}[Expected utility]
Given a utility function $u:Y\to \mathbb{R}$ and probability measures $\mu,\nu\in \Delta(\sigalg{Y})$, the \emph{expected utility} of $\mu$ is $\mathbb{E}_{\mu}[u]$.

$\mu$ is \emph{preferred} to $\nu$ if $\mathbb{E}_{\mu}[u]\geq \mathbb{E}_{\nu}[u]$, and \emph{strictly preferred} if $\mathbb{E}_{\mu}[u]>\mathbb{E}_{\nu}[u]$.
\end{definition}

\begin{definition}[Decision rule]
Given a see-to map $\kernel{T}:\RV{H}\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$, a \emph{decision rule} is a Markov kernel $X\to \Delta(\sigalg{D})$. A \emph{deterministic decision rule} is a decision rule that is deterministic.

\todo[inline]{Define deterministic Markov kernels}
\end{definition}

Expected utility together with a decision rule gives rise to the definition of \emph{risk}, which connects CSDT to classical statistical decision theory (SDT). For historical reasons, risks are minimised while utilities are maximised.

\begin{definition}[Risk]
Given a see-to map $\kernel{T}:\RV{H}\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$, a utility $u:Y\to \mathbb{R}$ and the set of decision rules $\mathscr{U}$, the \emph{risk} is a function $l:\RV{H}\times \mathscr{U}\to \mathbb{R}$ given by

\begin{align}
    R(\RV{H},\kernel{U}) := - \int_X  \kernel{U}_x \kernel{T}^{\RV{Y}|\RV{D}\RV{X}\RV{H}}_{\cdot,x,\RV{H}} u d\kernel{T}^{\RV{X}|\RV{H}}_\RV{H}(x)
\end{align}

for $\RV{H}\in \RV{H}$, $\kernel{U}\in \mathscr{U}$. Here $\kernel{U}_x \kernel{T}^{\RV{Y}|\RV{D}\RV{X}\RV{H}}_{\cdot,x,\RV{H}} u$ is the product of the measure $\kernel{U}_x$, the kernel $\kernel{T}^{\RV{Y}|\RV{D}\RV{X}\RV{H}}_{\cdot,x,\RV{H}}:D\to \Delta(\sigalg{Y})$ and the function $u$.
\end{definition}

The loss induces a partial order on decision rules. If for all $\RV{H}$, $l(\RV{H},\kernel{U})\leq l(\RV{H},\kernel{U}')$ then $\kernel{U}$ is at least as good as $\kernel{U}'$. If, furthermore, there is some $\RV{H}_0$ such that $l(\RV{H}_0,\kernel{U})<l(\RV{H}_0,\kernel{U}')$ then $\kernel{U}$ is preferred to $\kernel{U}'$.

\begin{definition}[Induced statistical decision problem]
A see-do model $\kernel{T}:\RV{H}\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$ along with a utility $u$ induces the \emph{statistical decision problem} $(\RV{H},\mathscr{U},R)$ with states $\RV{H}$, decisions $\mathscr{U}$ and risks $R$.

\todo[inline]{Statistical decision problems usually define the risk via the loss, but it is only possible to define a loss with a decomposable model. We don't actually need a loss, though: the complete class theorem still holds via the induced risk and Bayes risk}

\end{definition}


\section{Existence of counterfactuals}

\todo[inline]{I'm struggling with how to explain this well.}

``Counterfactual'' or ``potential outcomes'' models in the causal inference literature are consequence models where choices can be considered in \emph{parallel}. 

Before defining parallel choices, we will consider a ``counterfactual model'' without parallel choices. Consider the following definitions, first from \citet{pearl_causality:_2009} pg. 203-204. I have preserved his notation, including not using any special fonts for things called ``variables'' because this term is used interchangeably with ``sets of variables'' and using special fonts for variables might give the impression that these should be treated as different things while using special fonts for sets of variables is inconsistent with my usual notation.

\todo[inline]{The real solution here is that Pearl's ``variable sets'' are actually ``coupled variables'', see Definition \ref{def:ctensor}, but I'd rather not change his definitions if I can avoid it}

\todo[inline]{put the following inside a quote environment somehow, the regular quote environment fails due to too much markup}
\vspace{1cm}

```
\paragraph{Definition 7.1.1 (Causal Model)}
A causal model is a triple
$M = \langle U, V, F\rangle$,
where:
\begin{enumerate}[label=(\roman*)]
    \item $U$ is a set of \emph{background} variables, (also called \emph{exogenous}), that are determined by factors outside the model;
    \item $V$ is a set $\{V_1 , V_2 ,..., V_n\}$ of variables, called \emph{endogenous}, that are determined by variables in the model -- that is, variables in $U\cup V$;
    \item $F$ is a set of functions $\{f_1 , f_2 ,..., f_n\}$ such that each $f_i$ is a mapping from (the respective domains of) $U_i \cup PA_i$ to $V_i$, where $U i \subseteq U$ and $PA_i \subseteq V \setminus V_i$ and the entire set $F$ forms a mapping from $U$ to $V$. In other words, each $f_i$ in $$v_i = f_i (pa_i , u_i ),\qquad  i\in 1, ... n,$$ assigns a value to $V_i$ that depends on (the values of) a select set of variables in $V \cup U$, and the entire set $F$ has a unique solution $V(u)$.
\end{enumerate}

\paragraph{Definition 7.1.2 (Submodel)}
Let $M$ be a causal model, $X$ a set of variables in $V$, and $x$ a particular realization of $X$. A submodel $M_x$ of $M$ is the causal model $$M_x =\{U, V, F_x\},$$ where $$F_x = \{ f_i : V_i \notin X\}\cup\{ X = x\}.$$

\paragraph{Definition 7.1.3 (Effect of Action)}
Let $M$ be a causal model, $X$ a set of variables in $V$, and $x$ a particular realization of $X$. The effect of action $do(X=x)$ on $M$ is given by the submodel $M_x$

\paragraph{Definition 7.1.4 (Potential Response)}
Let $X$ and $Y$ be two subsets of variables in $V$. The potential response of $Y$ to action $do(X = x)$, denoted $Y_x(u)$, is the solution for $Y$ of the set of equations $F_x$, that is, $Y_x(u) = Y_{M_x}(u)$.

\paragraph{Definition 7.1.6 (Probabilistic Causal Model)}
A probabilistic causal model is a pair $\langle M, P(u)\rangle$, where $M$ is a causal model and $P(u)$ is a probability function defined over the domain of U.
'''


\vspace{1cm}

Implicitly, Definition 7.1.3 proposes a set of ``actions'' that have ``effects'' given by $M_x$. It's not entirely clear what this set of actions should be -- the definition seems to suggest that there is an action for each ``realization'' of each variable in $V$, which would imply that the set of actions corresponds to the range of $V$. For the following discussion, we will call the set of actions $D$, whatever it actually contains (we have deliberately chosen to use the same letter as we use to represent choices or actions in see-do models).

Given $D$, Definition 7.1.3 appears to define a function $h:\mathscr{M}\times D\to \mathscr{M}$, where $\mathscr{M}$ is the space of causal models with background variables $U$ and endogenous variables $V$, such that for $M\in \mathscr{M}$, $do(X=x)\in D$, $h(M,do(X=x))=M_x$.

Definition 7.1.4 then appears to define a function $Y_\cdot(\cdot):D\times U\to Y$ (distinct from $Y$, which appears to be a function $U\to\text{something}$) and calls $Y_\cdot(\cdot)$ the ``potential response''. We could always consider the variable $\RV{V}:=\utimes_{i\in [n]} \RV{V}_i$ and define the ``total potential response'' $\mathbf{g}:=\RV{V}_\cdot(\cdot)$, which captures the potential responses of any subset of variables in $V$.

From this, we might surmise that in the Pearlean view, it is necessary that a ``counterfactual'' or ``potential response'' model has a probability measure $P$ on background variables $U$, a set of actions $D$ and a \emph{deterministic} potential response function $\mathbf{g}:D\times U\to V$.

Pearl's model also features a second deterministic function $\mathbf{f}:U\to Y$, and $G$ is derived from $F$ via the equation modifications permitted by $D$. It is straightforward to show that an arbitrary function $\mathbf{f}:U\to Y$ can be constructed from Pearl's set of functions $f_i$, and if $D$ may modify the set $F$ arbitrarily, then it appears that $\mathbf{g}$ can in principle be an arbitrary function $D\times U\to Y$ (though many possible choices would be quite unusual).

Pearl's counterfactual model seems to essentially be a deterministic map $\mathbf{g}:D\times U\to V$ along with a probability measure $P$ on $U$. Putting these together and marginalising over $U$ (as we might expect we want to do with ``background variables'') simply yields a consequence map $D\to \Delta(\sigalg{V})$, which doesn't seem to have any special counterfactual properties.

In order to pose counterfactual questions, Pearl introduces the idea of holding $U$ fixed:
\\
````
\paragraph{Definition 7.1.5 (Counterfactual)}
Let $X$ and $Y$ be two subsets of variables in $V$. The counterfactual sentence ``$Y$ would be $y$ (in situation $u$), had $X$ been $x$'' is interpreted as the equality $Y_x(u) = y$, with $Y_x(u)$
being the potential response of $Y$ to $X = x$.'
'''
\\

Holding $U$ fixed allows SCM counterfactual models to answer questions about what would have happened if we had taken different actions given the same background context. For example, we can compare $Y_x(u)$ with $Y_{x'}(u)$ and interpret the comparison as telling us what would have happened in the same situation $u$ if we did $x$ and, at the same time, what would happen if we did $x'$. It is the ability to consider different actions ``in exactly the same situation'' that makes these models ``counterfactual''.

One obvious question is: does $\mathbf{g}$ have to be deterministic? While SCMs are defined in terms of deterministic functions with noise arguments, it's not clear that this is a necessary feature of counterfactual models. If $\mathbf{g}$ were properly stochastic, what is the problem with considering $\mathbf{g}(x,u)$ and $\mathbf{g}(x',u)$ to represents what would happen in a fixed situation $u$ if I did $x$ and if I did $x'$ respectively? In fact, a nondeterministic $\mathbf{g}$  arguably fails to capture a key intuition of taking actions ``in exactly the same situation''. If I want to know the result of doing action $x$ and, in exactly the same situation, the result of doing action $x$, then one might intuitively think that the result should always be \emph{deterministically the same}. This property, which we call \emph{deterministic reproducibility}, does not hold if we consider a nondeterministic potential response map $\mathbf{g}$.

This idea of doing $x$ and, in the same situation, doing $x$ doesn't render very well in English. Furthermore, even though deterministic reproducibility seems to be an important property of counterfactual SCMs, they don't help very much to elucidate the idea. ``If I take action $x$ in situation $U$ I get $V_x(u)$ and if I take action $x$ in situation $U$ I get $V_x(u)$'' is just a redundant repetition. It seems that we want some way to express the idea of having two copies of $V_x(u)$ or, more generally, having multiple copies of a potential response function in such a way that we can make comparisons between their results.

The idea that we need \emph{can} be clearly expressed with a see-do model. 


\section{Decomposability and double exchangeability}

A see-do model $\kernel{T}:\Theta\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$ is decomposable if an observational statistical model $\kernel{O}:\Theta\to \Delta(\sigalg{X})$ and a consequence map $\kernel{C}:\Theta\times D\to \Delta(\sigalg{Y})$ such that 

A great deal of ``non-causal statistics'' deals with models of \emph{exchangeable random variables}. Random variables $\RV{X}_1$ and $\RV{X}_2$ both taking values in $X$ are exchangeable if $\prob{P}^{\RV{X}_1\RV{X}_2} = \prob{P}^{\RV{X}_2\RV{X}_1}$; more generally, a set of $n$ random variables is exchangeable if the joint distribution is unchanged by applying any permutation to the order of the variables. Exchangeability implies indifference to the ordering of \emph{observations}. For example:
\begin{itemize}
    \item Suppose the random variables $\RV{X}_1, \RV{X}_2, \RV{X}_3$ represent beliefs about the outcomes of flipping a coin twice. If we are not completely sure the coin is fair, then we might suppose that seeing heads for the first two flips will leave us slightly more confident in a heads than a tails outcome on the next flip, so $\prob{P}^{\RV{X}_3|\RV{X}_2\RV{X}_1}_{\text{HH}}$ is not quite the same as $\prob{P}^{\RV{X}_3}$. However, if $\RV{X}_1,\RV{X}_2$ and $\RV{X}_3$ are exchangeable then it must be the case that $\prob{P}^{\RV{X}_3|\RV{X}_2\RV{X}_1}_{HT}=\prob{P}^{\RV{X}_3|\RV{X}_1\RV{X}_2}_{HT}$; our views about the likelihood of a particular $\RV{X}_3$ after seeing a particular number of heads and a particular number of tails do not depend on the order of the heads and tails.
    \item Suppose $\RV{W}_1$ and $\RV{W}_2$ represent consecutive draws without replacement from an urn containing a finite number of red and white balls in the frequentist sense that given a large ensemble of draws from the urn, the sample fractions will converge to the respective probabilities of $\RV{W}_1$ and $\RV{W}_2$. While the changing number of balls in the urn makes $\RV{W}_2$ depend on $\RV{W}_1$, it can be verified that supposing an equal chance of drawing any particular ball, $\RV{W}_1$ and $\RV{W}_2$ are exchangeable, i.e. $\prob{P}^{\RV{W}_1\RV{W}_2}=\prob{P}^{\RV{W}_2\RV{W}_1}$. This means that the probability of drawing a certain number of reds and whites does not depend on the order in which the balls are drawn.
\end{itemize}

\emph{Functional exchangeability} is a causal version of exchangeability that applies to consequence maps. Where exchangeability implies indifference to the ordering of observations, functional exchangeability implies indifference to the ordering of \emph{decision-consequence pairs}. For example:

\begin{itemize}
    \item Suppose you are planning to conduct a sequence of experiments in which you will set a piece of equipment to a particular setting, represented by $\RV{D}_1,\RV{D}_2,\RV{D}_3$, and record the results. The random variables $\RV{Y}_1,\RV{Y}_2,\RV{Y}_3$ represent our beliefs about the results of the first, second and third repeats of the experiment prior to undertaking it. This experiment is functionally exchangeable if it is described by a consequence map $\kernel{C}:D_0^3\to \Delta(\sigalg{Y}^3)$ such that $\kernel{C}^{\RV{Y}_1\RV{Y}_2\RV{Y}_3|\RV{D}_1\RV{D}_2\RV{D}_3}=\kernel{C}^{\RV{Y}_2\RV{Y}_3\RV{Y}_1|\RV{D}_2\RV{D}_3\RV{D}_1}$ and likewise for other joint permutations of the decisions and consequences. As in the coin flipping example, this means that we ``learn the same thing'' from choosing settings $a$ and observing $p$ followed by choosing $b$ and observing $q$ as we would from choosing $b$ and observing $q$ followed by choosing $a$ and observing $p$
    \item Suppose $\RV{W}_1$ and $\RV{W}_2$ represent (in the frequentist sense) an ensemble of draws from one of two finite urns of red and white balls, with the urn choices given by $\RV{D}_1$, $\RV{D}_2$. Then $\RV{W}_1, \RV{W}_2$ and $\RV{D}_1, \RV{D}_2$ are conditionally exchangeable in the sense that $\prob{P}^{\RV{W}_1\RV{W}_2|\RV{D}_1\RV{D}_2}=\prob{P}^{\RV{W}_2\RV{W}_1|\RV{D}_2\RV{D}_1}$
\end{itemize}

\todo[inline]{Define permutation, set permutation}



De Finetti's representation theorem shows that any infinite exchangeable sequence of random variables can be represented as a mixture of independent and identically distributed sequences. This theorem connects exchangeable \emph{subjective Bayesian random variables} $\RV{X}^{(B)}_n$, which represent expectations of future $X^n$-valued observations, and independent and identically distributed \emph{frequentist random variables} $\RV{X}^{(F)}$, which represent almost sure $n\to\infty$ limits of proportions in $X^n$-valued observations. Conseuqences of the theorem are:

\begin{itemize}
    \item Any exchangeable sequence of random variables $\RV{X}_A$ that can be extended to an infinite sequence can be represented as a mixture $\mu\in\Delta(\theta)$ of coupled statistical models $\utimes_{i\in A} \kernel{O}$ where $\kernel{O}:\Theta\to \Delta(\sigalg{X})$
    \item Any statistical model $\kernel{O}:\Theta\to \Delta(\sigalg{X})$ along with a prior $\mu$ induces a family of exchangeable sequences of random variables $\RV{X}_A$, $A\subset\mathbb{N}$
\end{itemize}

If our task is to predict future $X$-valued observations and our predictions are the same regardless of the order in which the observations arrive, then the probability distribution representing predictions can be represented by a statistical model and a prior. A similar theorem exists connects ``functionally exchangeable'' consequence models and coupled 2-player statistical models. Coupled 2-player statistical models themselves are closely related to models typically used in causal inference.

\begin{theorem}[Representation of infinite exchangeable sequences\citep{hewitt_symmetric_1955}]
Let $(X,\sigalg{X})$ be a compact Hausdorff space with the Baire $\sigma$-algebra and $\prob{P}$ a measure on $X^\mathbb{N}$ with the product sigma algebra such that $\RV{X}_\mathbb{N}$ with each $\RV{X}_i$ given by the projection map $\pi_i$. Define $(\Delta(\sigalg{X}),\sigalg{E})$ to be the set of all probability measures on $X$ with the $\sigma$-algebra $\sigalg{E}$ being the coarsest algebra for which the maps $\mathrm{ev}_A:\Delta(\sigalg{X})\to \mathbb{R}$ given by $\mathrm{ev}_A:\rho\mapsto \rho(A)$ (for $\rho\in\Delta(\sigalg{X})$) are measurable for all $A\in \sigalg{X}$. Then there exists a unique probability measure $\mu$ in $\Delta(\sigalg{E})$ such that for all $n\in\mathbb{N}$, $C\in\sigalg{X^n}$:
\begin{align}
    \prob{P}(C\times X^{\mathbb{N}\setminus[n]}) = \int_{(\Delta(\sigalg{X}))} \prod_{i\in [n]} \rho(\RV{X}_i(C)) d\mu(\rho) 
\end{align}

Where $\RV{X}_i(C)$ is the image of $C$ under $\RV{X}_i$.
\end{theorem}

Examples of such spaces include bounded Borel subsets of $\mathbb{R}$ and bounded subsets of $\mathbb{N}$.

\begin{definition}[Functional Exchangeability]
A finite sequence of random variables $\RV{Y}_1,...,\RV{Y}_n:\Omega\to Y$ and a sequence of choice variables\todo{define choice variables; independent of Y conditional on D} $\RV{D}_1,...,\RV{D}_n:D\to D_0$ on kernel space $(\kernel{C},D,\Omega)$ along with is \emph{functionally exchangeable} if for all permutations $\sigma:[n]\to[n]$, $\kernel{C}^{\RV{Y}_1,...,\RV{Y}_n|\RV{D}_1,...,\RV{D}_n}=\kernel{C}^{\RV{Y}_{\sigma(1)},...,\RV{Y}_{\sigma(n)}|\RV{D}_{\sigma(1)},...,\RV{D}_{\sigma(n)}}$.

Graphically, functional exchangeability of $\RV{Y}_1, \RV{Y}_2$ and $\RV{D}_1, \RV{D}_2$ implies

\begin{align}
\begin{tikzpicture} \path (0,0) node (D1) {$\RV{D}_1$}
        + (0,-0.3) node (D2) {$\RV{D}_2$}
        ++ (2,-0.15) node[kernel] (C) {$\kernel{C}^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}$}
        ++ (2,0.15) node (Y1) {$\RV{Y}_1$}
        +  (0,-0.3) node (Y2) {$\RV{Y}_2$};
        \draw (D1) -- ($(C.west)+(0,0.15)$) ($(C.east)+(0,0.15)$) -- (Y1);
        \draw (D2) -- ($(C.west)+(0,-0.15)$) ($(C.east)+(0,-0.15)$) -- (Y2);
    \end{tikzpicture} = \begin{tikzpicture} \path (0,0) node (D1) {$\RV{D}_2$}
        + (0,-0.3) node (D2) {$\RV{D}_1$}
        ++ (2.5,-0.15) node[kernel] (C) {$\kernel{C}^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}$}
        ++ (2.5,0.15) node (Y1) {$\RV{Y}_2$}
        +  (0,-0.3) node (Y2) {$\RV{Y}_1$};
        \draw (D1) to [out=0, in=180] ($(C.west)+(0,-0.15)$) ($(C.east)+(0,-0.15)$) to [out=0, in=180] (Y1);
        \draw (D2) to [out=0, in=180] ($(C.west)+(0,0.15)$) ($(C.east)+(0,0.15)$) to [out=0, in=180] (Y2);
    \end{tikzpicture}
\end{align}
\todo[inline]{Include a lemma about swap maps and variable permutations}


\end{definition}

\begin{lemma}[Functionally exchangeable sequences with exchangeable choices induce exchangeable sequences]\label{lem:f-ex2ex}
Given functionally exchangeable sequences $\RV{Y}_{[n]}$ and $\RV{D}_{[n]}$ on $(\kernel{C},D_0^n,Y_0^n)$ with product $\sigma$-algebra, along with an exchangable measure $\prob{P}^{\RV{D}_{[n]}}$, define $\prob{P}'$ as follows:

\begin{align}
    \prob{P}' = 
    \begin{tikzpicture}
        \path (0,0) node[dist] (P) {$\prob{P}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        ++ (0.5,0.5) node[kernel] (C) {$\kernel{C}$}
        ++ (1,0) node (Y) {$\RV{Y}_{[n]}$}
        + (0,-1) node (D) {$\RV{D}_{[n]}$};
        \draw (P) -- (copy0) (copy0) to [out=45,in=180] (C) (C) -- (Y);
        \draw (copy0) to [out=-45,in=180] (D);
    \end{tikzpicture}
\end{align}

Then sequence $\utimes_{i\in[n]}(\RV{Y}_i\otimes\RV{D}_i)$ (given by the obvious projection maps) on the probability space $(\prob{P}',Y_0^n\times D_0^n, \sigalg{Y}_0^n\otimes\sigalg{D}_0^n)$ is exchangeable.
\end{lemma}

\begin{proof}
For $i\in [n]$, $A_i\in \sigalg{Y}$, $B_i\in \sigalg{D}$ and arbitrary permutation $\sigma$ we have

\begin{align}
    \prob{P}^{\prime \RV{X}_{1}\RV{D}_1,...,\RV{X}_n\RV{D}_n}(\prod_{i\in[n]} A_i\times B_i) &= \int_{\prod_{i\in[n]}B_i} \prob{P}^{\prime \RV{X}_{[n]}|\RV{D}_{[n]}}_{d_{[n]}}(\prod_{i\in[n]} A_i) d\prob{P}^{\prime \RV{D}_{[n]}}(d_{[n]})\\
                                                                                             &= \int_{\prod_{i\in[n]}B_i} \kernel{C}^{\RV{X}_{[n]}|\RV{D}_{[n]}}_{d_{[n]}}(\prod_{i\in[n]} A_i) d\prob{P}^{\RV{D}_{[n]}}(d_{[n]})\label{eq:swapoutprime}\\
                                                                                             &= \int_{\prod_{i\in[n]}B_i} \kernel{C}^{\RV{X}_{\sigma([n])}|\RV{D}_{\sigma([n])}}_{d_{[n]}}(\prod_{i\in[n]} A_i) d\prob{P}^{\RV{D}_{\sigma([n])}}(d_{[n]})\label{eq:doubleswap}\\
                                                                                             &= \int_{\prod_{i\in[n]}B_i} \kernel{P}^{\prime \RV{X}_{\sigma([n])}|\RV{D}_{\sigma([n])}}_{d_{[n]}}(\prod_{i\in[n]} A_i) d\prob{P}^{\prime \RV{D}_{\sigma([n])}}\label{eq:swapforpprime}\\
                                                                                             &= \prob{P}^{\prime \RV{X}_{\sigma(1)}\RV{D}_{\sigma(1)},...,\RV{X}_{\sigma(n)}\RV{D}_{\sigma(n)}}(\prod_{i\in[n]} A_i\times B_i)
\end{align}

Where line \ref{eq:doubleswap} follows from exchangeability of $\prob{P}$ and functional exchangeability of $\kernel{C}$ and lines \ref{eq:swapoutprime} and \ref{eq:swapforpprime} follow from the fact that for any invertible function $f$ of $\RV{D}_{[n]}$ and random variable $\RV{Y}$, $\kernel{C}^{\RV{Y}|f(\RV{D}_{[n]})}$ is a version of $\prob{P}^{\prime \RV{Y}|f(\RV{D}_{[n]})}$ and $\prob{P}^{f(\RV{D}_{[n]})}=\prob{P}^{\prime \RV{Y}|f(\RV{D}_{[n]})}$.
\end{proof}

\begin{definition}[Non-interfering]
A pair of sequences $\RV{Y}_{[n]}$ and $\RV{D}_{[n]}$ on $(\kernel{C},D,\Omega)$ is \emph{noninterfering} if for all $U\subset [n]$, $\kernel{C}^{\RV{Y}_U|\RV{D}_U}$ exists and $\kernel{C}^{\RV{Y}_{U}|\RV{D}_{[n]}}=\kernel{C}^{\RV{Y}_U|\RV{D}_U}$. Non-interference implies that discard maps can ``fall through'' kernels:

\begin{align}
\begin{tikzpicture} \path (0,0) node (D1) {$\RV{D}_1$}
        + (0,-0.3) node (D2) {$\RV{D}_2$}
        ++ (2,-0.15) node[kernel] (C) {$\kernel{C}^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}$}
        ++ (2,0.15) node (Y1) {$\RV{Y}_1$}
        +  (0,-0.3) node (Y2) {};
        \draw (D1) -- ($(C.west)+(0,0.15)$) ($(C.east)+(0,0.15)$) -- (Y1);
        \draw (D2) -- ($(C.west)+(0,-0.15)$);
        \draw[-{Rays[n=8]}] ($(C.east)+(0,-0.15)$) -- (Y2);
    \end{tikzpicture} &= \begin{tikzpicture} \path (0,0) node (D1) {$\RV{D}_1$}
        + (0,-0.3) node (D2) {$\RV{D}_2$}
        ++ (2,-0.15) node[kernel] (C) {$\kernel{C}^{\RV{Y}_1|\RV{D}_1}$}
        ++ (2,0.15) node (Y1) {$\RV{Y}_1$}
        +  (-3,-1) node (Y2) {$\RV{Y}_2$};
        \draw (D1) -- ($(C.west)+(0,0.15)$) ($(C.east)+(0,0.15)$) -- (Y1);
        \draw (D2) -- ($(C.west)+(0,-0.15)$);
        \draw[-{Rays[n=8]}] ($(C.east)+(0,-0.15)$) -- (Y2);
    \end{tikzpicture}
\end{align}

\end{definition}

\todo[inline]{I think it is the case that functionally exchangeable + non-interfering implies infinitely functionally exchangeably extendable, but not proved yet}

\begin{theorem}[Representation of functionally exchangeable sequences]
Let $(Y,\sigalg{Y})$ be a compact Hausdorff space with the Baire $\sigma$-algebra and $(D,\sigalg{D})$ a finite discrete space. Let $\kernel{C}$ be a Markov kernel $D^\mathbb{N}\to \Delta(\sigalg{Y}^\mathbb{N})$ and $\RV{Y}_\mathbb{N}$, $\RV{D}_\mathbb{N}$ a pair of functionally exchangeable sequences. Define $(F,\sigalg{F})$ to be the set of all Markov kernels $D\to \Delta(\sigalg{Y})$ with $\sigalg{F}$ the coarsest $\sigma$-algebra for which all evaluation maps $\mathrm{ev}_{d,A}:F\to \mathbb{R}$ given by $\mathrm{ev}_{d,A}:\kernel{H}\mapsto \kernel{H}_d(A)$ are measurable. Then there exists a unique probability measure $\nu$ on $\Delta(\sigalg{F})$ such that for all $n\in\mathbb{N}$, $d\in D^n$, $C\in \sigalg{Y}^n$:

\begin{align}
    \kernel{C}_d(C) = \int_{F} \prod_{i\in [n]} \kernel{H}_{\RV{D}_i(d)}(\RV{Y}_i(C)) d\nu(\kernel{H})
\end{align}
\end{theorem}

\begin{proof}
Let $\delta\in\Delta(\sigalg{D})$ be such that for all $n\in \mathbb{N}$, $\emptyset\neq B\in \sigalg{D}^n$ we have $\delta\splitter{0.1}_n(B)>0$. Such a measure exists by assumption on $D$. Define $delta_{\underline{n}}:=\delta\splitter{0.1}_n$. It is trivial to show that $\delta_{\underline{n}}$ is exchangeable. Define 
\begin{align}
\kernel{C}^n_{\delta} := \begin{tikzpicture}
        \path (0,0) node[dist] (P) {$\prob{P}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        ++ (0.5,0.5) node[kernel] (C) {$\kernel{C}$}
        ++ (1,0) node (Y) {$\RV{Y}_{[n]}$}
        + (0,-1) node (D) {$\RV{D}_{[n]}$};
        \draw (P) -- (copy0) (copy0) to [out=45,in=180] (C) (C) -- (Y);
        \draw (copy0) to [out=-45,in=180] (D);
\end{tikzpicture}
\end{align}
 $:= \delta_{\underline{n}} \kernel{C}\utimes \mathrm{Id}_{D^n}$



.  By Lemma \ref{lem:f-ex2ex}, there is an exchangeable sequence $\utimes_{i\in[n]} \RV{Y}'_i\utimes \RV{D}'_i$ on the probability space $(\delta_{\underline{n}} \kernel{C}\utimes\mathrm{Id}_D,Y^n\times D^n, \sigalg{Y}^n\otimes\sigalg{D}^n)$.
 


\end{proof}

\begin{corollary}
Equivalently, for all $n\in \mathbb{N}$, let $\kernel{G}:F\to $

\begin{align}
\begin{tikzpicture}
    \path (0,0) node (D) {$\RV{D}_{[n]}$}
    ++ (2,0.) node[kernel] (C) {$\kernel{C}$}
    ++ (2,0.) node (Y) {$\RV{Y}_{[n]}$};
    \draw (D) -- (C) -- (Y);
\end{tikzpicture} &= \begin{tikzpicture} \path (0,0) node (D1) {$\RV{D}_1$}
        + (0,-0.5) node (dot) {...}
        + (0,-1) node (D2) {$\RV{D}_n$}
        ++ (2,0) node[kernel] (C) {$\kernel{H}^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}$}
        ++ (2,0.15) node (Y1) {$\RV{Y}_1$}
        +  (0,-0.5) node (dot2) {...}
        +  (0,-1) node (Y2) {$\RV{Y}_n$};
        \draw (D1) -- ($(C.west)+(0,0.15)$) ($(C.east)+(0,0.15)$) -- (Y1);
        \draw (D2) -- ($(C.west)+(0,-0.15)$) ($(C.east)+(0,-0.15)$) -- (Y2);
    \end{tikzpicture}
\end{align}

\end{corollary}
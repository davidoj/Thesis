
%!TEX root = main.tex

\chapter{Two player statistical models and see-do models}

\todo[inline]{These are ``todo'' notes. All such notes that involve theoretical development are also collected in an unordered list of outstanding theoretical questions}

In this chapter I introduce two types of model. Models of the first type are called \emph{two player statistical models} and the second type are a special class of the first called \emph{see-do models}. Fundamentally, each of these is just a particular kind of stochastic function. The reason we are interested in these kinds of stochastic functions is that is that almost all causal models are instances of see-do models. Before introducing two player models and discussing what makes them causal, it is worth briefly considering models in statistics and machine learning generally.

A \emph{world model} is something I will informally define as a family of ``descriptions'' indexed by hypotheses $\{R_h|h\in H\}$. The set $H$ represents hypotheses or proposals for how the world ought to be described, and each proposal $h\in H$ entails some description of the world $\prob{R}_h$. Some examples of world models:

\begin{itemize}
    \item A linear regressor may take some data $\mathbf{x}$ and $\mathbf{y}$ and returns a parameter $\beta\in B$ with the property that $(\mathbf{y}-\mathbf{x}^T \beta)^2$ is small. A normal way to interpret the parameter $\beta$ is to consider it to be a proposal about how some phenomenon of interest should be described, with this description explicitly given by the function $f:x\mapsto \beta x$.
    \item A neural network used in classification may take data $\mathbf{x}$ and labels $\mathbf{y}$ and returns parameters $\mathbf{w}\in W$ with the property that $-\mathbf{y} \log \mathbf{x}+(1-y)\log(1-\mathbf{x})$ is small. Each $\mathbf{w}$ is a proposal for how to classify data and the classification rule associated with each $\mathbf{w}$ is a function $x\mapsto f(\mathbf{w},x)$.
    \item A crude description of a general election pre-poll result can be given by the ``true fraction'' $\theta$ of voters for each candidate and, under some unreasonably strong sampling assumptions, and the results of the survey for each $\theta$ can be described by $\prod_N\prob{P}_\theta^\RV{X}$ where $N$ is the number of voters surveyed and $\RV{X}$ is the vote choice of each.
\end{itemize}

In the first two examples the ``description'' that goes with each hypothesis is a function, while in the third example the descriptions are probability measures. In almost all practical cases, these descriptions of the world do not tell us exactly how the world will turn out under each hypothesis, but at best offer us a prediction that is as good as we can hope for. Probability is the tool that is very widely used to formalise such ``descriptions with uncertainty''. Say I have two different linear regressors: one which minimises squared error on the training data and one that always returns $\beta=10$. I want to ask which one produces descriptions that are more fit for my purpose. It is pointless to ask which one is correct because, in general, I cannot know that either will offer a description that is even approximately correct. However, I can consider a second level world model $\{\prob{P}^{\RV{X}\RV{Y}}_\alpha|\alpha\in A\}$ in which the phenomenon of interest is described by a family of probability measures, and then I can ask, given an $\alpha$, which $\beta$ is my regressor likely to return and how closely will $x\mapsto \beta x$ be to $\mathbb{E}_{\prob{P}_\alpha}[\RV{Y}|\RV{X}]$ for each likely choice. Generally, if I need to model a world with uncertainty I will need a world model that is an indexed family of probability measures.

A world model that consists of a family of probability measures $\{\prob{P}_h|h\in H\}$ is a \emph{statistical model} or \emph{statistical experiment}. Because I almost always need to Statistical models can be found everywhere in theoretical statistics and machine learning \cite{fisher_statistical_1992,le_cam_comparison_1996,freedman_asymptotic_1963,de_finetti_foresight_1992,vapnik_nature_2013,wald_statistical_1950}. A key point about statistical models -- even if I can only state it somewhat vaguely -- is that the truth of any hypothesis $h\in H$ has no dependence on what I might want to be true. As a user of statistical models, I have no authority to choose a hypothesis -- this is Nature's choice alone. 

I can sometimes make choices that will affect the way that the future turns out. I might have some set $D$ of choices I can make, and for each $d\in D$ I require a description of the results of my choice. Just as the results of hypotheses are often uncertain, so are the results of choices. I might be motivated to choose a probability measure $\prob{P}_d$ to describe them, maybe because it is common to do so or because I find arguments for subjective expected utility theory compelling \citep{steele_decision_2020}. A family of probability measures indexed by a set of choices $\{\prob{P}_d|d\in D\}$ will be called a \emph{consequence model}.

Statistical models and consequence models are both families of probability measures indexed by arbitrary sets, which we have called hypotheses $H$ and choices $D$ respectively. Their general types are the same, and the only difference is in the interpretation of the sets $H$ and $D$. The difference can be informally summarised in this manner: I do not get to tell Nature what choice $h\in H$ she makes, and Nature does not get to tell me what choice $d\in D$ I make. It will often be the case that I have multiple choices that can affect how the world turns out \emph{and} I have multiple hypotheses about how each choice will affect the world. In this case, I will have a \emph{two-player statistical model} $\{\prob{P}_{h,d}|h\in H,d\in D\}$. 

So far I have explained the distinction between ``player 1'' and ``player 2'' in vague metaphorical terms. If I am using a two-player statistical model in the context of a well defined problem such as ``given data, what choice should I make?'' then we can say precisely what $H$ and $D$ are and what role each plays in the problem. However, the field of causal inference includes other types of problem so-called counterfactual problems which involve a choice set $D$ that plays a different role to the choice set in decision problems. Thus, while I will argue that causal models are two-player statistical models, and the second player is what distinguishes them from ordinary statistical models, the same kind of model can be used with different interpretations of what the second player's choices represent.

Decision problems involving often involve some data $\RV{X}$ is observed, then a choice is made, then the consequences $\RV{Y}$ are observed. In such a model, the observed data $\RV{X}$ cannot be affected by the choice. These models will be called \emph{see-do} models to capture the assumption that there is an order in which seeing and doing happen.

In this chapter I will introduce two-player statistical models ``looking backwards'' towards key results in the foundations of ordinary statistics, with a particular focus on exchangeability-like assumptions and statistical decision theory. In the following chapters, results obtained here will be applied ``looking forwards'' problems of causal inference.

\section{Two player statistical models and see-do models}

Two player statistical models were introduced as doubly indexed sets of probability measures $\{\prob{P}_{h,d}|h\in H,d\in D\}$. If each $\prob{P}_{h,d}\in \Delta(\sigalg{E})$ for some measurable space $(E,\sigalg{E})$, the indexed set is equivalent to a function $H\times D\to \Delta(\sigalg{E})$. In the following work, we will make two simplifying assumptions:

\begin{enumerate}
    \item A two player statistical model can be represented by a \emph{Markov kernel} $\kernel{T}:H\times D\to \Delta(\sigalg{E})$
    \item The kernel space $(\kernel{T},(H\times D,\sigalg{H}\otimes\sigalg{D}),(E,\sigalg{E}))$ admits disintegrations $\kernel{T}^{\RV{Y}|\RV{XDH}}$ for arbitrary random variables $\RV{X},\RV{Y}$ on $H\times D\times E$ and domain variable $\RV{D}\utimes\RV{H}$
\end{enumerate}

The first condition amounts to the additional requirement that $(h,d)\mapsto \kernel{T}_{h,d}(A)$ is measurable for every $A\in \sigalg{H}\otimes\sigalg{D}\otimes\sigalg{E}$, and sufficient for the second condition is that $D\times H$ is countable and $X\times Y$ standard measurable (though this is not necessary, see Theorem \ref{th:existence_continous}).

\begin{definition}[Two player statistical model]\label{def:2p_stat}
A \emph{two-player statistical model} is a Markov kernel $\kernel{T}:H\times D\to \Delta(\sigalg{E})$ such that, for any random variables $\RV{X}: H\times D\times E\to X$ and $\RV{Y}:H\times D\times E\to Y$, a disintegration $\kernel{K}^{\RV{Y}|\RV{XDH}}:X\times D\times H\to \Delta(\sigalg{Y})$ exists. Every two player statistical model has three distinguished random variables: the \emph{hypothesis} $\RV{H}:H\times D\times E\to H$ given by $(h,d,e)\mapsto h$ and the \emph{choice} $\RV{D}:H\times D\times E\to D$ given by $(h,d,e)\mapsto d$ and the \emph{outcome} $\RV{O}:H\times D\times E\to E$ given by $(h,d,e)\mapsto e$..
\end{definition}

\begin{definition}[See-Do model]\label{def:seedo}
A \emph{see-do model} is a two-player statistical model $\kernel{T}:H\times D\to \Delta(\sigalg{E})$ with two additional distinguished random variables: the \emph{observation} $\RV{X}: H\times D\times E\to X$ and the \emph{consequence} $\RV{Y}:H\times D\times E\to Y$ such that the outcome is the coupled product of the observation and the consequence $\RV{O}=\RV{X}\utimes\RV{Y}$\todo{More generally, an invertible function of this}. A see-do model must observe the conditional independence $\RV{X}\CI_\kernel{T} \RV{D}|\RV{H}$, i.e. the observation is independent of the choice conditional on the hypothesis.
\end{definition}

\subsection{Decomposability}

Decomposability is a property of see-do models that is relevant to the distinction between counterfacutal and regular models. As we will show, many causal problems allow the use of decomposable see-do models. However, certain types of counterfactual problem do not.

\begin{definition}[decomposability]\label{def:decomposability}
A see-do model $\kernel{T}:H\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$ is \emph{decomposable} iff $\RV{Y}\CI_\kernel{T} \RV{X}|\RV{D}\RV{H}$. That is, if the consequence is independent of the observations given the hypothesis and the choice.
\end{definition}

Decomposable see-do models can be represented as a pair $(\kernel{O},\kernel{C})$ where $\kernel{O}$ is a one-player statistical model we call the \emph{observation model} and $\kernel{C}$ is a two-player statistical model we call the \emph{consequence model} (Corollary \ref{corr:decomp_representation}. Most models in the causal inference literature are decomposable -- if the observed data can tell us nothing useful beyond the distribution of observations, then we have a decomposable model.

\begin{theorem}[Observation and Consequence models]\label{th:obs_cmaps}
Any see-do model $(\kernel{T},\RV{H},\RV{D},\RV{X},\RV{Y})$ can be uniquely represented by the following pair of Markov kernels:
\begin{itemize}
    \item The \emph{observation model} $\kernel{T}^{\RV{X}|\RV{H}}$
    \item The \emph{contextual consequence model} $\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$
\end{itemize}

Furthermore
\begin{align}
\kernel{T} = \begin{tikzpicture} \path (0,0) node (T) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        + (0.,-1.15) node[copymap] (copy2) {}
        ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
        ++ (0.7,0) node[copymap] (copy1) {}
        +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
        ++ (1.9,0) node (X) {$\RV{X}$}
        +  (0,-1) node (Y) {$\RV{Y}$}
        + (0,0.5) node (H) {$\RV{H}$}
        + (0,-1.5) node (D2) {$\RV{D}$};
        \draw (T) -- (O) -- (X);
        \draw (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
        \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
        \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
        \draw (C) -- (Y);
        \draw (copy0) to [out = 65, in = 180] (H);
        \draw (copy2) to [out = -65, in = 180] (D2);
    \end{tikzpicture}
\end{align}
\end{theorem}

\todo[inline]{Maybe moves proofs out of main text}

\begin{proof}
By \ref{th:representaiton}, 

\begin{align}
\kernel{T} = \begin{tikzpicture} \path (0,0) node (T) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        + (0.,-1.15) node[copymap] (copy2) {}
        ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}\RV{D}}$}
        ++ (0.7,0) node[copymap] (copy1) {}
        +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
        ++ (1.9,0) node (X) {$\RV{X}$}
        +  (0,-1) node (Y) {$\RV{Y}$}
        + (0,0.5) node (H) {$\RV{H}$}
        + (0,-1.5) node (D2) {$\RV{D}$};
        \draw (T) -- (O) -- (X);
        \draw[name path=P1] (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
        \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
        \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
        \draw (C) -- (Y);
        \draw (copy0) to [out = 65, in = 180] (H);
        \draw (copy2) to [out = -65, in = 180] (D2);
        \draw[name path=P2] (copy2) to [out = 65, in = 180] ($(O.west)+(0,-0.15)$);
    \end{tikzpicture}
\end{align}


By the assumption $\RV{X}\CI_{\kernel{T}} \RV{D}|\RV{H}$ and version 2 of conditional independence from Theorem \ref{th:ci_equivalence},

\begin{align}
\kernel{T} &= \begin{tikzpicture} \path (0,0) node (T) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        + (0.,-1.15) node[copymap] (copy2) {}
        ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
        ++ (0.7,0) node[copymap] (copy1) {}
        +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
        ++ (1.9,0) node (X) {$\RV{X}$}
        +  (0,-1) node (Y) {$\RV{Y}$}
        + (0,0.5) node (H) {$\RV{H}$}
        + (0,-1.5) node (D2) {$\RV{D}$};
        \draw (T) -- (O) -- (X);
        \draw (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
        \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
        \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
        \draw (C) -- (Y);
        \draw (copy0) to [out = 65, in = 180] (H);
        \draw (copy2) to [out = -65, in = 180] (D2);
        \draw[-{Rays[n=8]}] (copy2) to [out = 65, in = 180] ($(O.west)+(-0.2,-0.5)$);
    \end{tikzpicture}\\
    &= \begin{tikzpicture} \path (0,0) node (T) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        + (0.,-1.15) node[copymap] (copy2) {}
        ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
        ++ (0.7,0) node[copymap] (copy1) {}
        +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
        ++ (1.9,0) node (X) {$\RV{X}$}
        +  (0,-1) node (Y) {$\RV{Y}$}
        + (0,0.5) node (H) {$\RV{H}$}
        + (0,-1.5) node (D2) {$\RV{D}$};
        \draw (T) -- (O) -- (X);
        \draw (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
        \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
        \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
        \draw (C) -- (Y);
        \draw (copy0) to [out = 65, in = 180] (H);
        \draw (copy2) to [out = -65, in = 180] (D2);
    \end{tikzpicture}
\end{align}

\end{proof}

\begin{corollary}\label{corr:decomp_representation}
A decomposable see-do model $\kernel{T}:H\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$ can be uniquely represented by
\begin{itemize}
    \item The \emph{observation model} $\kernel{T}^{\RV{X}|\RV{H}}$
    \item The \emph{consequence model} $\kernel{T}^{\RV{Y}|\RV{H}\RV{D}}$
\end{itemize}
\end{corollary}

\begin{proof}
Because $\kernel{T}$ is decomposable, $\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}= \stopper{0.2}_X\otimes \kernel{T}^{\RV{Y}|\RV{H}\RV{D}}$. Then by theorem \ref{th:representaiton} we have a unique representation of $\kernel{T}$.
\end{proof}

\subsubsection{Examples of decomposable and indecomposable see-do models}

Recall the previous example: suppose we are betting on the outcome of the flip of a possibly biased coin with payout 1 for a correct guess and 0 for an incorrect guess, and we are given $N$ previous flips of the coin to inspect. This situation can be modeled by a decomposable see-do model. Define $\kernel{B}:(0,1)\to \Delta(\{0,1\})$ by $\kernel{B}:\RV{H}\mapsto \mathrm{Bernoulli}(\RV{H})$. Then define $\prescript{1}{}{\kernel{T}}$ by:

\begin{itemize}
    \item $D=\{0,1\}$
    \item $X=\{0,1\}^N$
    \item $Y=\{0,1\}$
    \item $H=(0,1)$
    \item $\prescript{1}{}{\kernel{O}}:\splitter{0.1}^N\kernel{B}$
    \item $\prescript{1}{}{\kernel{C}}:(h,d)\mapsto \mathrm{Bernoulli}(1-|d-h|)$
\end{itemize}

In this model, the chance $\RV{H}$ of the coin landing on heads is as much as we can hope to know about how our bet will work out.

Suppose instead that in addition to the $N$ prior flips, we manage to look at the outcome of the flip on which we will bet. In this case, the situation can be modeled by the following indecomposable see-do model $\prescript{2}{}{\kernel{T}}$:

\begin{itemize}
    \item $D=\{0,1\}$
    \item $X=\{0,1\}^{N+1}$
    \item $Y=\{0,1\}$
    \item $H=(0,1)$
    \item $\prescript{2}{}{\kernel{T}}^{\RV{X}|\RV{H}}:\splitter{0.1}^{N+1}\kernel{B}$
    \item $\prescript{2}{}{\kernel{T}}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}:(h,\mathbf{x},d)\mapsto \delta_{1-|d-x_{N+1}|}$
\end{itemize}

In this case, even if we are told the value of $\RV{H}$, we still benefit from using the observed data when making our decision.

It is possible to model the second situation with a decomposable model by including the result of the $N+1$th flip in the hypothesis. Define the new hypothesis space $H'=H\times\{0,1\}$ and let $\RV{H}_0$ be the projection to the old hypothesis space $H$. Define $\prescript{3}{}{\kernel{T}}$ by:

\begin{itemize}
    \item $D=\{0,1\}$
    \item $X=\{0,1\}^{N+1}$
    \item $Y=\{0,1\}$
    \item $H'=(0,1)\times\{0,1\}$
    \item $\prescript{3}{}{\kernel{O}}:(\splitter{0.1}^N\kernel{B}\otimes \delta_{x_{N+1}}$
    \item $\prescript{3}{}{\kernel{C}}:(h,x_{N+1},d)\mapsto \delta_{1-|d-x_{N+1}|}$
\end{itemize}

However, $\prescript{2}{}{\kernel{T}}^{\RV{X}_{N+1}|\RV{H}} = \kernel{B}$ while $\prescript{3}{}{\kernel{T}}^{\RV{X}_{N+1}|\RV{H}_0}$ is undefined, so $\prescript{3}{}{\kernel{T}}$ is a substantially different model to $\prescript{2}{}{\kernel{T}}$.

If an indecomposable see-do model is employed in a \emph{decision problem} it is possible to create an equivalent decision problem with a decomposable model as I will show later. Some counterfactual problems cannot be formulated as decision problems, and indecomposability is a property of the types of counterfacutal model proposed by \citet{pearl_causality:_2009}, but not to my knowledge of any causal models used in a ``decision like context''.

\subsubsection{Exchangeability}

Thus far, we haven't dwelt on what it means for a probability measure to ``describe'' or ``represent'' something. It's well-known that probability is suitable for representing a number of different things. Two common choices are:

\begin{enumerate}
    \item The long run convergence of sequences or ensembles of observations of certain types of systems
    \item Forecasts of observations that will take place in the future
\end{enumerate}

Taking the first view, one can view each hypotheses in a statistical model as representing the proposition that the system will tend to produce long-run sequences of observations favoured by the associated probability measure. Given a possibly loaded die, we might entertain hypotheses a) it is a system that produces a 6 $\frac{1}{6}$ of the time, b) it is a system that produces a 6 $\frac{1}{4}$ of the time and so forth. On the other hand, if we view a sequence of random variables as a sequence of forecasts it is not immediately obvious that we need such hypotheses. If $\RV{X}_1,\RV{X}_2,\RV{X}_3,...$ are rolls of a possibly loaded die, then it seems reasonable on observing a large number of sixes that sixes are more likely in the future. Unlike hypotheses a) and b), forecasts of the outcome do not assign a stable value to the proportion of sixes produced by the die. \citet{de_finetti_foresight_1992} showed that if and only if a probabilistic forecast $\prob{P}$ has the property that the forecast of a sequence of random variables $\prob{P}^{\RV{X}_1\RV{X}_2\RV{X}_3}$ is identical to the forecast of any permutation of the sequence $\prob{P}^{\RV{X}_2\RV{X}_1\RV{X}_3}$ (an assumption known as \emph{exchangeability}) and this sequence could be extended infinitely, then there exists an $(H,\sigalg{H})$, a Markov kernel $\kernel{Q}:H\to \Delta(\sigalg{X}^3)$ and a \emph{prior} $\mu\in \Delta(\sigalg{H})$ such that

\begin{align}
    \prob{P}^{\RV{X}_1\RV{X}_2\RV{X}_3} = \begin{tikzpicture}
        \path (0,0) node[dist] (P) {$\mu$}
        ++ (0.7,0) node[copymap] (copy0) {}
        ++ (0.5,0.5) node[kernel] (Q1) {$\kernel{Q}$}
        +  (0,-0.5) node[kernel] (Q2) {$\kernel{Q}$}
        +  (0,-1) node[kernel] (Q3) {$\kernel{Q}$}
        ++ (1,0) node (X1) {$\RV{X}_1$}
        + (0,-0.5) node (X2) {$\RV{X}_2$}
        + (0,-1) node (X3) {$\RV{X}_3$};
        \draw (P) -- (copy0);
        \draw (copy0) to [out=45,in=180] (Q1) (copy0) to [out=0, in=180] (Q2) (copy0) to [out=-45,in=180] (Q3);
        \draw (Q1) -- (X1) (Q2) -- (X2) (Q3) -- (X3);
    \end{tikzpicture}
\end{align}

We can then consider $H$ to be the hypothesis class and define the statistical model

\begin{align}
    \begin{tikzpicture}
        \path (0,0) node (P) {$\RV{H}$}
        ++ (0.7,0) node[copymap] (copy0) {}
        ++ (0.5,0.5) node[kernel] (Q1) {$\kernel{Q}$}
        +  (0,-0.5) node[kernel] (Q2) {$\kernel{Q}$}
        +  (0,-1) node[kernel] (Q3) {$\kernel{Q}$}
        ++ (1,0) node (X1) {$\RV{X}_1$}
        + (0,-0.5) node (X2) {$\RV{X}_2$}
        + (0,-1) node (X3) {$\RV{X}_3$};
        \draw (P) -- (copy0);
        \draw (copy0) to [out=45,in=180] (Q1) (copy0) to [out=0, in=180] (Q2) (copy0) to [out=-45,in=180] (Q3);
        \draw (Q1) -- (X1) (Q2) -- (X2) (Q3) -- (X3);
    \end{tikzpicture}
\end{align}

Exchangeability-like assumptions have a number of interesting applications to see-do models:
\begin{itemize}
    \item \emph{Functional exchangeability} is a fundamental assumption of counterfactual models
    \item Exchangeability of observations implies decomposability
    \item A representation theorem similar to the one described above will be proved for \emph{doubly exchangeable} see-do forecasts
    \item \emph{Imitable} see-do models, a special class of doubly exchangeable models, play a key role in identification of causal effects
\end{itemize}

In general, we will call the product of a prior and a two player statistical models a \emph{forecasts}.


\begin{definition}[Forecasts, see-do forecast]
A \emph{forecast} is a Markov kernel $D\to \Delta(\sigalg{E})$ for some set of choices $D$ and outcomes $E$. The choice variable $\RV{D}:D\times E\to D$ and the outcome variable $\RV{O}:D\times E\to E$ are defined analagously to \ref{def:2p_stat}.

A \emph{see-do forecast} is a forecast $D\to \Delta(\sigalg{E})$ with an \emph{observation variable} $\RV{X}:D\times E\to X$ and a consequence variable $\RV{Y}:D\times E\to Y$ such that $\RV{O}=\RV{X}\utimes\RV{Y}$ and $\RV{X}\CI\RV{D}$.
\end{definition}

\todo[inline]{stop here}

\begin{theorem}
The product $\kernel{L}:=(\mu\otimes \mathrm{Id}_D)\kernel{K}$ of a prior $\mu\in \Delta(\sigalg{H})$ and a two player statistical model $\kernel{K}:H\times D\to \Delta(\sigalg{E})$ is a forecast $D\to \Delta(\sigalg{E})$ with $\RV{D}^f:(d,e)\mapsto d$ and $\RV{E}^f:(d,e)\mapsto e$. If $\kernel{K}$ is a see-do model with respect to observations $\RV{X}^{sd}$, $\RV{Y}^{sd}$ then there exist $\RV{X}^{f}$, $\RV{Y}^f$ such that $\kernel{L}$ is a see-do forecast.
\end{theorem}


\begin{proof}
The first part is trivial: $(\mu\otimes \mathrm{Id}_D)\kernel{K}$ is a Markov kernel $D\to \Delta(\sigalg{E})$.

For the second part $\RV{X}^f\CI\RV{D}$ is required for some $\RV{X}^f$.By Theorem \ref{th:iterated_disint} we have

\begin{align}
    \kernel{K}^{\RV{X}^{sd}\RV{Y}^{sd}|\RV{HD}} = \begin{tikzpicture}
        \path (0,0) node (H) {$\RV{H}$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        ++ (0.7,0) node[kernel] (X) {$\kernel{K}^{\RV{X}|\RV{H}}$}
        ++ (0.5,0) node[copymap] (copy1) {}
        +  (0.8,-1) node[kernel] (Y) {$\kernel{K}^{\RV{Y}|\RV{XHD}}$}
        ++ (2,0) node (Xr) {$\RV{X}^{sd}$}
        +  (0,-1) node (Yr) {$\RV{Y}^{sd}$};
        \draw (H) -- (X) -- (Xr);
        \draw (copy0) to [out=-90,in=180] ($(Y.west) + (0,0)$) 
              (copy1) to [out=-90,in=180] ($(Y.west) + (0,0.15)$)
              (D) -- ($(Y.west) + (0,-0.15)$);
        \draw (Y) -- (Yr);
    \end{tikzpicture}
\end{align}

Define $\RV{X}^f$ and $\RV{Y}^f$ such that

\begin{align}
    \kernel{L}^{\RV{X}^{f}\RV{Y}^{f}|\RV{D}} = \begin{tikzpicture}
        \path (0,0) node[dist] (H) {$\mu$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        ++ (0.7,0) node[kernel] (X) {$\kernel{K}^{\RV{X}|\RV{H}}$}
        ++ (0.5,0) node[copymap] (copy1) {}
        +  (0.8,-1) node[kernel] (Y) {$\kernel{K}^{\RV{Y}|\RV{XHD}}$}
        ++ (2,0) node (Xr) {$\RV{X}^{f}$}
        +  (0,-1) node (Yr) {$\RV{Y}^{f}$};
        \draw (H) -- (X) -- (Xr);
        \draw (copy0) to [out=-90,in=180] ($(Y.west) + (0,0)$) 
              (copy1) to [out=-90,in=180] ($(Y.west) + (0,0.15)$)
              (D) -- ($(Y.west) + (0,-0.15)$);
        \draw (Y) -- (Yr);
    \end{tikzpicture}
\end{align}

Clearly $\RV{O}^f=\RV{X}^f\utimes\RV{Y}^f$.

Then

\begin{align}
    \kernel{L}^{\RV{X}^{f}|\RV{D}} &= \begin{tikzpicture}
        \path (0,0) node[dist] (H) {$\mu$}
        + (0,-1.15) node (D) {$\RV{D}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        ++ (0.7,0) node[kernel] (X) {$\kernel{K}^{\RV{X}|\RV{H}}$}
        ++ (0.5,0) node[copymap] (copy1) {}
        +  (0.8,-1) node[kernel] (Y) {$\kernel{K}^{\RV{Y}|\RV{XHD}}$}
        ++ (2,0) node (Xr) {$\RV{X}^{f}$}
        +  (0,-1) node (Yr) {};
        \draw (H) -- (X) -- (Xr);
        \draw (copy0) to [out=-90,in=180] ($(Y.west) + (0,0)$) 
              (copy1) to [out=-90,in=180] ($(Y.west) + (0,0.15)$)
              (D) -- ($(Y.west) + (0,-0.15)$);
        \draw[-{Rays[n=8]}] (Y) -- (Yr);
    \end{tikzpicture}\\
    &= \begin{tikzpicture}
        \path (0,0) node[dist] (H) {$\mu$}
        + (0,-1.) node (D) {$\RV{D}$}
        ++ (1.2,0) node[kernel] (X) {$\kernel{K}^{\RV{X}|\RV{H}}$}
        ++ (2.5,0) node (Xr) {$\RV{X}^{f}$}
        +  (0,-1) node (Yr) {};
        \draw (H) -- (X) -- (Xr);
        \draw[-{Rays[n=8]}] (D) -- (Yr);
    \end{tikzpicture}
\end{align}

And so $\RV{X}^f\CI_{\kernel{M}}\RV{D}$.
\end{proof}

\begin{definition}[Exchangeability]
Given $A\subseteq \mathbb{N}$, a sequence of random variables $\RV{X}_A:=\utimes_{i\in A} \RV{X}_i$ each taking values in $X$ on a probability space $(\prob{P},(\Omega,\sigalg{F}))$ is \emph{exchangeable} if for all $n\in A$, all permutations of indices $\sigma:[n]\to[n]$ and all  $B \in\sigalg{F}$, $\prob{P}^{\RV{X}_{[n]}}(B) =\prob{P}^{\RV{X}_{\sigma([n])}}(B)$.
\end{definition}

\begin{theorem}[Representation of infinite exchangeable sequences\citep{hewitt_symmetric_1955}]
Let $(X,\sigalg{X})$ be a compact Hausdorff space with the Baire $\sigma$-algebra and $\prob{P}$ a measure on $X^\mathbb{N}$ with the product sigma algebra such that $\RV{X}_\mathbb{N}$ with each $\RV{X}_i$ given by the projection map $\pi_i$. Define $(\Delta(\sigalg{X}),\sigalg{E})$ to be the set of all probability measures on $X$ with the $\sigma$-algebra $\sigalg{E}$ being the coarsest algebra for which the maps $\mathrm{ev}_A:\Delta(\sigalg{X})\to \mathbb{R}$ given by $\mathrm{ev}_A:\rho\mapsto \rho(A)$ (for $\rho\in\Delta(\sigalg{X})$) are measurable for all $A\in \sigalg{X}$. Then there exists a unique probability measure $\mu$ in $\Delta(\sigalg{E})$ such that for all $n\in\mathbb{N}$, $C\in\sigalg{X^n}$:
\begin{align}
    \prob{P}(C\times X^{\mathbb{N}\setminus[n]}) = \int_{(\Delta(\sigalg{X}))} \prod_{i\in [n]} \rho(\RV{X}_i(C)) d\mu(\rho) 
\end{align}

Where $\RV{X}_i(C)$ is the image of $C$ under $\RV{X}_i$.
\end{theorem}

Examples of such spaces include bounded Borel subsets of $\mathbb{R}$ and bounded subsets of $\mathbb{N}$.


\begin{definition}[Functional Exchangeability]
Given a two player statistical model $\kernel{K}:D\times H\to \Delta(\sigalg{E})$, a \emph{choice variable} $\RV{D}_i$ is a variable such that $\RV{D}_i \CI_{\kernel{K}} \RV{O} | \RV{D}$ a finite sequence of random variables $\RV{Y}_1,...,\RV{Y}_n:D\times E \to Y$ and a sequence of choice variables\todo{define choice variables; independent of Y conditional on D} $\RV{D}_1,...,\RV{D}_n:D\to D_0$ on kernel space $(\kernel{C},D,\Omega)$ along with is \emph{functionally exchangeable} if for all permutations $\sigma:[n]\to[n]$, $\kernel{C}^{\RV{Y}_1,...,\RV{Y}_n|\RV{D}_1,...,\RV{D}_n}=\kernel{C}^{\RV{Y}_{\sigma(1)},...,\RV{Y}_{\sigma(n)}|\RV{D}_{\sigma(1)},...,\RV{D}_{\sigma(n)}}$.

Graphically, functional exchangeability of $\RV{Y}_1, \RV{Y}_2$ and $\RV{D}_1, \RV{D}_2$ implies

\begin{align}
\begin{tikzpicture} \path (0,0) node (D1) {$\RV{D}_1$}
        + (0,-0.3) node (D2) {$\RV{D}_2$}
        ++ (2,-0.15) node[kernel] (C) {$\kernel{C}^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}$}
        ++ (2,0.15) node (Y1) {$\RV{Y}_1$}
        +  (0,-0.3) node (Y2) {$\RV{Y}_2$};
        \draw (D1) -- ($(C.west)+(0,0.15)$) ($(C.east)+(0,0.15)$) -- (Y1);
        \draw (D2) -- ($(C.west)+(0,-0.15)$) ($(C.east)+(0,-0.15)$) -- (Y2);
    \end{tikzpicture} = \begin{tikzpicture} \path (0,0) node (D1) {$\RV{D}_2$}
        + (0,-0.3) node (D2) {$\RV{D}_1$}
        ++ (2.5,-0.15) node[kernel] (C) {$\kernel{C}^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}$}
        ++ (2.5,0.15) node (Y1) {$\RV{Y}_2$}
        +  (0,-0.3) node (Y2) {$\RV{Y}_1$};
        \draw (D1) to [out=0, in=180] ($(C.west)+(0,-0.15)$) ($(C.east)+(0,-0.15)$) to [out=0, in=180] (Y1);
        \draw (D2) to [out=0, in=180] ($(C.west)+(0,0.15)$) ($(C.east)+(0,0.15)$) to [out=0, in=180] (Y2);
    \end{tikzpicture}
\end{align}
\todo[inline]{Include a lemma about swap maps and variable permutations}


\end{definition}

\begin{lemma}[Functionally exchangeable sequences with exchangeable choices induce exchangeable sequences]\label{lem:f-ex2ex}
Given functionally exchangeable sequences $\RV{Y}_{[n]}$ and $\RV{D}_{[n]}$ on $(\kernel{C},D_0^n,Y_0^n)$ with product $\sigma$-algebra, along with an exchangable measure $\prob{P}^{\RV{D}_{[n]}}$, define $\prob{P}'$ as follows:

\begin{align}
    \prob{P}' = 
    \begin{tikzpicture}
        \path (0,0) node[dist] (P) {$\prob{P}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        ++ (0.5,0.5) node[kernel] (C) {$\kernel{C}$}
        ++ (1,0) node (Y) {$\RV{Y}_{[n]}$}
        + (0,-1) node (D) {$\RV{D}_{[n]}$};
        \draw (P) -- (copy0) (copy0) to [out=45,in=180] (C) (C) -- (Y);
        \draw (copy0) to [out=-45,in=180] (D);
    \end{tikzpicture}
\end{align}

Then sequence $\utimes_{i\in[n]}(\RV{Y}_i\otimes\RV{D}_i)$ (given by the obvious projection maps) on the probability space $(\prob{P}',Y_0^n\times D_0^n, \sigalg{Y}_0^n\otimes\sigalg{D}_0^n)$ is exchangeable.
\end{lemma}

\begin{proof}
For $i\in [n]$, $A_i\in \sigalg{Y}$, $B_i\in \sigalg{D}$ and arbitrary permutation $\sigma$ we have

\begin{align}
    \prob{P}^{\prime \RV{X}_{1}\RV{D}_1,...,\RV{X}_n\RV{D}_n}(\prod_{i\in[n]} A_i\times B_i) &= \int_{\prod_{i\in[n]}B_i} \prob{P}^{\prime \RV{X}_{[n]}|\RV{D}_{[n]}}_{d_{[n]}}(\prod_{i\in[n]} A_i) d\prob{P}^{\prime \RV{D}_{[n]}}(d_{[n]})\\
                                                                                             &= \int_{\prod_{i\in[n]}B_i} \kernel{C}^{\RV{X}_{[n]}|\RV{D}_{[n]}}_{d_{[n]}}(\prod_{i\in[n]} A_i) d\prob{P}^{\RV{D}_{[n]}}(d_{[n]})\label{eq:swapoutprime}\\
                                                                                             &= \int_{\prod_{i\in[n]}B_i} \kernel{C}^{\RV{X}_{\sigma([n])}|\RV{D}_{\sigma([n])}}_{d_{[n]}}(\prod_{i\in[n]} A_i) d\prob{P}^{\RV{D}_{\sigma([n])}}(d_{[n]})\label{eq:doubleswap}\\
                                                                                             &= \int_{\prod_{i\in[n]}B_i} \kernel{P}^{\prime \RV{X}_{\sigma([n])}|\RV{D}_{\sigma([n])}}_{d_{[n]}}(\prod_{i\in[n]} A_i) d\prob{P}^{\prime \RV{D}_{\sigma([n])}}\label{eq:swapforpprime}\\
                                                                                             &= \prob{P}^{\prime \RV{X}_{\sigma(1)}\RV{D}_{\sigma(1)},...,\RV{X}_{\sigma(n)}\RV{D}_{\sigma(n)}}(\prod_{i\in[n]} A_i\times B_i)
\end{align}

Where line \ref{eq:doubleswap} follows from exchangeability of $\prob{P}$ and functional exchangeability of $\kernel{C}$ and lines \ref{eq:swapoutprime} and \ref{eq:swapforpprime} follow from the fact that for any invertible function $f$ of $\RV{D}_{[n]}$ and random variable $\RV{Y}$, $\kernel{C}^{\RV{Y}|f(\RV{D}_{[n]})}$ is a version of $\prob{P}^{\prime \RV{Y}|f(\RV{D}_{[n]})}$ and $\prob{P}^{f(\RV{D}_{[n]})}=\prob{P}^{\prime \RV{Y}|f(\RV{D}_{[n]})}$.
\end{proof}

\begin{definition}[Non-interfering]
A pair of sequences $\RV{Y}_{[n]}$ and $\RV{D}_{[n]}$ on $(\kernel{C},D,\Omega)$ is \emph{noninterfering} if for all $U\subset [n]$, $\kernel{C}^{\RV{Y}_U|\RV{D}_U}$ exists and $\kernel{C}^{\RV{Y}_{U}|\RV{D}_{[n]}}=\kernel{C}^{\RV{Y}_U|\RV{D}_U}$. Non-interference implies that discard maps can ``fall through'' kernels:

\begin{align}
\begin{tikzpicture} \path (0,0) node (D1) {$\RV{D}_1$}
        + (0,-0.3) node (D2) {$\RV{D}_2$}
        ++ (2,-0.15) node[kernel] (C) {$\kernel{C}^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}$}
        ++ (2,0.15) node (Y1) {$\RV{Y}_1$}
        +  (0,-0.3) node (Y2) {};
        \draw (D1) -- ($(C.west)+(0,0.15)$) ($(C.east)+(0,0.15)$) -- (Y1);
        \draw (D2) -- ($(C.west)+(0,-0.15)$);
        \draw[-{Rays[n=8]}] ($(C.east)+(0,-0.15)$) -- (Y2);
    \end{tikzpicture} &= \begin{tikzpicture} \path (0,0) node (D1) {$\RV{D}_1$}
        + (0,-0.3) node (D2) {$\RV{D}_2$}
        ++ (2,-0.15) node[kernel] (C) {$\kernel{C}^{\RV{Y}_1|\RV{D}_1}$}
        ++ (2,0.15) node (Y1) {$\RV{Y}_1$}
        +  (-3,-1) node (Y2) {$\RV{Y}_2$};
        \draw (D1) -- ($(C.west)+(0,0.15)$) ($(C.east)+(0,0.15)$) -- (Y1);
        \draw (D2) -- ($(C.west)+(0,-0.15)$);
        \draw[-{Rays[n=8]}] ($(C.east)+(0,-0.15)$) -- (Y2);
    \end{tikzpicture}
\end{align}

\end{definition}

\todo[inline]{I think it is the case that functionally exchangeable + non-interfering implies infinitely functionally exchangeably extendable, but not proved yet}

\begin{theorem}[Representation of functionally exchangeable sequences]
Let $(Y,\sigalg{Y})$ be a compact Hausdorff space with the Baire $\sigma$-algebra and $(D,\sigalg{D})$ a finite discrete space. Let $\kernel{C}$ be a Markov kernel $D^\mathbb{N}\to \Delta(\sigalg{Y}^\mathbb{N})$ and $\RV{Y}_\mathbb{N}$, $\RV{D}_\mathbb{N}$ a pair of functionally exchangeable sequences. Define $(F,\sigalg{F})$ to be the set of all Markov kernels $D\to \Delta(\sigalg{Y})$ with $\sigalg{F}$ the coarsest $\sigma$-algebra for which all evaluation maps $\mathrm{ev}_{d,A}:F\to \mathbb{R}$ given by $\mathrm{ev}_{d,A}:\kernel{H}\mapsto \kernel{H}_d(A)$ are measurable. Then there exists a unique probability measure $\nu$ on $\Delta(\sigalg{F})$ such that for all $n\in\mathbb{N}$, $d\in D^n$, $C\in \sigalg{Y}^n$:

\begin{align}
    \kernel{C}_d(C) = \int_{F} \prod_{i\in [n]} \kernel{H}_{\RV{D}_i(d)}(\RV{Y}_i(C)) d\nu(\kernel{H})
\end{align}
\end{theorem}

\begin{proof}
Let $\delta\in\Delta(\sigalg{D})$ be such that for all $n\in \mathbb{N}$, $\emptyset\neq B\in \sigalg{D}^n$ we have $\delta\splitter{0.1}_n(B)>0$. Such a measure exists by assumption on $D$. Define $delta_{\underline{n}}:=\delta\splitter{0.1}_n$. It is trivial to show that $\delta_{\underline{n}}$ is exchangeable. Define 
\begin{align}
\kernel{C}^n_{\delta} := \begin{tikzpicture}
        \path (0,0) node[dist] (P) {$\prob{P}$}
        ++ (0.5,0) node[copymap] (copy0) {}
        ++ (0.5,0.5) node[kernel] (C) {$\kernel{C}$}
        ++ (1,0) node (Y) {$\RV{Y}_{[n]}$}
        + (0,-1) node (D) {$\RV{D}_{[n]}$};
        \draw (P) -- (copy0) (copy0) to [out=45,in=180] (C) (C) -- (Y);
        \draw (copy0) to [out=-45,in=180] (D);
\end{tikzpicture}
\end{align}
 $:= \delta_{\underline{n}} \kernel{C}\utimes \mathrm{Id}_{D^n}$



.  By Lemma \ref{lem:f-ex2ex}, there is an exchangeable sequence $\utimes_{i\in[n]} \RV{Y}'_i\utimes \RV{D}'_i$ on the probability space $(\delta_{\underline{n}} \kernel{C}\utimes\mathrm{Id}_D,Y^n\times D^n, \sigalg{Y}^n\otimes\sigalg{D}^n)$.
 


\end{proof}

\begin{corollary}
Equivalently, for all $n\in \mathbb{N}$, let $\kernel{G}:F\to $

\begin{align}
\begin{tikzpicture}
    \path (0,0) node (D) {$\RV{D}_{[n]}$}
    ++ (2,0.) node[kernel] (C) {$\kernel{C}$}
    ++ (2,0.) node (Y) {$\RV{Y}_{[n]}$};
    \draw (D) -- (C) -- (Y);
\end{tikzpicture} &= \begin{tikzpicture} \path (0,0) node (D1) {$\RV{D}_1$}
        + (0,-0.5) node (dot) {...}
        + (0,-1) node (D2) {$\RV{D}_n$}
        ++ (2,0) node[kernel] (C) {$\kernel{H}^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}$}
        ++ (2,0.15) node (Y1) {$\RV{Y}_1$}
        +  (0,-0.5) node (dot2) {...}
        +  (0,-1) node (Y2) {$\RV{Y}_n$};
        \draw (D1) -- ($(C.west)+(0,0.15)$) ($(C.east)+(0,0.15)$) -- (Y1);
        \draw (D2) -- ($(C.west)+(0,-0.15)$) ($(C.east)+(0,-0.15)$) -- (Y2);
    \end{tikzpicture}
\end{align}

\end{corollary}

\subsection{Causal questions and decision functions}

\citet{pearl_book_2018} has proposed three types of causal question:
\begin{enumerate}
    \item Association: How are $\RV{W}$ and $\RV{Z}$ related? How would observing $\RV{W}$ change my beliefs about $\RV{Z}$?
    \item Intervention: What would happen if I do ... ? How can I make ... happen?
    \item Counterfactual: What if I had done ... instead of what I actually did?
\end{enumerate}

\emph{Causal decision problems} are, roughly speaking, ``interventional'' problems. In English, a causal decision problem roughly asks

\begin{quote}
    Given that I have data $\RV{X}$ and I know which values of $\RV{Y}$ I would like to see and some knowledge about how the world works, which of my available choices $D$ should I select?
\end{quote}

This type of question presupposes somewhat more than Pearl's prototypical interventional questions. First, it supposes that we have \emph{preferences} over the values that $\RV{Y}$ might take, which we need not have to answer the question ``What would happen if I do ...?''. Secondly, and crucially to our theory, causal decision problem suppose that we are given data and a set of choices. 

We will return to the question of preferences. For now, we will focus on the idea that a causal decision problem is about selecting a choice given data. That is, however the selection is made, the answer to a causal decision problem is always a \emph{decision function} $\kernel{D}:X\to \Delta(\sigalg{D})$.

A property that will be of interest when considering counterfactual models is \emph{decomposability}. A see-do model 



\begin{definition}[Consequence map]
Given a see-do model $(\kernel{T},\RV{H},\RV{D},\RV{X},\RV{Y})$, a \emph{consequence map} is a map $\kernel{C}:D\to \Delta(\sigalg{Y})$ where $D$ is a choice set and $Y$ is a consequence set.

The consequence model evaluated at any particular hypothesis $h\in H$, $\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}_{\cdot,h,\cdot}$ is a consequence map.
\end{definition}

\todo[inline]{Not quite sure if this is the right place for the following definition}

The independence of observations and choices is preserved when we take the product of a see-do model and a \emph{prior} over hypotheses. Such a product produces a \emph{Bayesian see-do model}:

\begin{definition}[Bayesian See-Do Model]
A Bayesian See-Do Model $\langle\kernel{U},\RV{D},\RV{X},\RV{Y}\rangle$ is a Markov kernel space $(\kernel{U},D,X\times Y)$ with the property $\RV{X}\CI_{\kernel{U}}\RV{D}$, along with choices $\RV{D}$, observations $\RV{X}$ and consequences $\RV{Y}$, defined as before.
\end{definition}

\begin{theorem}[A see-do model with a prior is a Bayesian see-do model]
The product of a see-do model $\kernel{T}$ and a prior $\gamma\in \Delta(\sigalg{H})$
\begin{align}
    \kernel{U} &:= (\gamma\otimes \mathrm{Id}^D)\kernel{T}
\end{align}
Is a Bayesian see-do model.
\end{theorem}

\begin{proof}

It nees to be shown that $\RV{X}\CI_{\kernel{U}}\RV{D}$.

By definition
\begin{align}
\kernel{U}^{\RV{X}|\RV{D}} &= \kernel{U}\kernel{F}^{\RV{X}}\\
                            &= (\gamma\otimes \mathrm{Id}^D)\kernel{T}\kernel{F}^{\RV{X}}\\
                            &= \begin{tikzpicture} \path (0,0) node[dist] (T) {$\gamma$}
                                    + (0,-1.15) node (D) {$\RV{D}$}
                                    ++ (0.5,0) node[copymap] (copy0) {}
                                    + (0.,-1.15) node[copymap] (copy2) {}
                                    ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
                                    ++ (0.7,0) node[copymap] (copy1) {}
                                    +  (0.9,-1) node[kernel] (C) {$\kernel{T}^{\RV{Y}|\RV{X}\RV{H}\RV{D}}$}
                                    ++ (1.9,0) node (X) {$\RV{X}$}
                                    +  (0,-1) node (Y) {};
                                    \draw (T) -- (O) -- (X);
                                    \draw (copy0) to [out=-90,in=180] ($(C.west) + (0,0)$);
                                    \draw (D) to [out=0,in=180] ($(C.west) + (0,-0.15)$);
                                    \draw (copy1) to [out=-60,in=180] ($(C.west)+ (0,0.15)$);
                                    \draw[-{Rays[n=8]}] (C) -- (Y);
                                \end{tikzpicture}\\
                            &= \begin{tikzpicture} \path (0,0) node[dist] (T) {$\gamma$}
                                    + (0,-1.15) node (D) {$\RV{D}$}
                                    ++ (0.5,0) coordinate (copy0)
                                    ++ (0.7,0) node[kernel] (O) {$\kernel{T}^{\RV{X}|\RV{H}}$}
                                    ++ (0.7,0) coordinate (copy1)
                                    ++ (1.9,0) node (X) {$\RV{X}$}
                                    +  (0,-1) node (Y) {};
                                    \draw (T) -- (O) -- (X);
                                    \draw[-{Rays[n=8]}] (D) -- (Y);
                                \end{tikzpicture}
\end{align}

Which implies $\RV{X}\CI_{\kernel{U}} \RV{D}$ by version (2) of conditional indpendence (Theorem \ref{th:ci_equivalence}).
\end{proof}
% Decisions are similar to the ``regime indicators'' found in \citet{dawid_decision-theoretic_2020}. They coincide precisely if we suppose that the observation and consequence spaces coincide ($X=Y$) and there exists an ``idle'' decision $d^*\in D$ such that $\kernel{C}_{(\cdot,d^*)} = \kernel{O}_{\cdot}$. However, in general we don't require that $\kernel{O}$ and $\kernel{C}$ are related in this manner. This assumption will be revisited in \todo[inline]{A section I haven't written yet}.

\subsubsection{Example}

Suppose we are betting on the outcome of the flip of a possibly biased coin with payout 1 for a correct guess and 0 for an incorrect guess, and we are given $N$ previous flips of the coin to inspect. This situation can be modeled by a decomposable see-do model. Define $\kernel{B}:(0,1)\to \Delta(\{0,1\})$ by $\kernel{B}:\RV{H}\mapsto \mathrm{Bernoulli}(\RV{H})$. Then define ${\kernel{T}}$ by:

\begin{itemize}
    \item Choice set: $D=\{0,1\}$
    \item Observation set: $X=\{0,1\}^N$
    \item Consequence set: $Y=\{0,1\}$
    \item Hypothesis set: $H=(0,1)$
    \item Observation map: ${\kernel{T}}^{\RV{X}|\RV{H}}:\splitter{0.1}^N\kernel{B}$
    \item Consequence model: ${\kernel{T}}^{\RV{Y}|\RV{D}\RV{H}}:(h,d)\mapsto \mathrm{Bernoulli}(1-|d-h|)$
\end{itemize}

In this model, the chance $\RV{H}$ of the coin landing on heads is as much as we can hope to know about the success of our bet. $\RV{H}$ may be inferred from observation by some standard method, and 



\subsubsection{Avoiding indecomposability with decision functions}

\todo[inline]{Show that a decision problem with a indecomposable model induces an equivalent decision problem with a decomposable model with an expanded set of choices, subject to some conditions.}

\subsubsection{Decision rules}

See-do models encode the relationship between observed data and consequences of decisions. In order to actually make decisions, we also require preferences over consequences. We suppose that a \emph{utility function} is given, and evaluate the desirability of consequences using \emph{expected utility}. A see-do model along with a utility allows us to evaluate the desirability of \emph{decisions rules} according to each hypothesis.

\begin{definition}[Utility function]
Given a See-Do Model $\kernel{T}:\RV{H}\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$, a \emph{utility function} $u$ is a measurable function $Y\to \mathbb{R}$. 
\end{definition}

\begin{definition}[Expected utility]
Given a utility function $u:Y\to \mathbb{R}$ and probability measures $\mu,\nu\in \Delta(\sigalg{Y})$, the \emph{expected utility} of $\mu$ is $\mathbb{E}_{\mu}[u]$.

$\mu$ is \emph{preferred} to $\nu$ if $\mathbb{E}_{\mu}[u]\geq \mathbb{E}_{\nu}[u]$, and \emph{strictly preferred} if $\mathbb{E}_{\mu}[u]>\mathbb{E}_{\nu}[u]$.
\end{definition}

\begin{definition}[Decision rule]
Given a see-to map $\kernel{T}:\RV{H}\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$, a \emph{decision rule} is a Markov kernel $X\to \Delta(\sigalg{D})$. A \emph{deterministic decision rule} is a decision rule that is deterministic.

\todo[inline]{Define deterministic Markov kernels}
\end{definition}

Expected utility together with a decision rule gives rise to the definition of \emph{risk}, which connects CSDT to classical statistical decision theory (SDT). For historical reasons, risks are minimised while utilities are maximised.

\begin{definition}[Risk]
Given a see-to map $\kernel{T}:\RV{H}\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$, a utility $u:Y\to \mathbb{R}$ and the set of decision rules $\mathscr{U}$, the \emph{risk} is a function $l:\RV{H}\times \mathscr{U}\to \mathbb{R}$ given by

\begin{align}
    R(\RV{H},\kernel{U}) := - \int_X  \kernel{U}_x \kernel{T}^{\RV{Y}|\RV{D}\RV{X}\RV{H}}_{\cdot,x,\RV{H}} u d\kernel{T}^{\RV{X}|\RV{H}}_\RV{H}(x)
\end{align}

for $\RV{H}\in \RV{H}$, $\kernel{U}\in \mathscr{U}$. Here $\kernel{U}_x \kernel{T}^{\RV{Y}|\RV{D}\RV{X}\RV{H}}_{\cdot,x,\RV{H}} u$ is the product of the measure $\kernel{U}_x$, the kernel $\kernel{T}^{\RV{Y}|\RV{D}\RV{X}\RV{H}}_{\cdot,x,\RV{H}}:D\to \Delta(\sigalg{Y})$ and the function $u$.
\end{definition}

The loss induces a partial order on decision rules. If for all $\RV{H}$, $l(\RV{H},\kernel{U})\leq l(\RV{H},\kernel{U}')$ then $\kernel{U}$ is at least as good as $\kernel{U}'$. If, furthermore, there is some $\RV{H}_0$ such that $l(\RV{H}_0,\kernel{U})<l(\RV{H}_0,\kernel{U}')$ then $\kernel{U}$ is preferred to $\kernel{U}'$.

\begin{definition}[Induced statistical decision problem]
A see-do model $\kernel{T}:\RV{H}\times D\to \Delta(\sigalg{X}\otimes\sigalg{Y})$ along with a utility $u$ induces the \emph{statistical decision problem} $(\RV{H},\mathscr{U},R)$ with states $\RV{H}$, decisions $\mathscr{U}$ and risks $R$.

\todo[inline]{Statistical decision problems usually define the risk via the loss, but it is only possible to define a loss with a decomposable model. We don't actually need a loss, though: the complete class theorem still holds via the induced risk and Bayes risk}

\end{definition}


\section{Existence of counterfactuals}

\todo[inline]{I'm struggling with how to explain this well.}

``Counterfactual'' or ``potential outcomes'' models in the causal inference literature are consequence models where choices can be considered in \emph{parallel}. 

Before defining parallel choices, we will consider a ``counterfactual model'' without parallel choices. Consider the following definitions, first from \citet{pearl_causality:_2009} pg. 203-204. I have preserved his notation, including not using any special fonts for things called ``variables'' because this term is used interchangeably with ``sets of variables'' and using special fonts for variables might give the impression that these should be treated as different things while using special fonts for sets of variables is inconsistent with my usual notation.

\todo[inline]{The real solution here is that Pearl's ``variable sets'' are actually ``coupled variables'', see Definition \ref{def:ctensor}, but I'd rather not change his definitions if I can avoid it}

\todo[inline]{put the following inside a quote environment somehow, the regular quote environment fails due to too much markup}
\vspace{1cm}

```
\paragraph{Definition 7.1.1 (Causal Model)}
A causal model is a triple
$M = \langle U, V, F\rangle$,
where:
\begin{enumerate}[label=(\roman*)]
    \item $U$ is a set of \emph{background} variables, (also called \emph{exogenous}), that are determined by factors outside the model;
    \item $V$ is a set $\{V_1 , V_2 ,..., V_n\}$ of variables, called \emph{endogenous}, that are determined by variables in the model -- that is, variables in $U\cup V$;
    \item $F$ is a set of functions $\{f_1 , f_2 ,..., f_n\}$ such that each $f_i$ is a mapping from (the respective domains of) $U_i \cup PA_i$ to $V_i$, where $U i \subseteq U$ and $PA_i \subseteq V \setminus V_i$ and the entire set $F$ forms a mapping from $U$ to $V$. In other words, each $f_i$ in $$v_i = f_i (pa_i , u_i ),\qquad  i\in 1, ... n,$$ assigns a value to $V_i$ that depends on (the values of) a select set of variables in $V \cup U$, and the entire set $F$ has a unique solution $V(u)$.
\end{enumerate}

\paragraph{Definition 7.1.2 (Submodel)}
Let $M$ be a causal model, $X$ a set of variables in $V$, and $x$ a particular realization of $X$. A submodel $M_x$ of $M$ is the causal model $$M_x =\{U, V, F_x\},$$ where $$F_x = \{ f_i : V_i \notin X\}\cup\{ X = x\}.$$

\paragraph{Definition 7.1.3 (Effect of Action)}
Let $M$ be a causal model, $X$ a set of variables in $V$, and $x$ a particular realization of $X$. The effect of action $do(X=x)$ on $M$ is given by the submodel $M_x$

\paragraph{Definition 7.1.4 (Potential Response)}
Let $X$ and $Y$ be two subsets of variables in $V$. The potential response of $Y$ to action $do(X = x)$, denoted $Y_x(u)$, is the solution for $Y$ of the set of equations $F_x$, that is, $Y_x(u) = Y_{M_x}(u)$.

\paragraph{Definition 7.1.6 (Probabilistic Causal Model)}
A probabilistic causal model is a pair $\langle M, P(u)\rangle$, where $M$ is a causal model and $P(u)$ is a probability function defined over the domain of U.
'''


\vspace{1cm}

Implicitly, Definition 7.1.3 proposes a set of ``actions'' that have ``effects'' given by $M_x$. It's not entirely clear what this set of actions should be -- the definition seems to suggest that there is an action for each ``realization'' of each variable in $V$, which would imply that the set of actions corresponds to the range of $V$. For the following discussion, we will call the set of actions $D$, whatever it actually contains (we have deliberately chosen to use the same letter as we use to represent choices or actions in see-do models).

Given $D$, Definition 7.1.3 appears to define a function $h:\mathscr{M}\times D\to \mathscr{M}$, where $\mathscr{M}$ is the space of causal models with background variables $U$ and endogenous variables $V$, such that for $M\in \mathscr{M}$, $do(X=x)\in D$, $h(M,do(X=x))=M_x$.

Definition 7.1.4 then appears to define a function $Y_\cdot(\cdot):D\times U\to Y$ (distinct from $Y$, which appears to be a function $U\to\text{something}$) and calls $Y_\cdot(\cdot)$ the ``potential response''. We could always consider the variable $\RV{V}:=\utimes_{i\in [n]} \RV{V}_i$ and define the ``total potential response'' $\mathbf{g}:=\RV{V}_\cdot(\cdot)$, which captures the potential responses of any subset of variables in $V$.

From this, we might surmise that in the Pearlean view, it is necessary that a ``counterfactual'' or ``potential response'' model has a probability measure $P$ on background variables $U$, a set of actions $D$ and a \emph{deterministic} potential response function $\mathbf{g}:D\times U\to V$.

Pearl's model also features a second deterministic function $\mathbf{f}:U\to Y$, and $G$ is derived from $F$ via the equation modifications permitted by $D$. It is straightforward to show that an arbitrary function $\mathbf{f}:U\to Y$ can be constructed from Pearl's set of functions $f_i$, and if $D$ may modify the set $F$ arbitrarily, then it appears that $\mathbf{g}$ can in principle be an arbitrary function $D\times U\to Y$ (though many possible choices would be quite unusual).

Pearl's counterfactual model seems to essentially be a deterministic map $\mathbf{g}:D\times U\to V$ along with a probability measure $P$ on $U$. Putting these together and marginalising over $U$ (as we might expect we want to do with ``background variables'') simply yields a consequence map $D\to \Delta(\sigalg{V})$, which doesn't seem to have any special counterfactual properties.

In order to pose counterfactual questions, Pearl introduces the idea of holding $U$ fixed:
\\
````
\paragraph{Definition 7.1.5 (Counterfactual)}
Let $X$ and $Y$ be two subsets of variables in $V$. The counterfactual sentence ``$Y$ would be $y$ (in situation $u$), had $X$ been $x$'' is interpreted as the equality $Y_x(u) = y$, with $Y_x(u)$
being the potential response of $Y$ to $X = x$.'
'''
\\

Holding $U$ fixed allows SCM counterfactual models to answer questions about what would have happened if we had taken different actions given the same background context. For example, we can compare $Y_x(u)$ with $Y_{x'}(u)$ and interpret the comparison as telling us what would have happened in the same situation $u$ if we did $x$ and, at the same time, what would happen if we did $x'$. It is the ability to consider different actions ``in exactly the same situation'' that makes these models ``counterfactual''.

One obvious question is: does $\mathbf{g}$ have to be deterministic? While SCMs are defined in terms of deterministic functions with noise arguments, it's not clear that this is a necessary feature of counterfactual models. If $\mathbf{g}$ were properly stochastic, what is the problem with considering $\mathbf{g}(x,u)$ and $\mathbf{g}(x',u)$ to represents what would happen in a fixed situation $u$ if I did $x$ and if I did $x'$ respectively? In fact, a nondeterministic $\mathbf{g}$  arguably fails to capture a key intuition of taking actions ``in exactly the same situation''. If I want to know the result of doing action $x$ and, in exactly the same situation, the result of doing action $x$, then one might intuitively think that the result should always be \emph{deterministically the same}. This property, which we call \emph{deterministic reproducibility}, does not hold if we consider a nondeterministic potential response map $\mathbf{g}$.

This idea of doing $x$ and, in the same situation, doing $x$ doesn't render very well in English. Furthermore, even though deterministic reproducibility seems to be an important property of counterfactual SCMs, they don't help very much to elucidate the idea. ``If I take action $x$ in situation $U$ I get $V_x(u)$ and if I take action $x$ in situation $U$ I get $V_x(u)$'' is just a redundant repetition. It seems that we want some way to express the idea of having two copies of $V_x(u)$ or, more generally, having multiple copies of a potential response function in such a way that we can make comparisons between their results.

The idea that we need \emph{can} be clearly expressed with a see-do model. 
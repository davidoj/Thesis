
%!TEX root = main.tex



\section{Theories of causal inference}

\todo[inline]{Feedback start here}

Beginning in the 1930s, a number of associations between cigarette smoking and lung cancer were established: on a population level, lung cancer rates rose rapidly alongside the prevalence of cigarette smoking. Lung cancer patients were far more likely to have a smoking history than demographically similar individuals without cancer and smokers were around 40 times as likely as demographically similar non-smokers to go on to develop lung cancer. In laborotory experiments, cells which were introduced to tobacco smoke developed \emph{ciliastasis}, and mice exposed to cigarette smoke tars developed tumors\citep{proctor_history_2012}. Nevertheless, until the late 1950s, substantial controversy persisted over the question of whether the available data was sufficient to establish that smoking cigarettes \emph{caused} lung cancer. Cigarette manufacturers famously argued against any possible connection \citep{oreskes_merchants_2011} and Roland Fisher in particular argued that the available data was not enough to establish that smoking actually caused lung cancer \citep{fisher_cancer_1958}. Today, it is widely accepted that cigarettes do cause lung cancer, along with other serious conditions such as vascular disease and chronic respiratory disease \citep{world_health_organisation_tobacco_nodate,wiblin_why_2016}.

The question of a causal link between smoking and cancer is a very important one to many different people. Individuals who enjoy smoking (or think they might) may wish to avoid smoking if cigarettes pose a severe health risk, so they are interested in knowing whether or not it is so. Additionally, some may desire reassurance that their habit is not too risky, whether or not this is true. Potential and actual investors in cigarette manufacturers may see health concerns as a barrier to adoption, and also may personally want to avoid supporting products that harm many people. Like smokers, such people might have some interest in knowing the truth of this question, and a separate interest in hearing that cigarettes are not too risky, whether or not this is true. Governments and organisations with a responsibility for public health may see themselves as having responsibility to discourage smoking as much as possible if smoking is severely detrimental to health. The costs and benefits of poor decisions about smoking are large: 8 million annual deaths are attributed to cigarette-caused cancer and vascular disease in 2018\citep{world_health_organisation_tobacco_nodate} while  global cigarette sales were estimated at US\$711 billion in 2020 \citep{noauthor_cigarettes_nodate} (a figure which might be substantially larger if cigarettes were not widely believed to be harmful).

The question of whether or not cigarette smoking causes cancer illustrates two key facts about causal questions: First, having the right answers to causal questions is of tremendous importance to huge numbers of people. Second, confusion over causal questions can persist even when a great deal of data and facts relevant to the question are agreed upon.

Causal conclusions are often justified on the basis of ad-hoc reasoning. For example \citet{krittanawong_association_2020} state:

\begin{quote}
[...] the potential benefit of increased chocolate consumption, reducing coronary artery disease (CAD) risk is not known. We aimed to explore the association between chocolate consumption and CAD.
\end{quote}

It is not clear whether Krittanawong et. al. mean that a negative association between chocolate consumption and CAD implies that increased chocolate consumption is likely to reduce coronary artery disease (which is suggested by the word ``benefit''), or that an association may be relevant to the question and the reader should draw their own conclusions. Whether the implication is being suggested by Krittanawong et. al. or merely imputed by na\"ive readers, it is being drawn on an ad-hoc basis -- no argument for the implication can be found in this paper. As \citet{pearl_causality:_2009} has forcefully argued, additional assumptions are always required to answer causal questions from associational facts, and stating these assumptions explicitly allows those assumptions to be productively scrutinised.

For causal questions that are controversial or difficult, it is tremendously advantageous to be able to address them transparently. Theories of causation enable this; given a theory of causation and a set of assumptions, if anyone claims that some conclusion follows it is publicly verifiable whether or not it actually does so. If the deduction is correct, then any remaining disagreement must be in the assumptions or in the theory. For people who are interested in understanding what is true, pinpointing disagreement can be enlightening. Someone could learn, for example, that there are assumptions that they find plausible that permit conclusions they did not initially believe. Alternatively, if a motivated conclusion follows only from implausible assumptions, hearing these assumptions explicitly might make the conclusion less attractive. 

Theories of causation help us to answer causal questions, which means that before we have any theory, we already have causal questions we want to answer. If potential outcomes notation and causal graphical models had never been invented there would still be just as many people who want to the answer to questions something like ``does smoking causes cancer?'', even if on-one could say what exactly they meant by ``causes'' and even if many people actually want answers to slightly different questions. Theories exist to serve our need for transparent answers to causal questions.

Potential outcomes and causal graphical models are prominent examples of ``practical theories'' of causation. I call them ``practical theories'' because most of the time we encounter them they are being used to answer ``practical'' questions like ``Does smoking cause cancer?'', or ``In general, when does data allow us to conclude that $X$ causes $Y$?'' It is less common to see the ``fundamental questions'' addressed, like ``Does the theory of causal graphical models offer an adequate account of what `cause' means?'', which is more often found in the field of philosophy. \citet{spirtes_causation_1993} explain their motivation to study what I call ``practical theories of causation'' as follows:

\begin{quote}
One approach to clarifying the notion of causation -- the philosophers’ approach ever since Plato -- is to try to define ``causation'' in other terms, to provide necessary and sufficient and noncircular conditions for one thing, or feature or event or circumstance, to cause another, the way one can define ``bachelor'' as ``unmarried adult male human.'' Another approach to the same problem -- the mathematician’s approach ever since Euclid -- is to provide axioms that use the notion of causation without defining it, and to investigate the necessary consequences of those assumptions. We have few fruitful examples of the first sort of clarification, but many of the second [...]
\end{quote}

I think what Spirtes, Glymour and Scheines (henceforth: SGS) mean here is that they \emph{define} a notion of causation -- because causal graphical models do define a notion of causation -- without interrogating whether it means the same thing as the word ``causation''. Incidentally, since publication of this paragraph, the notion of causation defined by causal graphical models has been subject to substantial interrogation by philosophers \citep{woodward_causation_2016}.

I am sympathetic to the argument that it does not matter a great deal whether ``causal-graphical-models-causation'' and ``causation'' mean the same thing in everyday language. It is common for words to have somewhat different meanings when used by specialists to when they are used by laypeople, and this isn't because the specialists are ignorant or confused about their subject. However, I think it matters a lot which causal questions can be transparently answered by ``causal-graphical-models-causation'', and so I believe that the notions of causation adopted by practical theories do warrant scrutiny.

I think one reason that SGS are keen to avoid dwelling on the definition of causation is that satisfactory definitions of causation are difficult. For example, causal graphical models depend on the notion of \emph{causal relationships} between variables. These may be defined as follows:

\begin{quote}
$\RV{X}_i$ is a \emph{cause} of $\RV{X}_j$ if there is an \emph{ideal intervention} on $\RV{X}_i$ that changes the value $\RV{X}_j$
\end{quote}

This definition is incomplete without a definition of ``ideal interventions''. Ideal interventions may be defined by their action in ``causally sufficient models'':
\begin{itemize}
    \item An $[\RV{X}_i,\RV{X}_j]$-ideal intervention is an operation whose result is determined by applying the \emph{do-calculus} to a \emph{causally sufficient} model $((\Omega,\mathcal{F},\prob{P}),\diagram{G},\vecRV{U})$
    \item A model $((\Omega,\mathcal{F},\prob{P}),\diagram{G},\vecRV{U})$ is $[\RV{X}_i,\RV{X}_j]$-causally sufficient if $\RV{U}$ contains $\RV{X}_i$, $\RV{X}_j$ and ``all intervenable variables that \emph{cause}'' both $\RV{X}_i$ and $\RV{X}_j$ \footnote{Weaker conditions for causal sufficiency are possible, but they don't avoid circularity \citep{shpitser_complete_2008}}
\end{itemize}

While I don't offer a definition of the \emph{do-calculus} in this introduction, it can be rigorously defined, see for example \citet{pearl_causality:_2009}. The problem is that the definition of a \emph{causally sufficient} model itself invokes the word \emph{cause}, which is what the original definition was trying to address. Circularity is a recognised problem with interventional definitions of causation \citep{woodward_causation_2016}. In Section \ref{sec:cbns_without_d}, I further show models with ideal interventions generally have counterintuitive properties. The purpose of a theory of causation like causal graphical models is to support transparent reasoning about causal questions, and a circular definition that leads to counterintuitive conclusions undermines this purpose.

As with Euclid's parallel postulate, I think it is reasonable to ask if the notion of ideal interventions and other causal definitions can be modified or avoided. Causal statistical decision theory (CSDT) is a theory of causation that is motivated by the problem of \emph{what is generally needed to answer causal questions} rather than \emph{what does ``causation'' mean?} Along similar lines to CSDT, \citet{dawid_decision-theoretic_2020} has observed that the problem of deciding how to act in light of data can be formalised without appeal to theories of causation. We develop this in substantial detail, showing how both \emph{interventional models} and \emph{counterfactual models} arise as special cases of CSDT.\todo{I want to revisit the claims about what I actually show, hopefully to add to it}

A key feature of CSDT is what I call the \emph{option set}. This is the set of decisions, acts or counterfactual propositions under consideration in a given problem. A causal graphical model and a potential outcomes model will both implicitly define an option set as a result of their basic definitions of causation, but CSDT demands that this is done explicitly. I argue that this is a key strength of CSDT, on the basis of the following claims which I defend in the following chapters:

\begin{itemize}
    \item Causal questions are not well-posed without an option set in the same way a function is not well-defined without its domain
    \item The option set need not correspond in any fixed manner to the set of observed variables
    \item The nature of the option set can affect the difficulty of causal inference questions
\end{itemize}


\todo[inline]{I commented out an additional section about potential outcomes and closest world counterfactuals, which is a second example of ``opaque causal definitions''. I'm interested if any readers think it would be good to have a second example}


% Potential outcomes basic assumptions

% \begin{itemize}
%     \item Potential outcomes defines ``the treatment effect of $\RV{X}_i$ on $\RV{X}_j$'' in terms of the value of $\RV{X}_j$ under the \emph{counterfacutal supposition} that $\RV{X}_i$ had taken a different value
% \end{itemize}

% In fact, the notion of ``ideal intervention'' often seems to underpin potential outcomes models as well. Work in the potential outcomes theory often uses the idea of the value of $\RV{X}_j$ under a counterfactual supposition concerning $\RV{X}_i$ interchangeably with the idea the response of $\RV{X}_j$ to an idealised intervention on $\RV{X}_i$ \citep{morgan_counterfactuals_2014,rubin_causal_2005,richardson2013single}. \cite{lewis_causation_1986} offered a definition of the value $\RV{X}_j$ under counterfactual suppositions in terms of the value it would take in the world that was ``closest'' to the real world but in which the value of $\RV{X}_i$ was altered. There are many ways that we could use to measure how close one world is to another, many of which need not invoke any notion of ``ideal intervention'', but I have never encountered practical work on causal inference that was based on considerations of such similarity measures.

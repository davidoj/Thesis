%!TEX root = main.tex

\chapter{Decision problems with repeatable phenomena}\label{ch:evaluating_decisions}

Chapter \ref{ch:tech_prereq} introduced probability sets as generic tools for causal modelling, while Chapter \ref{ch:2p_statmodels} examined how probability set models fit into existing work addressing the question of how to construct mathematical models of decision problems. Both chapters deal with probability sets with minimal amounts of structure. Section \ref{sec:cons_to_sdp} introduced \emph{see-do} models, which feature observations, consequences, decisions and hypotheses and some assumptions relating these different elements, but no particular assumptions are made about (for example) the form of the observations. Causal models that solve ``practical problems'' typically have a lot more structure than this.

This chapter is concerned with examining the basic assumptions that underpin practical causal models. Causal and non-causal statistical problems usually concern repeatable phenomena -- that is, the measurement procedure that is being modeled is assumed to break down into a sequence of subprocedures that are, in some sense, all similar to one another. In non-causal problems, the sense of similarity is sometimes expressed by the assumption of \emph{exchangeability}, which is the assumption that swapping the subprocedures does not have any effect on the appropriate model of the phenomenon. This assumption is not applicable to causal problems, because generally different choices will lead to different actions being taken for different subprocedures. The key idea in this chapter is the idea of a \emph{repeatable response function} -- this is the idea that (roughly speaking) each subprocedure features ``input'' and ``output'' variables such that the mapping from input to output is interchangeable.

The key result is the representation of a sequence of subprocedures as a mixture of repeatable response functions is equivalent to the assumption of \emph{causal contractibility}, a generalisation of exchangeability. In the general case, where the input for the $i$th subprocedure can depend on the results of the subprocedures prior to $i$, causal contractibility is required of a \emph{comb} induced by the probability set, a generalisation of the notion of a conditional probability. If inputs to each subprocedure are independent of data produced prior, then the comb reduces to a conditional probability. Causal contractibility is the union of an assumption of a particular kind of exchangeability, and a conditional independence assumption, both of which can be found separately in prior literature.

Causal contractibility is a more complicated assumption than exchangeability, and it is not obvious how to assess when it is appropriate or not. One implications of causal contractibility is the equality of reduced conditionals (Theorem \ref{th:equal_of_condits}), which is argued to rule out causal contractibility in some situations where passive observations are mixed with data from active intervention. A second contribution is to show that when subprocedures are associated with \emph{interchangeable unique identifiers} and the inputs are deterministically controlled, then causal contractibility holds.

Causal contractibility is a very strong assumption, and it appears to generally be unacceptable assumption when data from passive observations is mixed with data from active intervention. A weaker but more widely applicable assumption is examined: ``what will be done has been done already, and will be done again'' \todo{Ecclesiastes' assumption?}. This is the assumption that, no matter what choice is made, some subsequence of observations can be found that are distributed identically to the consequences. This assumption leads to a certain kind of ``unobserved confounder''.

\section{Relevance to previous work}

This chapter draws on three different lines of work. The first is the study of representations of symmetric of probability models. The equivalence between infinite exchangeable probability models and mixtures of independent and identically distributed models was shown by \cite{de_finetti_foresight_1992}. This result has been extended in many ways, including to finite sequences \citet{kerns_definettis_2006,diaconis_finite_1980} and for partially exchangeable arrays \citet{aldous_representations_1981}. A comprehensive overview of results is presented in \citet{kallenberg_probabilistic_2005}. This work is only engaged shallowly with this literature, but the idea that symmetries of probabilistic models may imply representability as mixtures of ``fixed but unknown'' models is crucial, as is basic result of De Finetti.

The second line of work is the study of exchangeability-like assumptions in causal models in particular. \citet{dawid_decision-theoretic_2020} defines \emph{post-treatment exchangeability}, closely related to \emph{exchange commutativity} (Definition \ref{def:caus_exch}), one of the two conditions constituting causal contractibility. \citet{greenland_identifiability_1986} discusses the assumption of ``exchangeability of individuals'' in a medical experiment that also suggests the key idea of exchange commutativity. \citet{banerjee_chapter_2017} also mention the condition that ``subjects are exchangeable conditional on covariates, so that experiments identical up to a permutation of labels are equivalent from the perspective of the experimenter'', which is similarly suggestive of exchange commutativity. While both of these are suggestive of exchange commutativity, exchanging \emph{individuals} is a transformation of measurement procedures, not an operation defined on a probability model, and so it does not automatically imply any particular properties of the model. Exchange commutativity, on the other hand, is a symmetry of Markov kernels which might be appealing in situations where measurement procedures with individuals exchanged are regarded as essentially the same. \citet{rubin_causal_2005} discusses the assumption of the exchangeability of potential outcomes.

The other component of causal contractibility is \emph{consequence locality} (Definition \ref{def:caus_cont}). This is also suggested by existing work -- in particular, the stable unit treatment distribution assumption (SUTDA) in \citet{dawid_decision-theoretic_2020}, and the stable unit treatment value assumption (SUTVA) in \citep{rubin_causal_2005}:
\begin{blockquote}
(SUTVA) comprises two sub-assumptions. First, it assumes that \emph{there is no interference between units (Cox 1958)}; that is, neither $Y_i(1)$ nor $Y_i(0)$ is affected by what action any other unit received. Second, it assumes that \emph{there are no hidden versions of treatments}; no matter how unit $i$ received treatment $1$, the outcome that would be observed would be $Y_i(1)$ and similarly for treatment $0$.
\end{blockquote}

Finally, the idea of \emph{combs} in probabilistic models was first proposed by \citet{chiribella_quantum_2008} and an application to causal models was developed by \citet{jacobs_causal_2019}.

\section{Repeatable Response Functions}\label{sec:response_functions}

Start with a sequence of variable pairs $(\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}}$ where $\RV{X}_i$ is the $i$th ``input'' and $\RV{Y}_i$ is the corresponding ``output'', each taking values in $X$ and $Y$ respectively. A ``repeatable response function'' is a probabilistic mapping $X\kto Y$ that is identical for all $(\RV{X}_i,\RV{Y}_i)$ pairs. Repeatable response functions are in general be unknown, in which case (under a Bayesian model $\prob{P}_C$), the response function is \emph{not} the conditional $\prob{P}_C^{\RV{Y}_i|\RV{X}_i}$ but rather the conditional $\prob{P}_C^{\RV{Y}_i|\RV{X}_i\RV{H}}$ where $\RV{H}$ is an unobserved hypothesis variable. ``Repeatability'' also means that the same response function can be obtained no matter which actions have already been taken. That is, $\RV{Y}_i$ is independent of previous input-output pairs when conditioned on $\RV{H}$ and $\RV{X}_i$.

The result of this section is that the pairs in a sequence $(\RV{X},\RV{Y}):=(\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}}$ modeled by $\prob{P}_C$ are related by repeatable repeatable response functions if and only if there is a causally contractible \emph{uniform comb} $\prob{P}_C^{\RV{Y}\combbreak\RV{X}}$. Combs are a generalisation of conditional probabilities and, and if we assume that actions are independent of previous data ($\RV{X}_i\CI_{\prob{P}_C}^e \RV{Y}_{<i} C|\RV{X}_{<i}$), this reduces to the assumption that the uniform conditional distribution $\prob{P}_C^{\RV{Y}|\RV{X}}$ is causally contractible.

Because combs are unfamiliar, this section is structured so that the ``data-independent actions'' case is introduced first. Specifically, the representation theorem is proven for general Markov kernels in Section \ref{sec:ccontracibility}, and applied to models $\prob{P}_C$ with data-independent actions in Section \ref{sec:data_independent_actions}. Subsequently, combs are introduced in Section \ref{sec:data_dependent}, and the general result applied to models with data-dependent actions. The following section, Section \ref{sec:assessing}, discusses questions related to when the assumption of causal contractibility might be held to apply to a particular problem, as well as introducing ``Ecclesiastes' assumption'', a weaker assumption than causal contractibility which could be applied to problems where observations and active interventions are mixed.


\subsection{Causally contractible Markov kernels}\label{sec:ccontracibility}

Here a representation theorem is proved for causally contractible Markov kernels. First, causal contractibility is defined, which is the conjunction of the sub-assumptions of \emph{locality} and \emph{exchange commutativity}. 

The intuitive basis of the two sub-assumptions is easier to see for Markov kernels with just two input-output pairs. In that simplified case, exchange commutativity for two inputs and outputs is given by the following equality:
\begin{align}
    \tikzfig{commutativity_of_exchange}
\end{align}
It expresses the idea that swapping the inputs is equivalent to swapping the outputs. Locality is given by the following pair of equalities:
\begin{align}
    \tikzfig{cons_locality_1}\\
    \tikzfig{cons_locality_2}
\end{align}
and expresses the notion that the outputs are independent of the non-corresponding input, conditional on the corresponding input.

\subsubsection{Definition of causal contractibility}

The general definitions follow.

\begin{definition}[Locality]\label{def:caus_cont}
A Markov kernel $\kernel{K}:X^{\mathbb{N}}\kto Y^{\mathbb{N}}$ is \emph{local} if for all $n\in \mathbb{N}$, $A_i\in \sigalg{Y}$, $(x_{[n]},x_{[n]^C})\in\mathbb{N}$ there exists $\kernel{L}:X^n\kto Y^n$ such that
\begin{align}
    \tikzfig{local_lhs} &= \tikzfig{local_rhs}\\
    &\iff\\
    \kernel{K}(\bigtimes_{i\in [n]} A_i\times Y^{\mathbb{N}}|x_{[n]},x_{[n]^C}) &= \kernel{L}(\bigtimes_{i\in [n]} A_i|x_{[n]})
\end{align}
\end{definition}

\begin{definition}[Exchange commutativity]\label{def:caus_exch}
A Markov kernel $\kernel{K}:X^{\mathbb{N}}\kto Y^{\mathbb{N}}$ \emph{commutes with exchange} if for all finite permutations $\rho:\mathbb{N}\to\mathbb{N}$, $A_i\in \sigalg{Y}$, $(x_{[n]},x_{[n]^C})\in\mathbb{N}$
\begin{align}
    \kernel{K}\mathrm{swap}_{\rho,Y} &=  \mathrm{swap}_{\rho,X} \kernel{K}\\
    &\iff\\
    \kernel{K}(\bigtimes_{i\in\mathbb{N}} A_{\rho(i)}|(x_i)_{i\in {\mathbb{N}}}) &= \kernel{K}(\bigtimes_{i\in\mathbb{N}} A_{i}|(x_{\rho(i)})_{i\in {\mathbb{N}}})
\end{align}
\end{definition}

Causal contractibility is the conjunction of both assumptions.
\begin{definition}[Causal contractibility]
A Markov kernel $\kernel{K}:X^{\mathbb{N}}\kto Y^{\mathbb{N}}$ is \emph{causally contractible} if it is local and commutes with exchange.
\end{definition}

\subsubsection{Properties of causally contractible Markov kernels}

A causally contractible Markov kernel over a sequence of pairs treats all subsequences as equivalent in a particular way (Theorem \ref{th:equal_of_condits}, although the sense in which this implies equivalence of subsequences might be more obvious from the statement of Theorem \ref{th:equal_of_reduced_condits} presented later). This feature is the motivation for the name \emph{causal contractibility}. Both sub-assumptions are independent -- Theorem \ref{th:no_implication} presents counterexamples.

Before these theorems are proved, the following definition and Lemma will prove helpful.

All swaps can be written as a product of transpositions, so proving that a property holds for all finite transpositions is enough to show it holds for all finite swaps. It's useful to define a notation for transpositions.
\begin{definition}[Finite transposition]
Given two equally sized sequences $A=(a_i)_{i\in [n]}$, $B=(b_i)_{i\in [n]}$, ${A\leftrightarrow B}:\mathbb{N}\to \mathbb{N}$ is the permutation that sends the $i$th element of $A$ to the $i$th element of $B$ and vise versa. Note that $A\leftrightarrow B$ is its own inverse.
\end{definition}

Lemma \ref{lem:infinitely_extended_kernels} is used to extend finite sequences to infinite ones, and is used in a number of upcoming theorems.

\begin{lemma}[Infinitely extended kernels]\label{lem:infinitely_extended_kernels}
Given a collection of Markov kernels $\kernel{K}_i:X^i\kto Y^i$ for all $i\in \mathbb{N}$, if we have for every $j>i$
\begin{align}
    \kernel{K}_j(\text{id}_{X_i}\otimes \text{del}_{X_{j-i}}) &= \kernel{K}_i\otimes \text{del}_{X_{j-i}}\label{eq:marginalise_comb}
\end{align} 
then there is a unique Markov kernel $\kernel{K}:X^{\mathbb{N}}\kto Y^{\mathbb{N}}$ such that for all $i,j\in \mathbb{N}$,$j>i$
\begin{align}
    \kernel{K}(\text{id}_{X_i}\otimes \text{del}_{X_{j-i}})&= \kernel{K}_i\otimes \text{del}_{X_{j-i}}
\end{align}
\end{lemma}

\begin{proof}
Take any $x\in X^{\mathbb{N}}$ and let $x_{|m}\in X^n$ be the first $n$ elements of $x$. By Equation \ref{eq:marginalise_comb}, for any $A_i\in \sigalg{Y}$, $i\in [m]$
\begin{align}
    \kernel{K}_n(\bigtimes_{i\in [m]}A_i\times Y^{n-m}|x_{|n}) &= \kernel{K}_m(\bigtimes_{i\in [m]}A_i|x_{|m})
\end{align}

Furthermore, by the definition of the $\mathrm{swap}$ map for any permutation $\rho:[n]\to[n]$
\begin{align}
    \kernel{K}_n\mathrm{swap}_{\rho}(\bigtimes_{i\in [m]}A_{\rho(i)}\times Y^{n-m}|x_{|n}) &= \kernel{K}_n(\bigtimes_{i\in [m]}A_{i}\times Y^{n-m}|x_{|n})
\end{align}
thus by the Kolmogorov Extension Theorem \citep{cinlar_probability_2011}, for each $x\in X^{\mathbb{N}}$ there is a unique probability measure $\prob{Q}_x\in \Delta(Y^{\mathbb{N}}$ satisfying
\begin{align}
    \prob{Q}_d(\bigtimes_{i\in [n]}A_i\times Y^{\mathbb{N}}) &= \kernel{K}_n(\bigtimes_{i\in [n]}A_{\rho(i)}|d_{|n})\label{eq:q_is_Markov}
\end{align}

Furthermore, for each $\{A_i\in\sigalg{Y}|i\in \mathbb{N}\}$, $n\in \mathbb{N}$ note that for $p>n$
\begin{align}
\prob{Q}_d(\bigtimes_{i\in[n]} A_i \times Y^{\mathbb{N}})&\geq \prob{Q}_d(\bigtimes_{i\in [p]} A_i\times Y^{\mathbb{N}})\\
&\geq \prob{Q}_d(\bigtimes_{i\in \mathbb{N}} A_i)
\end{align}
so by the Monotone convergence theorem, the sequence $\prob{Q}_d(\bigtimes_{i\in[n]} A_i)$ converges as $n\to \infty$ to $\prob{Q}_d(\bigtimes_{i\in\mathbb{N}} A_i)$. $d\mapsto \prob{Q}_d^{\RV{Z}_n}(\bigtimes_{i\in[n]} A_i)$ is measurable for all $n$, $\{A_i\in\sigalg{Y}|i\in \mathbb{N}\}$ by Equation \ref{eq:q_is_Markov}, and so $d\mapsto Q_d$ is also measurable.

Thus $d\mapsto Q_d$ is the desired $\prob{P}_C^{\RV{Y}_{\mathbb{N}}\combbreak \RV{D}_{\mathbb{N}}}:D^\mathbb{N}\kto Y^\mathbb{N}$.
\end{proof}

Theorem \ref{th:equal_of_condits} shows that, given a causally contractible kernel, the following operations yield equivalent results:
\begin{itemize}
    \item Marginalising all but the first $n$ outputs
    \item Marginalising all outputs except for the positions $A\subset\mathbb{N}$ where $|A|=n$, and swapping the first $n$ inputs with the elements of $A$
\end{itemize}

\begin{definition}[Marginalising kernel]
Given $(X,\sigalg{X})$ and $A\subset\mathbb{N}$, $\mathrm{marg}_A:X^\mathbb{N}\kto X^A$ is the Markov kernel given by
\begin{align}
    \bigotimes_{i\in \mathbb{N}} \text{switch}_{A,i}
\end{align}
where
\begin{align}
    \text{switch}_A &= \begin{cases}
                        \text{id}_X&i\in A\\
                        \text{del}_X&i\not\in A
                        \end{cases}
\end{align} 
\end{definition}

\begin{theorem}[Equality of equally sized contractions]\label{th:equal_of_condits}
A Markov kernel $\kernel{K}:X^{\mathbb{N}}\kto Y^{\mathbb{N}}$ is \emph{causally contractible} if and only if for every $n\in \mathbb{N}$ and every $A\subset\mathbb{N}$ there exists some $\kernel{L}:X^n\kto Y^n$ such that
\begin{align}
    \kernel{K} \text{marg}_A &= \text{swap}_{[n]\leftrightarrow A} \kernel{L}\otimes \text{del}_{X^{\mathbb{N}}}
\end{align}
\end{theorem}

\begin{proof}
Only if:
By exchange commutativity
\begin{align}
    \text{swap}_{[n]\leftrightarrow A} \kernel{K} &= \kernel{K} \text{swap}_{[n]\leftrightarrow A}
\end{align}
multiply both sides by $\text{swap}_{[n]\leftrightarrow A}$ on the right and, because $\text{swap}_{[n]\leftrightarrow A}$ is its own inverse,
\begin{align}
        \text{swap}_{[n]\leftrightarrow A} \kernel{K}\text{swap}_{[n]\leftrightarrow A} &= \kernel{K}
\end{align}
so
\begin{align}
    \kernel{K}\text{marg}_A &= \text{swap}_{[n]\leftrightarrow A} \kernel{K}\text{swap}_{[n]\leftrightarrow A}\text{marg}_A\\
    &= \text{swap}_{[n]\leftrightarrow A} \kernel{K}\text{marg}_{[n]}
\end{align}
By locality, there exists some $\kernel{L}:X^n\kto Y^n$ such that
\begin{align}
    \kernel{K} \text{marg}_{[n]} &= \kernel{K}(\text{id}_{[n]}\otimes \text{del}_{X^{\mathbb{N}}})\\
     &= \kernel{L}\otimes \mathrm{del}_{X^{\mathbb{N}}}
\end{align}
If:
Taking $A=[n]$ for all $n$ establishes locality.

For exchange commutativity, note that for all $x\in X^{\mathbb{N}}$, $n\in\mathbb{N}$, we have
\begin{align}
    \text{swap}_{A\leftrightarrow [n]} \kernel{K} \text{marg}_A &= \text{swap}_{A\leftrightarrow [n]} \kernel{K} \text{swap}_{A\leftrightarrow [n]} (\text{id}_{[n]}\otimes \text{del}_{X^{\mathbb{N}}})\\
     &= \kernel{K} \text{marg}_{[n]}\\
     &= \kernel{K}(\text{id}_{[n]}\otimes \text{del}_{X^{\mathbb{N}}})
\end{align}
Then by Lemma \ref{lem:infinitely_extended_kernels}
\begin{align}
    \text{swap}_{A\leftrightarrow [n]} \kernel{K} \text{swap}_{A\leftrightarrow [n]} &= \kernel{K}
\end{align}
Consider an arbitrary finite permutation $\rho:\mathbb{N}\to \mathbb{N}$. $\rho$ can be decomposed into a finite set of cyclic permutations on disjoint orbits. Each cyclic permutation is simply the composition of some set of transpositions, and so $\rho$ itself can be written as a composition of a sequence of transpositions. Thus for any finite $\rho:\mathbb{N}\to\mathbb{N}$
\begin{align}
    \text{swap}_{\rho} \kernel{K} \text{swap}_{\rho} &= \kernel{K}
\end{align}
\end{proof}

Theorem \ref{th:no_implication} shows that neither locality nor exchange commutativity is implied by the other.

\begin{theorem}\label{th:no_implication}
Exchange commutativity does not imply locality or vise versa.
\end{theorem}

\begin{proof}
First, a Markov kernel that exhibits exchange commutativity but not locality. Suppose $D=Y=\{0,1\}$ and $\kernel{K}:D^2\kto Y^2$ is given by
\begin{align}
    \kernel{K}(y_1,y_2|d_1,d_2) &= \llbracket (y_1,y_2)= (d_1+d_2,d_1+d_2) \rrbracket
\end{align}
then 
\begin{align}
    \kernel{K}(y_1,Y|d_1,d_2) &= \llbracket y_1 = d_1+d_2 \rrbracket
\end{align}
and there is no function depending on $y_1$ and $d_1$ only that is equal to this. Thus $\kernel{K}$ does not satisfy locality. 

However, taking $\rho$ to be the unique nontrivial swap $\{0,1\}\to \{0,1\}$
\begin{align}
    \text{swap}_{\rho,D}\kernel{K}(y_1,y_2|d_1,d_2) &= \kernel{K}(y_1,y_2|d_2,d_1)\\
    &= \llbracket (y_1,y_2)= (d_2+d_1,d_2+d_1) \rrbracket\\
    &= \llbracket (y_1,y_2)= (d_1+d_2,d_1+d_2) \rrbracket\\
    &= \llbracket (y_2,y_1)= (d_1+d_2,d_1+d_2) \rrbracket\\
    &= \kernel{K}\text{swap}_{\rho,Y}(y_1,y_2|d_1,d_2)
\end{align}
so $\kernel{K}$ commutes with exchange.

Next, a Markov kernel that satisfies locality but does not commute with exchange. Suppose again $D=Y=\{0,1\}$ and $\kernel{K}:D^2\kto Y^2$ is given by
\begin{align}
    \kernel{K}(y_1,y_2|d_1,d_2) &= \llbracket (y_1,y_2)= (0,1) \rrbracket
\end{align}

Then:
\begin{align}
    \kernel{K}(y_1|d_1,d_2) &= \llbracket y_1= 0 \rrbracket\\
    &= \kernel{K}(y_1|d_1)\\
    \kernel{K}(y_2|d_1,d_2)&= \llbracket y_2= 1 \rrbracket\\
    &= \kernel{K}(y_2|d_2)
\end{align}
so $\kernel{K}$ satisfies locality.

However, $\kernel{K}$ does not commute with exchange.
\begin{align}
    \text{swap}_{\rho(\RV{D})} \kernel{K}(y_1,y_2|d_1,d_2) &= \kernel{K}(y_1,y_2|d_2,d_1)\\
    &=\llbracket (y_1,y_2)= (0,1) \rrbracket\\
    &\neq \llbracket (y_2,y_1)= (0,1) \rrbracket\\
    &= \kernel{K}\text{swap}_{\rho(\RV{D})}(y_1,y_2|d_1,d_2)
\end{align}
\end{proof}

A model of the treatment of several patients who have already been examined might satisfy consequence locality but not exchange commutativity. Patient B's treatment could be assumed not to affect patient A, but the same results would not be expected from giving patient A's treatment to patient B as from giving patient A's treatment to patient A. 

A model of economic interventions might satisfy exchange commutativity but not locality. If a government prints money to make exactly $n$ payments of \$10 000 are made to a number of undistinguished recipients, the government cannot say much about the impact of who exactly receives the payment. However, the amount of inflation created by the payments depends on the number of payments made; making 100 such payments will have a negligible effect on inflation, while making payments to everyone in the country will have a substantial effect, and this will in turn affect the outcomes of the people who did or did not receive payment. \citet{dawid_causal_2000} offers the alternative example of herd immunity in vaccination campaigns as a situation where commutativity of exchange holds but locality does not.

Although locality seems to imply a lack of interference between inputs and outputs of different indices, it actually allows for some models with certain kinds of interference between actions and outcomes of different indices. For example: consider an experiment where I first flip a coin and record the results of this flip as the outcome of the ``step 1''. Subsequently, I can choose either to copy the outcome from step 1 to be the input for ``step 2'' (this is the choice $\RV{D}_1=0$), or flip a second coin use this as the input for step 2 (this is the choice $\RV{D}_1=1$). At the second step, I may further choose to copy the provisional results ($\RV{D}_2=0$) or invert them ($\RV{D}_2=1$). Then
\begin{align}
    \prob{P}_S^{\RV{Y}_1|\RV{D}}(y_1|d_1,d_2) &= 0.5\\
    \prob{P}_S^{\RV{Y}_2|\RV{D}}(y_2|d_1,d_2) &= 0.5
\end{align}
\begin{itemize}
    \item The marginal distribution of both experiments in isolation is $\text{Bernoulli}(0.5)$ no matter what choices I make, so a model of this experiment would satisfy Definition \ref{def:caus_cont}
    \item Nevertheless, the choice at step 1 affects the result of step 2
\end{itemize}

\subsubsection{Representation theorems for causally contractible Markov kernels}

Theorem \ref{th:table_rep_kernel} shows that a causally contractible Markov kernel can be represented as the product of a column exchangeable probability distribution and a ``lookup function''. This representation is identical to the representation of potential outcomes models (see, for example, \citet{rubin_causal_2005}), but Theorem \ref{th:table_rep_kernel} applies to arbitrary kernels and the resulting representation will usually not be interpretable as a potential outcomes models. This theorem allows De Finetti's theorem to be applied to the column exchangeable probability distribution, which is a key step in proving the main result (Theorem \ref{th:ciid_rep_kernel}).

\begin{theorem}\label{th:table_rep_kernel}
A Markov kernel $\kernel{K}:X^{\mathbb{N}}\kto Y^{\mathbb{N}}$ is causally contractible if and only if there exists a column exchangeable probability distribution $\mu \Delta(Y^{|X|\times \mathbb{N}})$ such that
\begin{align}
    \kernel{K} &= \tikzfig{lookup_representation_kernel}\label{eq:lup_rep_kernel}\\
    &\iff\\
    \kernel{K}(A|(x_i)_{i\in \mathbb{N}}) &= \mu \Pi_{(x_i i)_{i\in\mathbb{N}}}(A)\forall A\in \sigalg{Y}^{\mathbb{N}}
\end{align}
Where $\Pi_{(d_i i)_{i\in\mathbb{N}}}:Y^{|X|\times \mathbb{N}}\to Y^{\mathbb{N}}$ is the function 
\begin{align}
    (y_{j i})_{j,i \in X\times  \mathbb{N}}\mapsto (y_{d_i i})_{i\in \mathbb{N}}
\end{align}
that projects the $(x_i,i)$ indices of $y$ for all $i\in \mathbb{N}$, and $\prob{F}_{\text{ev}}$ is the Markov kernel associated with the evaluation map
\begin{align}
    \text{ev}:X^\mathbb{N}\times Y^{X\times \mathbb{N}}&\to Y\\
    ((x_i)_\mathbb{N},(y_{ji})_{j,i\in X\times \mathbb{N}})&\mapsto (y_{x_i i})_{i\in \mathbb{N}}
\end{align}
\end{theorem}

\begin{proof}
Only if:
Choose $e:=(e_i)_{i\in\mathbb{N}}$ such that $e_{i+|X|j}$ is the $i$th element of $X$ for all $i,j\in \mathbb{N}$.

Define
\begin{align}
    \mu(\bigtimes_{(i,j)\in X\times \mathbb{N}} A_{ij}):=\kernel{K}(\bigtimes_{(i,j)\in X\times \mathbb{N}} A_{ij}|e)& \forall A_{ij}\in \sigalg{Y}
\end{align}

Now consider any $x:=(x_i)_{i\in \mathbb{N}}\in X^{\mathbb{N}}$. By definition of $e$, $e_{x_i i}=x_i$ for any $i,j\in \mathbb{N}$.

Define
\begin{align}
    \prob{Q}:X^{\mathbb{N}}\kto Y^{\mathbb{N}}\\
    \prob{Q}:= \tikzfig{lookup_representation_kernel}
\end{align}
and consider some $A\subset \mathbb{N}$, $|A|=n$ and $B:= (x_i,i))_{i\in A}$. Note that the subsequence of $e$ indexed by $B$, $e_B:=(e_{x_i i})_{i\in A}=x_A$. Thus given the swap map $\mathrm{swap}_{A\leftrightarrow B}:\mathbb{N}\to\mathbb{N}$ that sends the first element of $A$ to the first element of $B$ and so forth, $\mathrm{swap}_{A\leftrightarrow B} (e_B) = x_A$. For arbitrary $\{C_i\in \sigalg{Y}|i\in A\}$, define $C_A:=\mathrm{swap}_{[n]\leftrightarrow A} (\times_{i\in [n]} C_i\times Y^{\mathbb{N}})$. Then, for arbitrary $x\in X^{\mathbb{N}}$
\begin{align}
    \prob{Q}(C_A|x) &= \mu (\mathrm{ev}_x^{-1}(C_A))\label{eq:q_mu_rel}
\end{align}

The argument of $\mu$ is
\begin{align}
    \mathrm{ev}_x^{-1}(C_A)&=\{(y_{ji})_{j,i\in X\times\mathbb{N}}|(y_{x_i i})_{i\in\mathbb{N}}\in C_A\}\\
    &= \bigtimes_{i\in \mathbb{N}} \bigtimes_{j\in X} D_{ji}
\end{align}
where
\begin{align}
    D_{ji} = \begin{cases}
        C_i & (j,i)\in B\\
        Y & \text{otherwise}
    \end{cases}
\end{align}
and so
\begin{align}
    \text{swap}_{A\leftrightarrow B} (\mathrm{ev}_x^{-1}(C_A)) &= C_A\label{eq:swap_select_relation}
\end{align}

Substituting Equation \ref{eq:swap_select_relation} into \ref{eq:q_mu_rel}
\begin{align}
    \prob{Q}(C_A|x) &= \mu \text{swap}_{A\leftrightarrow B} (C_A)\\
    &= \kernel{K} \text{swap}_{A\leftrightarrow B} (C_A|e)\\
    &= \kernel{K}\text{swap}_{A\leftrightarrow B} (C_A|e_B,\text{swap}_{B\leftrightarrow A}(x)_B^C)&\text{by locality}\\
    &= \kernel{K}\text{swap}_{A\leftrightarrow B} (C_A|\text{swap}_{B\leftrightarrow A}(x))\\
    &= \text{swap}_{B\leftrightarrow A} \kernel{K}\text{swap}_{A\leftrightarrow B} (C_A|x)\\
    &= \kernel{K}(C_A|x)&\text{by commutativity of exchange}
\end{align}

Because this holds for all $x$, $A\subset\mathbb{N}$, by Lemma \ref{lem:infinitely_extended_kernels}

\begin{align}
    \prob{Q} &= \kernel{K}
\end{align}

Next we will show $\mu$ is column exchangeable. Consider any column swap $\text{swap}_{c}:X\times \mathbb{N}\to X\times \mathbb{N}$ that acts as the identity on the $X$ component and a finite permutation on the $\mathbb{N}$ component. From the definition of $e$, $\text{swap}_c(e)=e$. Thus by commutativity of exchange, for any $A\in \sigalg{Y}^{\mathbb{N}}$
\begin{align}
 \kernel{K}(A|e) &= \text{swap}_c\kernel{K}\text{swap}_c(A|e)\\
 &= \kernel{K}\text{swap}_c(A|\text{swap}_c(e))\\
 &= \kernel{K}\text{swap}_c(A|e)
\end{align}


If:
Suppose 
\begin{align}
    \kernel{K} &= \tikzfig{lookup_representation_kernel}
\end{align}
where $\mu$ is column exchangeable, and consider any two $x,x'\in X^{\mathbb{N}}$ such that some subsequences are equal $x_S=x'_T$ with $S,T\subset \mathbb{N}$ and $|S|=|T|=[n]$.

For any $\{A_i\in\sigalg{Y}|i\in S\}$, let $A_S = \text{swap}_{[n]\leftrightarrow S} \times_{i\in [n]} A_i\times Y^{\mathbb{N}}$, $A_T = \text{swap}_{S\leftrightarrow T} (A_S)$, $B=(x_i i)_{i\in S}$ and $C=(x_i i)_{i\in T}=(x_{\text{swap}_{S\leftrightarrow T}}(i) i)_{i\in S}$. By Equations \ref{eq:q_mu_rel} and \ref{eq:swap_select_relation}
\begin{align}
    \kernel{K}(A_S|x) &= \mu \text{swap}_{S\leftrightarrow B} (A_S)\\
    &= \mu \text{swap}_{T\leftrightarrow C} (A_T)&\text{ by column exchangeability of }\mu\\
    &= \kernel{K}(A_T|\text{swap}_{S\leftrightarrow T}(x))\\
    &=  \text{swap}_{S\leftrightarrow T}\kernel{K}(A_T| x)\\
    &= \text{swap}_{S\leftrightarrow T} \kernel{K} \text{swap}_{S\leftrightarrow T} (A_S| x)
\end{align}
so $\kernel{K}$ is causally contractible by Theorem \ref{th:equal_of_condits}.
\end{proof}

Theorem \ref{th:ciid_rep_kernel} is the main result of this section. It shows that a causally contractible Markov kernel $X^{\mathbb{N}}\kto Y^{\mathbb{N}}$ is representable as a ``prior'' $\mu\in \Delta(H)$ and a ``parallel product'' of Markov kernels $H\times X\kto Y$. These will be the response conditionals when Theorem \ref{th:ciid_rep_kernel} is applied to probability set models.

\begin{definition}[Measurable set of probability distributions]
Given a measurable set $(\Omega,\sigalg{F})$, the measurable set of distributions on $\Omega$, $\mathcal{M}_1(\Omega)$, is the set of all probability distributions on $\Omega$ equipped with the coarsest $\sigma$-algebra such that the evaulation maps $\eta_B:\nu\mapsto \nu(B)$ are measurable for all $B\in \sigalg{F}$.
\end{definition}

\begin{theorem}\label{th:ciid_rep_kernel}
Given a kernel $\kernel{K}:X^{\mathbb{N}}\kto Y^{\mathbb{N}}$, let $H:=\mathcal{M}_1(Y^X)$ be the measurable set of probability distributions on $(Y^X,\sigalg{Y}^X)$. $\kernel{K}$ is causally contractible if and only if there is some $\RV{H}:Y^{X\times\mathbb{N}}\to H$ and $\kernel{L}:H\times X\kto Y$ such that
\begin{align}
    \kernel{K} &= \tikzfig{do_model_representation_kernel}\\
    &\iff\\
    \kernel{K}(\bigtimes_{i\in\mathbb{N}}A_i|(x_i)_{i\in\mathbb{N}}) &= \int_H \prod_{i\in\mathbb{N}} \kernel{L}(A_i|h,x_i)\mu\kernel{F}_{\RV{H}}(\mathrm{d}h)
\end{align}
\end{theorem}

\begin{proof}
By Theorem \ref{th:table_rep_kernel}, we can represent the conditional probability $\kernel{K}$ as
\begin{align}
        \kernel{K} &= \tikzfig{lookup_representation_kernel}\label{eq:lookup_representation}
\end{align}
where $\mu$ is column exchangeable.

As a preliminary, we will show
\begin{align}
    \kernel{F}_{\mathrm{ev}} &= \tikzfig{lookup_rep_intermediate_kernel}\label{eq:ev_alternate_rep}
\end{align}
where  $\mathrm{evs}_{Y^D\times D}:Y^D\times D\to Y$ is the single-shot evaluation function
\begin{align}
    (x,(y_i)_{i\in X})\mapsto y_x
\end{align}

Recall that $\mathrm{ev}$ is the function
\begin{align}
    ((x_i)_\mathbb{N},(y_{ji})_{j,i\in X\times \mathbb{N}})&\mapsto (y_{x_i i})_{i\in \mathbb{N}}
\end{align}
By definition, for any $\{A_i\in\sigalg{Y}|i\in \mathbb{N}\}$
\begin{align}
    \kernel{F}_{\mathrm{ev}}(\bigtimes_{i\in \mathbb{N}}A_i|(x_i)_\mathbb{N},(y_{ji})_{i\in X\times \mathbb{N}}) &= \delta_{(y_{x_i i})_{i\in \mathbb{N}}}(\bigtimes_{i\in \mathbb{N}}A_i)\\
        &= \prod_{i\in \mathbb{N}} \delta_{y_{x_i i}} (A_i)\\
        &= \prod_{i\in \mathbb{N}} \kernel{F}_{\text{evs}} (A_i|x_i,(y_{ji})_{j\in X})\\
        &= \left(\bigotimes_{i\in\mathbb{N}} \kernel{F}_{\mathrm{evs}} \right)(\bigtimes_{i\in \mathbb{N}}A_i|(x_i)_\mathbb{N},(y_{ji})_{j\in X\times \mathbb{N}})
\end{align}
which is what we wanted to show.

Only if:
Define $\kernel{M}:H\kto Y^D$ by $\kernel{M}(A|h)=h(A)$ for all $A\in\sigalg{Y}^X$, $h\in H$. By the column exchangeability of $\mu$, from \citet[Prop. 1.4]{kallenberg_basic_2005} there is a directing random measure $\RV{H}:Y^{X\times\mathbb{N}}\to H$ such that
\begin{align}
    \mu &= \tikzfig{de_finetti_representation_kernel}\label{eq:df_rep_mu}\\
    &\iff\\
    \mu(\bigtimes_{i\in \mathbb{N}} A_i) &= \int_H \prod_{i\in \mathbb{N}} \kernel{M}(A_i|h) \mu\kernel{F}_{\RV{H}}(\mathrm{d}h)&\forall A_i\in\sigalg{Y}^X
\end{align}

By Equations \ref{eq:lookup_representation} and \ref{eq:ev_alternate_rep}
\begin{align}
    \kernel{K} &= \tikzfig{do_model_representation_kernel_pre}\\
    &:= \tikzfig{do_model_representation_kernel}\label{eq:lup_rep_combined}
\end{align}
Where we can connect the copied outputs of $\mu\kernel{F}_{\RV{H}}$ to the inputs of each $\kernel{M}$ ``inside the plate'' as the plates in Equations \ref{eq:ev_alternate_rep} and \ref{eq:df_rep_mu} are equal in number and each connected wire represents a single copy of $Y^D$.

If:
By assumption, for any $\{A_i\in \sigalg{Y}|i\in\mathbb{N}\}$, $x:=(x_i)_{i\in\mathbb{N}}\in X^{\mathbb{N}}$
\begin{align}
    \kernel{K}(\bigtimes_{i\in \mathbb{N}} A_i|x) &= \int_H \prod_{i\in \mathbb{N}}\kernel{L}(A_i|h,x_i)\mu(\mathrm{d}h)
\end{align}

Consider any $S,T\subset\mathbb{N}$ with $|S|=|T|$, and define $A_S:=\times_{i\in\mathbb{N}} B_i$ where $B_i=Y$ if $i\not\in S$, otherwise $A_i$ is an arbitrary element of $\sigalg{Y}$. Define $A_T:=\times_{i\in\mathbb{N}} B_{\mathrm{swap}_{S\leftrightarrow T}(i)}$.

\begin{align}
    \kernel{K}(A_S|x) &= \int_H \prod_{i\in S}\kernel{L}(A_i|h,x_i)\mu(\mathrm{d}h)\\
                      &= \int_H\prod_{i\in T}\kernel{L}(A_i|h,x_{\mathrm{swap}_{S\leftrightarrow T}(i)})\mu(\mathrm{d}h)\\
                      &= \mathrm{swap}_{S\leftrightarrow T}\kernel{K}(A_T|x)\\
                      &= \mathrm{swap}_{S\leftrightarrow T}\kernel{K}\mathrm{swap}_{S\leftrightarrow T}(A_S|x)
\end{align}
So by Theorem \ref{th:equal_of_condits}, $\kernel{K}$ is causally contractible.
\end{proof}

\subsection{Causal contractibility with data-independent actions}\label{sec:data_independent_actions}

Given a sequence of variables $(\RV{D}_i,\RV{Y}_i)_{i\in \mathbb{N}}$ where the ``inputs'' are $\RV{D}:=(\RV{D}_i)_{i\in\mathbb{N}}$ and the ``outputs'' are $\RV{Y}=(\RV{Y}_i)_{i\in\mathbb{N}}$, say the inputs are independent of previous observations if $\RV{D}_i\CI^e_{\prob{P}_C} (\RV{Y}_{<i},C)|\RV{D}_{<i}$ for all $i\in\mathbb{N}$. This models an experiment where it may be possible to choose different inputs $\RV{D}$, but all the inputs are determined before the outputs $\RV{Y}$ are known. If a model satisfies this, then the dependence of $\RV{Y}$ on $\RV{D}$ is a sequence of repeatable response functions if and only if the uniform conditional $\prob{P}_C^{\RV{Y}|\RV{D}}$ exists (Definition \ref{def:cprob_pset}) and is causally contractible.

We call a model $\prob{P}_C$ with sequential outputs $\RV{Y}$ and a corresponding sequence of data-independent inputs $\RV{D}$ a ``sequential just-do model''.

\begin{definition}[Sequential just-do model]
A \emph{sequential just-do model} is a triple $(\prob{P}_C,\RV{D},\RV{Y})$ where $\prob{P}_C$ is a probability set on $(\Omega,\sigalg{F})$, $\RV{D}$ is a sequence of ``inputs'' $\RV{D}:=(\RV{D}_i)_{i\in\mathbb{N}}$ and $\RV{Y}$ is a corresponding sequence of ``outputs'' $\RV{Y}=(\RV{Y}_i)_{i\in\mathbb{N}}$ where $\RV{D}_i:\Omega\to D$ and $\RV{Y}_i:\Omega\to Y$. Furthermore, it is required that $\RV{X}_i\CI^e_{\prob{P}_C} (\RV{Y}_{<i},C)|\RV{X}_{<i}$ for all $i\in \mathbb{N}$, and $\RV{Y}\CI^e_{\prob{P}_C} C|\RV{D}$.
\end{definition}

To apply Theorem \ref{th:ciid_rep_kernel} to a sequential just-do model, it is necessary to extend the model to a larger sample space including ``latent variables'' taking values in $Y^D$. A latent extension is a model over a larger collection of variables that reduces to the original model when we restrict our attention to the original collection of variables.

\begin{definition}[Latent extension]
Given a probability set $\prob{P}_C'$ on $(\Omega,\sigalg{F})$ and some measurable set $(G,\sigalg{G})$, a probability set $\prob{P}_C$ is a \emph{latent extension} of $\prob{P}_C'$ to $(\Omega\times G,\sigalg{F}\otimes \sigalg{G})$ if $\prob{P}_C \kernel{F}_{\Pi_{\Omega}} = \prob{P}_C'$.
\end{definition}

\begin{notation}[Variables on a latent extension]
Given a probability set $\prob{P}_C'$ on $(\Omega,\sigalg{F})$ and a latent extension $\prob{P}_C$ on $(\Omega\times G,\sigalg{F}\otimes \sigalg{G})$, every variable on the original sample space is given a primed name $\RV{X}'$, $\RV{Y}'$ etc., and corresponds to an unprimed variable on the larger space $\RV{X}:=\Pi_\Omega\circ \RV{X}'$.
\end{notation}

Theorem \ref{th:data_ind_CC} applies Theorem \ref{th:ciid_rep_kernel} to the case of a model with data-independent actions and derives the required conditional independences and equalities to show that a sequential just-do model $(\prob{P}_C,\RV{D},\RV{Y})$ with causally contractible $\prob{P}_C^{\RV{Y}|\RV{X}}$ satisfies the required conditional independences and equalities of conditional distributions for $\RV{X}$ and $\RV{Y}$ to be related by repeatable response functions.

\begin{theorem}[Data-independent causal contractibility]\label{th:data_ind_CC}
Given a sequential just-do model $(\prob{P}_C',\RV{D}',\RV{Y}')$ on $(\Omega,\sigalg{F})$, then $\prob{P}_C^{\prime \RV{Y}'|\RV{D}'}$ is causally contractible if and only if there is a latent extension $\prob{P}_C$ of $\prob{P}_C'$ to $(\Omega\times Y^{D\times\mathbb{N}},\sigalg{F}\otimes\sigalg{Y}^{D\times\mathbb{N}})$ with some hypothesis $\RV{H}:\Omega\times Y^{D\times\mathbb{N}}\to H$ such that $\RV{Y}_i\CI^e_{\prob{P}_C'} (\RV{Y}_{<i},\RV{X}_{<i},C)|(\RV{X}_i,\RV{H})$ and $\prob{P}_C^{\RV{Y}_i|\RV{X}_i\RV{H}}=\prob{P}_C^{\RV{Y}_j|\RV{X}_j\RV{H}}$ for all $i,j\in \mathbb{N}$ and $\RV{H}\CI_{\prob{P}_C} (\RV{X},\RV{C})$.
\end{theorem}

\begin{proof}
If:
First, define the extension $\prob{P}_C$. From Theorem \ref{th:table_rep_kernel} and causal contractibility of $\prob{P}_C^{\prime \RV{Y}'|\RV{D}'}$ there is some $\mu\in \Delta(Y^{D\times\mathbb{N}})$ such that
\begin{align}
    \prob{P}_C^{\prime \RV{Y}'|\RV{D}'} &= \tikzfig{lookup_representation_variablised}\label{eq:lup_rep_varb}
\end{align}
Let $\prob{P}_C^{\RV{Y}^{D}|\RV{D}}=\mu\otimes \text{del}_{D^{\mathbb{N}}}$, $\prob{P}_C^{\RV{Y}|\RV{Y}^D\RV{D}}=\kernel{F}_{\mathrm{ev}}$ and $\RV{Y}^D:=\Pi_{Y^{D\times\mathbb{N}}}$, the projection $\Omega\times Y^{D\times\mathbb{N}}\to \Omega$. Let $\RV{W}=\Pi_{\Omega}$ and for each $\alpha\in C$, set 
\begin{align}
    \prob{P}_\alpha^{\RV{W}|\RV{Y}^D\RV{D}} &= \tikzfig{augmented_ccontracible}
\end{align}
Then 
\begin{align}
    \prob{P}_\alpha^{\RV{W}} &= \tikzfig{augmented_ccon2}\\
    &= \tikzfig{augmented_ccon3}\\
    &= \prob{P}_\alpha^{\prime \text{id}_\Omega}
    &= \prob{P}_\alpha
\end{align}

Before going further, it's necessary to check that there is some nonempty probability set $\prob{P}_C$ with these conditionals. By Theorem \ref{lem:valid_extendability}, because $\prob{P}_\alpha^{\RV{W}}=\prob{P}_{\alpha}'$ it is sufficient to show that $\prob{P}_\alpha^{\RV{Y}^D|\RV{W}}$ is valid. Because 
\begin{align}
    (\RV{W},\RV{Y}^D)(\Omega\times Y^{D\times\mathbb{N}})&=\Omega\times Y^{D\times\mathbb{N}}\\
    &=\RV{W}(\Omega\times Y^{D\times\mathbb{N}})\times \RV{Y}^D(\Omega\times Y^{D\times\mathbb{N}})
\end{align}
there are no impossible events, and so validity is guaranteed for any $\prob{P}_\alpha^{\RV{Y}^D|\RV{W}}$.

Thus $\prob{P}_C$ is a latent extension of $\prob{P}_C'$, and so $\prob{P}_C^{\RV{Y}|\RV{D}}$ is also causally contractible.

From Theorem \ref{th:ciid_rep_kernel} and by construction of $\prob{P}_C$, there exists a directing random measure $\RV{H}^*:Y^{D\times\mathbb{N}}\to H$ such that, defining $\RV{H}=\RV{H}^*\circ\Pi_{D\times\mathbb{N}}$
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{D}} &= \tikzfig{do_model_representation}
\end{align}
it remains to be shown that $\kernel{L}$ is a version of $\prob{P}^{\RV{Y}_i|\RV{D}_i\RV{H}}$ for all $i\in \mathbb{N}$ and $\RV{Y}_i\CI^e_{\prob{P}_C'} (\RV{Y}_{<i},\RV{D}_{<i},C)|(\RV{D}_i,\RV{H})$.

To show $\kernel{L}$ is a version of $\prob{P}^{\RV{Y}_i|\RV{H}\RV{D}_i}$ for all $i\in \mathbb{N}$:
\begin{align}
    \kernel{L}&=\tikzfig{kernel_l_broken_down}\\
              &=\tikzfig{kernel_l_broken_down2}\\
              &=\tikzfig{kernel_l_broken_down3}\label{eq:h_ci_x}\\
              &=\tikzfig{kernel_l_broken_down4}\label{eq:Y_ci_h_yd}\\
              &=\prob{P}_C^{\RV{Y}_i|\RV{H}\RV{D}_i}
\end{align}
Where \ref{eq:h_ci_x} follows from $\RV{H}\CI^e_{\prob{P}_C} (\RV{D}_i,\RV{C})$, which itself follows from $\RV{Y}^D_i\CI^e_{\prob{P}_C} (\RV{D}_i,\RV{C})$ which holds by construction. \ref{eq:Y_ci_h_yd} follows from $\RV{Y}_i\CI^e_{\prob{P}_C} (\RV{H},\RV{C})|(\RV{Y}^D_i,\RV{D}_i)$, which follows from $\RV{Y}_i$ being a deterministic function of $(\RV{Y}^D_i,\RV{D}_i)$.

For independence, note that
\begin{align}
     \prob{P}_C^{\RV{Y}_{<i}|\RV{H}\RV{X}_{<i}\RV{X}_i} &= \tikzfig{independence_inductive_base_0}\\
     &= \tikzfig{independence_inductive_base}
\end{align}
hence $\RV{Y}_{<i}\CI^e_{\prob{P}_C} (\RV{X}_i,\RV{C})|(\RV{H},\RV{X}_{<i})$

Then
\begin{align}
    \prob{P}_C^{\RV{Y}_i\RV{Y}_{<i}|\RV{H}\RV{D}_i\RV{D}_{<i}} &= \tikzfig{independence_inductive}\\
    \implies \prob{P}_C^{\RV{Y}_i|\RV{H}\RV{D}_i\RV{D}_{<i}} &\overset{\prob{P}_C}{\cong} \tikzfig{independence_inductive_last}
\end{align}
by Theorem \ref{th:higher_order_conditionals}. Hence $\RV{Y}_i\CI^e_{\prob{P}_C} (\RV{X}_{<i},\RV{Y}_{<i},\RV{C})|(\RV{H},\RV{X}_i)$.

Only if:
If $\prob{P}_C$ is a latent extension of $\prob{P}_C'$, then $\prob{P}_C^{\RV{Y}|\RV{D}}$ is causally contractible if and only if $\prob{P}_C^{\prime \RV{Y}'|\RV{D}'}$ is causally contractible. Thus it is sufficient to show $\prob{P}_C^{\RV{Y}|\RV{D}}$ is causally contractible.

By assumption, for all $i\in \mathbb{N}$
\begin{align}
    \prob{P}_C^{\RV{Y}_i|\RV{H}\RV{X}_{[i]}\RV{Y}_{<i}} &\overset{\prob{P}_C}{\cong} \text{del}_{X^{i-1}\times Y^{i-1}}\otimes \prob{P}_C^{\RV{Y}_1|\RV{H}\RV{X}_1}
\end{align}

Thus for all $n\in \mathbb{N}$ by repeated application of Theorem \ref{th:higher_order_conditionals}
\begin{align}
    \prob{P}_C^{\RV{Y}_{[n]}|\RV{H}\RV{X}_{[n]}} &\overset{\prob{P}_C}{\cong} \tikzfig{do_model_representation_finite}
\end{align}
thus by Lemma \ref{lem:infinitely_extended_kernels}
\begin{align}
    \prob{P}_C^{\RV{Y}_{\mathbb{N}}|\RV{H}\RV{X}_{\mathbb{N}}} &\overset{\prob{P}_C}{\cong} \tikzfig{do_model_representation_noprior}
\end{align}
and, because $\RV{H}\CI_{\prob{P}_C}^e(\RV{X},\RV{C})$
\begin{align}
    \prob{P}_C^{\RV{Y}_{\mathbb{N}}|\RV{X}_{\mathbb{N}}} &\overset{\prob{P}_C}{\cong} \tikzfig{do_model_representation}
\end{align}
causal contractibility follows from Theorem \ref{th:ciid_rep_kernel}.
\end{proof}

A consequence of Theorem \ref{th:equal_of_condits} applied to a just-do models $\prob{P}_C$ with causally contractible $\prob{P}_C^{\RV{Y}|\RV{D}}$ is that, for any $A,B\subset\mathbb{N}$ with $|A|=|B|$, $\prob{P}_C^{\RV{Y}_A|\RV{D}_A}=\prob{P}_C^{\RV{Y}_B|\RV{D}_B}$. A further consequence is the interchangeability of conditioning data -- for any $i\in \mathbb{N}$, $\prob{P}_C^{\RV{Y}_i|\RV{D}_i\RV{Y}_A\RV{D}_A}=\prob{P}_C^{\RV{Y}_i|\RV{D}_i\RV{Y}_B\RV{D}_B}$.

\begin{theorem}[Equality of subsequence conditionals]\label{th:equal_of_reduced_condits}
A sequential just-do model $(\prob{P}_C,\RV{D},\RV{Y})$ with $\prob{P}_C^{\RV{Y}|\RV{D}}$ causally contractible satisfies, for any $A,B\subset \mathbb{N}$ with $|A|=|B|$
\begin{align}
    \prob{P}_C^{\RV{Y}_A|\RV{D}_A} \overset{\prob{P}_C}{\cong} \prob{P}_C^{\RV{Y}_B|\RV{D}_B}
\end{align}
\end{theorem}

\begin{proof}
Only if:
For any $A,B\subset \mathbb{N}$, let $\text{swap}_{B\leftrightarrow A,D}:D^{\mathbb{N}}\kto D^{\mathbb{N}}$ be the transposiiton of $B$ with $A$ indices and $\text{swap}_{B\leftrightarrow A,Y}:Y^{\mathbb{N}}\kto Y^{\mathbb{N}}$ be the same defined on $Y$. By Theorem \ref{th:equal_of_condits}
\begin{align}
    \prob{P}_C^{\RV{Y}_A|\RV{D}_A}\otimes \text{del}_{D^{\mathbb{N}}} &=  \prob{P}_C^{\RV{Y}|\RV{D}} \text{marg}_A\\
     &= \text{swap}_{A\leftrightarrow[n],D} \prob{P}_C^{\RV{Y}_{[n]}|\RV{D}}\\
    &= \prob{P}_C^{\RV{Y}_{[n]}|\RV{D}_{[n]}}\otimes \text{del}_{D^{\mathbb{N}}}\\
    &= \text{swap}_{N\leftrightarrow[n],D} \prob{P}_C^{\RV{Y}_{[n]}|\RV{D}}\\
    &= \prob{P}_C^{\RV{Y}_B|\RV{D}_B}\otimes \text{del}_{D^{\mathbb{N}}}
\end{align}
\end{proof}

\subsubsection{Examples}

Purely passive observations can be modeled with a probability set $\prob{P}_C$ where $|\prob{P}_C|=1$. In this case, a model that is exchangeable over the sequence of pairs $(\RV{D}_i,\RV{Y}_i)_{i\in \mathbb{N}}$ has $\prob{P}_C^{\RV{Y}|\RV{D}}$ causally contractible. This follows from the fact that

\begin{align}
    \prob{P}_C^{\RV{YD}} &= \tikzfig{do_model_rep_onechoice_combined}
\end{align}
and so
\begin{align}
    \tikzfig{do_model_rep_onechoice}
\end{align}
is a version of $\prob{P}_C^{\RV{Y}|\RV{D}}$.

Instead of passive observations only, a model might feature a subsequence of passive observations and a subsequence of active interventions. Say the passive observations are $(\RV{D},\RV{Y})_{i\in\mathbb{N}}$ and the active interventions are $(\RV{E},\RV{Z})_{i\in \mathbb{N}}$. By the previous argument, $\prob{P}_C^{\RV{Y}|\RV{D}}$ is causally contractible. We might further assume that $\prob{P}_C^{\RV{YZ}|\RV{DE}}$ is causally contractible -- that is, there is a repeatable response function $\prob{P}_C^{\RV{Z}_i|\RV{E}_i\RV{H}}$ equal to $\prob{P}_C^{\RV{Y}_i|\RV{D}_i\RV{H}}$.

One conseqeuence of this is ``observational imitation'': any choice $\alpha$ that makes $\prob{P}_\alpha^{\RV{D}\RV{E}}$ exchangeable also makes $\prob{P}_\alpha^{\RV{YZ}}$ exchangeable. That is, if for some permutation $\mathrm{swap}_\rho$
\begin{align}
    \prob{P}_\alpha^{\RV{DE}}\mathrm{swap}_\rho &= \prob{P}_\alpha^{\RV{DE}}
\end{align}
then by commutativity of exchange
\begin{align}
    \prob{P}_\alpha^{\RV{YZ}} &= \prob{P}_\alpha^{\RV{DE}} \prob{P}_C^{\RV{YZ}|\RV{DE}}\\
    &=  \prob{P}_\alpha^{\RV{DE}}\mathrm{swap}_\rho \prob{P}_C^{\RV{YZ}|\RV{DE}}\\
    &= \prob{P}_\alpha^{\RV{DE}} \prob{P}_C^{\RV{YZ}|\RV{DE}}\mathrm{swap}_\rho\\
    &= \prob{P}_C^{\RV{YZ}|\RV{DE}}\mathrm{swap}_\rho
\end{align}

However, the assumption that $\prob{P}_C^{\RV{YZ}|\RV{DE}}$ is causally contractible seems unreasonable in most situations. One implication of this assumption is (by Theorem \ref{th:equal_of_condits}):
\begin{align}
    \prob{P}^{\RV{Y}\RV{Z}_i|\RV{D}\RV{E}_i}_C &= \prob{P}^{\RV{Z}|\RV{E}}\\
    \implies \prob{P}^{\RV{Z}_i|\RV{E}_i\RV{D}\RV{Y}}_C &= \prob{P}^{\RV{Z}_{i}|\RV{E}_i\RV{E}_{\{i\}^C}\RV{Z}_{\{i\}^C}}
\end{align}
That is, the model must yield the same result when conditioned on either the observational results, or the results of other active interventions. It is rare to assume \emph{a priori} that observational and experimental data are equally informative. Such a conclusion could be drawn \emph{after} reviewing both sequences of data, see for example \citet{eckles_bias_2021}, or it might be rejected \citet{gordon_comparison_2018,gordon_close_2022}.

\begin{example}[Backdoor adjustment]\label{ex:backdoor}
If a sequential just-do model $(\prob{P}_C,(\RV{D},\RV{X}),\RV{Y})$ has $\prob{P}_C^{\RV{Y}|\RV{DX}}$ causally contractible as well as:
\begin{itemize}
    \item $\RV{X}_{i}\CI^e_{\prob{P}_C}\RV{D}_{i}C|\RV{H}$ ($\RV{X}_i$ is extended independent of $\RV{D}_i$ conditional on $\RV{H}$)
    \item $\prob{P}_C^{\RV{X}_{i}|\RV{H}}\cong \prob{P}_C^{\RV{X}_{1}|\RV{H}}$ (the distribution of $\RV{X}$ is exchangeable)
 \end{itemize}
Then the model exhibits a kind of ``backdoor adjustment'' \citet[Chap. 1]{pearl_causality:_2009}. Specifically
\begin{align}
    \prob{P}_\alpha^{\RV{Y}_{i}|\RV{D}_{i}\RV{H}}(A|d,h) &= \int_X \prob{P}_\alpha^{\RV{Y}_{i}|\RV{X}_{i}\RV{D}_{i}\RV{H}}(A|d,x,h)\prob{P}_\alpha^{\RV{X}_{i}|\RV{D}_{i}\RV{H}}(\mathrm{d}x|d,h)\\
    &= \int_X \prob{P}_C^{\RV{Y}_{1}|\RV{X}_{1}\RV{D}_{1}\RV{H}}(A|d,x,h)\prob{P}_C^{\RV{X}_{i}|\RV{H}}(\mathrm{d}x|h)\\
    &= \int_X \prob{P}_C^{\RV{Y}_{1}|\RV{X}_{1}\RV{D}_{1}\RV{H}}(A|d,x,h)\prob{P}_C^{\RV{X}_{1}|\RV{H}}(\mathrm{d}x|h)\label{eq:backdoor}
\end{align}
\end{example}


Equation \ref{eq:backdoor} is identical to the backdoor adjustment formula for an intervention on $\RV{D}_1$ targeting $\RV{Y}_1$ where $\RV{X}_1$ is a common cause of both.

\section{Causal contractibility in sequences of active choices}\label{sec:assessing}

Assessing when a particular sequence of experiments should be modeled with a causally contractible model can be difficult. As noted, a purely observational sequence is causally contractible if it is exchangeable. However, the point of all this theory is to study models that offer different choices. The assumption of causal contractibility can be justified for a sequence of active interventions if the following are satisfied:
\begin{enumerate}
    \item There exist variables $\RV{I}$ representing ``unique experiment identifiers'' which satisfy the assumption that $\prob{P}_C^{\RV{Y}|\RV{DI}}$ is causally contractible (informally: it doesn't matter which order the experiments are conducted in, and treatments in each experiment do not affect any other experiments)
    \item Given a permutation $\rho$ of identifiers, $\prob{P}_\alpha^{\RV{YD}\rho(\RV{I})}=\prob{P}_\alpha^{\RV{YDI}}$ (informally: unique identifiers are not themselves informative)
    \item The map $\alpha\to \prob{P}_\alpha^{\RV{D}}$ is deterministic Markov kernel associated with an invertible function $f:C\to D^{\mathbb{I}}$
\end{enumerate}

Theorem \ref{th:cc_ind_treat} shows that, under these assumptions, $\prob{P}_C^{\RV{Y}|\RV{D}}$ is also causally contractible.

The first assumption -- that causal contractibility is satisfied jointly conditioning on decisions $\RV{D}$ and identifers $\RV{I}$ -- seems to often be a background assumption in the literature, while assumptions similar to the second two are discussed explicitly. For example, \citet{greenland_identifiability_1986} explain
\begin{quote}
    Equivalence of response type may be thought of in terms of exchangeability of individuals: if the exposure states of the two individuals had been exchanged, the same data distribution would have resulted.
\end{quote}
Note that exchanging individuals involved in an experiment and exchanging the individuals' exposure states are two different things, and the former doesn't imply the latter -- for example, there might be some background trend such that individuals treated later experience different outcomes to individuals treated at the start. Assumptions 1 and 2 \emph{together} imply that permuting identifiers or permuting decisions both lead to the same distribution.

\citet{dawid_decision-theoretic_2020} suggests (with some qualifications) that ``post-treatment exchangeability'' for a decision problem regarding taking aspirin to treat a headache may be acceptable if the data are from
\begin{quote}
    A group of individuals whom I can regard, in an intuitive sense, as similar to myself, with headaches similar to my own.
\end{quote}
This seems on the face of it similar to assumption 2: that I can permute the identifies ``me'' and ``someone else'' without changing the model.

Finally, \citet{rubin_causal_2005} discusses two separate assumptions to justify causal identifiability:
\begin{quote}
    indexing of the units is, by definition, a random permutation of $1,..., N$, and thus any distribution on the science must be row-exchangeable [...] The second critical fact is that if the treatment assignment mechanism is ignorable (e.g., randomized), then when the expression for the assignment mechanism (2) is evaluated at the observed data, it is free of dependence on $Y_{mis}$
\end{quote}
Here ``the science'' means (roughly) \emph{the response function of each individual}, and exchangeability of these response functions is a similar assumption to permutability of individual identifiers (though we don't derive the exact correspondence here). Rubin's second condition is that treatment assignment is ignorable. Like Assumption 3, this assumption limits ``how much we can learn from the treatment assignment'', but again we don't derive the exact correspondence. Note that in Rubin's scheme the preliminary assumption of \emph{stable unit-treatment values} is made in order to establish the existence of individual response functions, which plays a similar role to Assumption 1. 

Rubin's result also differs substantially from this one in that it applies to \emph{identification of potential outcomes in randomised experiments}, while this result is about the existence of response conditionals \emph{when there are different choices that can be made}.

As an example of the application of Theorem \ref{th:cc_ind_treat}, consider an experiment where $n$ patients, each with an individual identifier $\RV{I}_i$, receive treatment $\RV{D}_i$ and experience outcome $\RV{Y}_i$. $\prob{P}_C^{\RV{Y}_{[n]}|\RV{D}_{[n]}\RV{I}_{[n]}}$ can be extended to an infinite sequence $\prob{P}_C^{\RV{Y}|\RV{DI}}$ that is causally contractible (see Assumption 1), no matter which choice $\alpha\in C$ is decided on, all identifiers can be swapped without altering the distribution over consequences (see Assumption 2), and finally that the treatment vector $\RV{D}$ is a deterministic and invertible function of the choice $\alpha\in C$ then $\prob{P}_C^{\RV{Y}|\RV{D}}$ is causally contractible, and hence there are response functions $\prob{P}_C^{\RV{Y}_i|\RV{D}_i\RV{H}}$.

Theorem \ref{th:cc_ind_treat} can also be extended to the case where $\RV{D}$ is a function of the choice $\alpha$ and a ``random signal'' $\RV{R}$.

\begin{lemma}\label{lem:ind_to_cc}
Given sequential just-do model $(\prob{P}_C,(\RV{D},\RV{I}),\RV{Y})$ with $\prob{P}_C^{\RV{Y}|\RV{DI}}$ causally contractible, if $\RV{Y}\CI_{\prob{P}_C}^e (\RV{I},\RV{C})|\RV{D}$ then $\prob{P}_C^{\RV{Y}|\RV{D}}$ is also causally contractible.
\end{lemma}

\begin{proof}
For arbitrary $\nu\in \Delta(I^{\mathbb{N}})$, by assumption of causal contractibility of $\prob{P}_C^{\RV{Y}|\RV{DI}}$ and Theorem \ref{th:ciid_rep_kernel}
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{DI}} &= \tikzfig{index_independence_1}\\
    &= \tikzfig{index_independence_2}\\
    &= \tikzfig{index_independence_3}\\
    \implies \prob{P}_C^{\RV{Y}|\RV{D}} &= \tikzfig{index_independence_4}
\end{align}
Applying Theorem \ref{th:ciid_rep_kernel}, $\prob{P}_C^{\RV{Y}|\RV{D}}$ is causally contractible.
\end{proof}

An \emph{identifier variable} is a variable $\RV{I}$ that takes values in the set of finite permutations of $\mathbb{N}$. It is associated with a sequence $(\RV{I}_i)_{i\in \mathbb{N}}$ where $\RV{I}_i=\RV{I}(i)$. Each $\RV{I}_i$ takes values in $\mathbb{N}$ and $\RV{I}_i\neq \RV{I}_j$ for all $j\neq i$.

\begin{definition}[Identifier variable]
Given a probability set $\prob{P}_C$ on $(\Omega,\sigalg{F})$, let $I$ be the set of finite permutations $\mathbb{N}\to \mathbb{N}$. A variable $\RV{I}:\Omega\to I$ be a variable taking values in $I$ is an \emph{identifier variable}.
\end{definition}

If a uniform conditional probability is invariant to permutations of an index variable, then it is independent of that index variable.

\begin{lemma}\label{lem:ind}
Given a probability set $\prob{P}_C$ where $\RV{Y}\CI_{\prob{P}_C}^e \RV{C}|(\RV{D},\RV{I})$ and $\RV{I}:\Omega\to I$ is an identifier variable, if for each finite permutation $\rho:\mathbb{N}\to \mathbb{N}$
\begin{align}
    \prob{P}_\alpha^{\RV{Y}|\RV{ID}} &= (\text{swap}_{\rho(I)}\otimes \text{Id}_X )\prob{P}_\alpha^{\RV{Y}|\RV{ID}}
\end{align}
then $\RV{Y}\CI_{\prob{P}_C}^e (\RV{I},\RV{C})|\RV{D}$.
\end{lemma}

\begin{proof}
By definition of the set $I$ of finite permutations, for every $\rho\in I$, $B\in\sigalg{Y}^{\mathbb{N}}$, $d\in D^{\mathbb{N}}$ there is a finite permutation $\rho^{-1}\in I$ such that $\rho\circ\rho^{-1}=\text{id}_{\mathbb{N}}$. Then
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{ID}}(B|i,d) &= (\kernel{F}_{\rho^{-1}}\otimes \text{Id}_X )\prob{P}_C^{\RV{Y}|\RV{ID}}(B|\rho,d)\\
    &= \prob{P}_C^{\RV{Y}|\RV{ID}}(B|\text{id}_{\mathbb{N}},d)
\end{align}
Therefore
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{ID}} &\overset{\prob{P}_C}{\cong} \text{erase}_{I}\otimes \kernel{K} 
\end{align}
where $\kernel{K}:D^{\mathbb{N}}\kto Y^{\mathbb{N}}$ is the kernel
\begin{align}
    (B|d)\mapsto \prob{P}_C^{\RV{Y}|\RV{ID}}(B|\text{id}_{\mathbb{N}},d)
\end{align}
\end{proof}

The following theorem assumes that the set of choices $C$ is countable and there is a one-to-one function $f:C\to D^{\mathbb{N}}$. Thus, if $|D|>1$, $f$ cannot be surjective.

\begin{theorem}\label{th:cc_ind_treat}
Given a sequential just-do model $(\prob{P}_C,(\RV{D},\RV{I}),\RV{Y})$ on $(\Omega,\sigalg{F})$ with $C$ countable, $\prob{P}_C^{\RV{Y}|\RV{DI}}$ causally contractible $\RV{I}:\Omega\to I$ an identifier variable, if for each $\alpha\in C$, $\rho\in I$
\begin{align}
    \prob{P}_\alpha^{\RV{Y}|\RV{I}} &= \kernel{F}_{\rho}\prob{P}_\alpha^{\RV{Y}|\RV{I}}
\end{align}
and furthermore
\begin{align}
    &\RV{YI}\CI^e_{\prob{P}_C} \RV{C}|\RV{D}\\
    &\RV{YI}\CI^e_{\prob{P}_C} \RV{D}|\RV{C}
\end{align}
then $\prob{P}_C^{\RV{Y}|\RV{D}}$ is causally contractible.
\end{theorem}

\begin{proof}
For any $\alpha\in C$ by Theorem \ref{th:higher_order_conditionals}
\begin{align}
    \prob{P}_\alpha^{\RV{Y}|\RV{I}} &= \tikzfig{kernel_fac_with_idents}\\
    &= \tikzfig{kernel_fac_with_idents_indepped}
\end{align}

Define $\kernel{Q}$ by $\alpha\mapsto \prob{P}_\alpha$ and $\kernel{Q}^{\cdot|\cdot\RV{C}}$ by $\alpha\mapsto \prob{P}_\alpha^{*}$ and $\kernel{Q}^{\RV{C}}$ is an arbitrary distribution in $\Delta(C)$ with full support. Note that the support of $\kernel{Q}^{\RV{IDY}}$ is the union of the support of $\prob{P}^{\RV{IDY}}_\alpha$ for all $\alpha$. Then
\begin{align}
    \kernel{Q}^{\RV{Y}|\RV{IC}} &\overset{\prob{Q}}{\cong} \tikzfig{kernel_fac_with_idents_kernelised}
\end{align}

By assumption $\RV{YI}\CI^e_{\prob{P}_C} \RV{D}|\RV{C}$, it is also the case that
\begin{align}
    \kernel{Q}^{\RV{Y}|\RV{ID}} &\overset{\prob{Q}}{\cong} \tikzfig{kernel_Q_fac_with_idents}\\
    &\overset{\prob{Q}}{\cong} \tikzfig{kernel_Q_fac_with_idents_indepped}\\
    &\overset{\prob{Q}}{\cong} \tikzfig{kernel_Q_fac_with_idents_subbed}
\end{align}
But
\begin{align}
    \kernel{Q}^{\RV{Y}|\RV{ID}}=\sum_{\alpha\in C} \prob{P}_\alpha^{\RV{Y}|\RV{ID}}\kernel{Q}^{\RV{C}}(\alpha)\\
    &= \prob{P}_C^{\RV{Y}|\RV{ID}}
    \implies \tikzfig{kernel_Q_fac_with_idents_subbed} &= \prob{P}_C^{\RV{Y}|\RV{ID}}
\end{align}

Furthermore, by assumption, for any permutation $\rho:\mathbb{N}\to\mathbb{N}$
\begin{align}
    \kernel{Q}^{\RV{Y}|\RV{IC}} &= \tikzfig{kernel_Q_with_swap}\\
    \implies \prob{P}_C^{\RV{Y}|\RV{ID}} &= \tikzfig{kernel_Q_fac_with_idents_swapped}\\
    &= \tikzfig{kernel_Q_fac_with_idents_swapped_exch}\\
    &= \tikzfig{kernel_P_with_swap}
\end{align}
Then by Lemma \ref{lem:ind} the independence $\RV{Y}\CI_{\prob{P}_C}^e \RV{I}C|\RV{D}$ holds, and by Lemma \ref{lem:ind_to_cc} $\prob{P}_C^{\RV{Y}|\RV{D}}$ is causally contractible.
\end{proof}

Theorem \ref{th:cc_ind_treat} can be extended to the case where decisions $\RV{D}$ are one-to-one deterministic, or random mixtures of one-to-one deterministic.

\begin{corollary}
Given a sequential just-do model $(\prob{P}_{C'},(\RV{D},\RV{I}),\RV{Y})$ satisfying the conditions of Theorem \ref{th:cc_ind_treat} and a second model $(\prob{P}_{C},(\RV{D},\RV{I}),\RV{Y})$ such that for all $\alpha\in C$ there is some set of coefficients $k_i$ such that
\begin{align}
    \prob{P}_\alpha &= \sum_{c\in C'} k_c \prob{P}_c 
\end{align}
then $\prob{P}_C^{\RV{Y}|\RV{D}}$ is also causally contractible.
\end{corollary}

\begin{proof}
For all $\alpha\in C$
\begin{align}
    \prob{P}_\alpha^{\RV{Y}|\RV{D}} &= \sum_{c\in C'} k_c \prob{P}_c^{\RV{Y}|\RV{D}}\\
    &= \prob{P}_{C'}^{\RV{Y}|\RV{D}}
\end{align}
\end{proof}

Dropping the assumption $\RV{YI}\CI^e_{\prob{P}_C} \RV{C}|\RV{D}$ means that, in general, one or both of $\prob{P}_C^{\RV{Y}|\RV{D}}$ or $\prob{P}_C^{\RV{Y}|\RV{ID}}$ may be ill-defined (note that the independence is merely a sufficient condition, not a necessary condition for these uniform conditional probabilities). The condition $\RV{YI}\CI^e_{\prob{P}_C} \RV{C}|\RV{D}$ alone also does \emph{not} imply the conclusion of Theorem \ref{th:cc_ind_treat}. 

Constructing the following example requires the hypotheses that any given identifier $i\in\mathbb{N}$ could be associated with one of two input-output maps $D\kto Y$. This generates space of hypotheses $H=\{0,1\}^{\mathbb{N}}$, which needs to be equipped with an algebra of measurable sets. Equipped with the product topology, $H$ is a countable product of separable, completely metrizable spaces and is therefore also separable and completely metrizable \citep[Thm. 16.4,Thm. 24.11]{willard_general_1970}. Thus $(H,\mathcal{B}(H))$ is a standard measurable space and because it is uncountable, it is isomorphic to $([0,1],\mathcal{B}([0,1]))$.

\begin{example}
Take $Y=C=D=\{0,1\}$ and take $(H,\sigalg{H})$ to be $\{0,1\}^{\mathbb{N}}$ equipped with the product topology. For any $i\neq 1$, $\RV{Y}_i\RV{I}_i\RV{D}_i\CI^e_{\prob{P}_C} \RV{C}$, while $\prob{P}_\alpha^{\RV{D}_1}=\delta_\alpha$ and $\RV{I}_i\CI^e_{\prob{P}_C} \RV{C}$.

$\RV{YI}\CI^e_{\prob{P}_C} \RV{C}|\RV{D}$ follows from the fact that $\RV{C}$ can be (almost surely) written as a function of $\RV{D}$.

For all $i,\in \mathbb{N}$, $y,d\in \{0,1\}$, $h\in H$ set
\begin{align}
    \prob{P}_C^{\RV{Y}_i|\RV{H}\RV{I}_i\RV{D}_i}(y|h,j,d) &= \delta_1(p(j,h))\delta_d(y) + \delta_0(p(j,h))\delta_{1-d}(y)
\end{align}
where $p(j,h)$ projects the $j$-th component of $h$. That is, if $h$ maps $j$ to 1, $\RV{Y}$ goes with $\RV{D}$ while if $h$ maps $j$ to $0$, $\RV{Y}$ goes opposite $\RV{D}$. Suppose also 
\begin{align}
    \RV{Y}_i\CI_{\prob{P}_C}^e (\RV{X}_{<i},\RV{Y}_{<i},\RV{I}_{<i},\RV{C})|(\RV{X}_i,\RV{Y}_i,\RV{H})
\end{align}
Then $\prob{P}_C^{\RV{Y}|\RV{DI}}$ is causally contractible. Set $\prob{P}_{C}^{\RV{H}}$ to be the uniform measure on $(H,\sigalg{H})$ and for $i>1$
\begin{align}
    \prob{P}_C^{\RV{D}_i|\RV{I}_i\RV{H}}(d|j,h) &= \delta_{p(j,h)}(d)
\end{align}
that is, if $h$ maps $j$ to 1, $\RV{D}$ is 1 while if $h$ maps $j$ to $0$, $\RV{D}$ is 0. This also implies
\begin{align}
    \prob{P}_C^{\RV{I}_i|\RV{D}_i\RV{H}}(p(\cdot,h)^{-1}(d)|d,h) &= 1\label{eq:all_eq_d}
\end{align}

Then, for $i>1$
\begin{align}
    \prob{P}_\alpha^{\RV{Y}_i|\RV{H}\RV{D}_i}(y|h,d) &= \sum_{j\in \mathbb{N}} \delta_1(p(j,h))\delta_d(y)\prob{P}_C^{\RV{I}_i|\RV{D}_i\RV{H}}(j|d,h) + \delta_0(p(j,h))\delta_{1-d}(y)\prob{P}_C^{\RV{I}_i|\RV{D}_i\RV{H}}(j|d,h)\\
    &= \sum_{j\in \mathbb{N}} \delta_1(d)\delta_d(y)\prob{P}_C^{\RV{I}_i|\RV{D}_i\RV{H}}(j|d,h) + \delta_0(d)\delta_{1-d}(y)\prob{P}_C^{\RV{I}_i|\RV{D}_i\RV{H}}(j|d,h)&\text{by Eq \ref{eq:all_eq_d}}\\
    &= \delta_1(y)\\
    \implies \prob{P}_\alpha^{\RV{Y}_i|\RV{D}_i}(y|d) &= \delta_1(y)
\end{align}

For $q\in I$, set
\begin{align}
    \prob{P}_C^{\RV{I}|\RV{H}}(q|h)&= \begin{cases}
        0.5 & q=(1,2,3,4,...) \text{ or } (1,3,2,4,...)\\
        0&\text{otherwise}
    \end{cases}
\end{align}
and set
\begin{align}
    \prob{P}_C^{\RV{H}|\RV{D}}(h) &= \begin{cases}
        0.5 & h=(0,1,0,1,1,...)\text{ or }h=(0,0,1,1,1,...)\\
        0 &\text{otherwise}
    \end{cases}
\end{align}
Let $\overline{H}$ be the support of $\prob{P}_C^{\RV{H}|\RV{D}}(h)$.

Then for $i=1$
\begin{align}
    \prob{P}_\alpha^{\RV{Y}_1|\RV{D}_1}(y|h,d) &= \sum_{h\in H} \sum_{j\in \mathbb{N}} \prob{P}_\alpha^{\RV{I}_1|\RV{D}_1\RV{H}}(j|d,h)\prob{P}_C^{\RV{H}|\RV{D}_1}(h|d)\left(\delta_1(p(j,h))\delta_d(y) + \delta_0(p(j,h))\delta_{1-d}(y)\right)\\
    &= \sum_{h\in \overline{H}} 0.5( \delta_1(p(1,h))\delta_d(y) + \delta_0(p(1,h))\delta_{1-d}(y))\\
    &= \delta_{1-d}(y))\\
    &\neq  \prob{P}_\alpha^{\RV{Y}_i|\RV{D}_i}(y|h,d) & i\neq 1
\end{align}
Thus $\prob{P}_C^{\RV{Y}|\RV{D}}$ is not causally contractible by Theorem \ref{th:equal_of_condits}. 

However, given any finite permutation $\rho:\mathbb{N}\to\mathbb{N}$
\begin{align}
    \prob{P}_\alpha^{\RV{Y}|\RV{I}}(y|q) &= \sum_{h\in \overline{H}}\sum_{d\in\{0,1\}^{\mathbb{N}}} \prod_{i\in \mathbb{N}} \prob{P}_C^{\RV{Y}_i|\RV{I}_i\RV{D}_i\RV{H}}(y_i|q_i,d_i,h) \prob{P}_\alpha^{\RV{D}_i|\RV{I}_i\RV{H}}(d_i|q_i,h)\prob{P}_C^{\RV{H}}(h)\\
    &= \delta_{1-\alpha}(y_1)\delta_{(1)_{i\in\mathbb{N}}}(y_{>1})\\
    &= \prob{P}_\alpha^{\RV{Y}|\RV{I}}(y|\rho^{-1}(q))\\
    &= \kernel{F}_{\rho}\prob{P}_\alpha^{\RV{Y}|\RV{I}}(y|q)
\end{align}
\end{example}

\subsubsection{Example: body mass index}

Given a sequential just-do model $(\prob{P}_C,(\RV{B},\RV{I}),\RV{Y})$ with $\RV{B}:=(\RV{B}_i)_{i\in M}$ representing body mass index of individual $\RV{I}_i$ and $\RV{Y}:=(\RV{Y}_i)_{i\in M}$ representing health outcomes of interest for the same individual, \citet{hernan_does_2008} noted that there are multiple different choices that can influence an individual's body mass index $\RV{B}_i$ in the same way. Thus $\RV{YI}\CI^e_{\prob{P}_C} \RV{C}|\RV{B}$ might generally be rejected, and so there may be no uniform conditional $\prob{P}_C^{\RV{Y}|\RV{IB}}$. In this case, $\prob{P}_C^{\RV{Y}|\RV{IB}}$ cannot be causally contractible because it doesn't exist.

Suppose instead a model $(\prob{P}_C,(\RV{D},\RV{I}),(\RV{B},\RV{Y}))$ is given, with $\RV{D}=(\RV{D}_i)_{i\in M}$ representing ``decisions'', appropriately fine-grained to satisfy
\begin{align}
    &\RV{YBI}\CI^e_{\prob{P}_C} \RV{C}|\RV{D}\\
    &\RV{YBI}\CI^e_{\prob{P}_C} \RV{D}|\RV{C}
\end{align}
and $\prob{P}_C^{\RV{YB}|\RV{ID}}$ causally contractible. Then by Theorem \ref{th:cc_ind_treat} $\prob{P}_C^{\RV{Y}|\RV{BD}}$ is also causally contractible. In general, there may be some $U\subset H$ such that for any $h\in U$ 
\begin{align}
    \prob{P}_C^{\RV{Y}_i|\RV{B}_i\RV{D}_i\RV{H}}(y|b,d,h) &= \prob{P}_C^{\RV{Y}_i|\RV{B}_i\RV{H}}(y|b,h)\label{eq:conditional_conditional_independence}
\end{align}
then, \emph{conditioning on }$\RV{H}\in U$, the resulting $\prob{P}_{C,\RV{H}\in U}^{\RV{Y}|\RV{B}}$ is causally contractible.
\todo[inline]{Defining conditioning}
So it may be possible to derive the fact that there is a repeatable response conditional $\prob{P}_{C,\RV{H}\in U}^{\RV{Y}_i|\RV{H}\RV{B}_i}$ if $\RV{H}\in U$ is implied by available data, even if it is not assumed outright.

\section{Response conditionals with data-dependent actions}\label{sec:data_dependent}

The results of the previous section concern ``just-do'' models where actions have not dependence on previous data. Decision problems of interest actually have actions that depend on data -- what's really wanted are ``see-do'' models of some variety (see Definition \ref{def:see_do_model}). Here, Theorem \ref{th:data_ind_CC} is generalised to sequential see-do models with the use of \emph{probability combs}. Combs are a generalisation of conditional probabilities which can be used to capture a certain notion of data-dependent choices.

Because combs are a bit more complicated to work with than conditional probabilities, most of the previous results have not yet been generalised to the data-dependent case, if such a generalisation is possible.

To begin with an example, consider a probability set $(\prob{P}_C,\RV{D},\RV{Y})$ with $\RV{D}:=(\RV{D}_i)_{i\in\mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$ as usual, and take a subsequence $(\RV{D}_i,\RV{Y}_i)_{i\in [2]}$ of length 2. Suppose $\prob{P}_C$ features repeatable response conditionals in the sense that the following holds
\begin{align}
    \RV{Y}_i&\CI^e_{\prob{P}_C} (\RV{Y}_{<i},\RV{D}_{<i},\RV{C})|\RV{H}\RV{D}_i&\forall i\in \mathbb{N}\\
    \land \RV{H} &\CI^e_{\prob{P}_C} \RV{D} C\\
    \land \prob{P}_C^{\RV{Y}_i|\RV{H}\RV{D}_i} &= \prob{P}_C^{\RV{Y}_0|\RV{H}\RV{D}_0} & \forall i\in \mathbb{N}
\end{align}

Then, for arbitrary $\alpha\in C$
\begin{align}
    \prob{P}_\alpha^{\RV{Y}_{[2]}} &= \tikzfig{response_conditional_comb}
\end{align}
note that $\RV{D}_2$ depends on $\RV{Y}_1$ and $\RV{D}_1$. Instead of multiplying by a distribution over $(\RV{D}_1,\RV{D}_2)$, $\prob{P}_\alpha^{\RV{D}_2|\RV{Y}_1\RV{D}_1}$ has been ``inserted'' between the response conditionals $\prob{P}_C^{\RV{Y}_1|\RV{D}_1\RV{H}}$ and $\prob{P}_C^{\RV{Y}_2|\RV{D}_2\RV{H}}$. A comb is a Markov kernel that yields a probability distribution when another Markov kernel of appropriate type is inserted in this manner.

Given $\prob{P}_C^{\RV{Y}_1|\RV{D}_1\RV{H}}$ and $\prob{P}_C^{\RV{Y}_2|\RV{D}_2\RV{H}}$, define the comb
\begin{align}
    \prob{P}_C^{\RV{Y}_{[2]}\combbreak \RV{D}_{[2]}} := \tikzfig{causally_contractible_comb}
\end{align}
then $\prob{P}_C^{\RV{Y}_{[2]}\combbreak \RV{D}_{[2]}}$ is causally contractible. $\prob{P}_C^{\RV{Y}_{[2]}\combbreak \RV{D}_{[2]}}$ is \emph{not} a uniform conditional probability; in general 
\begin{align}
    \prob{P}_\alpha^{\RV{D}_1\RV{D}_2} \prob{P}_C^{\RV{Y}_{[2]}\combbreak \RV{D}_{[2]}}\neq \prob{P}_\alpha^{\RV{Y}_1\RV{Y}_2}
\end{align}

\subsection{Combs}

Where uniform conditional probabilities map probability distributions to probability distributions via the semidirect product, 2-combs map conditional probabilities to conditional probabilities via an ``insert'' operation. More generally, higher order combs map lower order combs to lower order combs (where conditional probabilities are though of as 1-combs and probability distributions as 0-combs).  Graphically, the insert operation can be represented in with the following diagrams
% \begin{align}
%     \prob{P}_\alpha^{\RV{XY}}&=\prob{P}_\alpha^{\RV{X}}\cprod\prob{P}_C^{\RV{Y}|\RV{X}}\\
%     &= \tikzfig{conditional_semidirect_product}
% \end{align}
% and the insert operation looks like
\begin{align}
    \prob{P}_\alpha^{\RV{Y}_{1}\RV{D}_2\RV{Y}_2|\RV{D}_1}&=\text{insert}(\prob{P}_\alpha^{\RV{D}_2|\RV{D}_1\RV{Y}_1},\prob{P}_C^{\RV{Y_{[2]}}\combbreak\RV{D}_{[2]}})\\
    &= \tikzfig{comb_insert_complicated}\label{eq:comb_insert_complicated}\\
    &= \tikzfig{comb_insert_gettingsimpler}\\
    &= \tikzfig{comb_insert_simple}\label{eq:comb_insert_simple}
\end{align}

While Equation \ref{eq:comb_insert_complicated} is a well-formed string diagram in the category of Markov kernels, Equation \ref{eq:comb_insert_simple} is not. In the case that all the underlying sets are discrete, Equation \ref{eq:comb_insert_simple} can be defined using an extended string diagram notation appropriate for the category of real-valued matrices \citep{jacobs_causal_2019}, though we do not introduce this extension here.

\begin{definition}[Uniform $n$-Comb]
Given a probability set $\prob{P}_C$ with variables $\RV{Y}_i:\Omega\to Y$, $\RV{D}_i:\Omega\to D$ for $i\in [n]$ and uniform conditional probabilities $\{\RV{P}_C^{\RV{Y}_i|\RV{D}_{[i]}\RV{Y}_{[i-1]}}|i\in [n]\}$, the uniform $n$-comb $\prob{P}_C^{\RV{Y}_{[n]}\combbreak \RV{D}_{[n]}}:D^n\kto Y^n$ is the Markov kernel given by the recursive definition
\begin{align}
    \prob{P}_C^{\RV{Y}_{1}\combbreak \RV{D}_{1}} &= \prob{P}_C^{\RV{Y}_1|\RV{D}_1}\\
    \prob{P}_C^{\RV{Y}_{[m]}\combbreak \RV{D}_{[m]}} &= \tikzfig{comb_inductive}
\end{align}
\end{definition}

\begin{definition}[Uniform $\mathbb{N}$-comb]
Given a probability set $\prob{P}_C$ with variables $\RV{Y}_i:\Omega\to Y$ and $\RV{D}_i:\Omega\to D$ for $i\in \mathbb{N}$ and uniform conditional probabilities $\{\RV{P}_C^{\RV{Y}_i|\RV{D}_{[i]}\RV{Y}_{[i-1]}}|i\in \mathbb{N}\}$, the uniform $\mathbb{N}$-comb $\prob{P}_C^{\RV{Y}_{\mathbb{N}}\combbreak \RV{D}_{\mathbb{N}}}:D^\mathbb{N}\kto Y^\mathbb{N}$ is the Markov kernel such that for all $n\in \mathbb{N}$
\begin{align}
    \prob{P}_C^{\RV{Y}_{\mathbb{N}}\combbreak \RV{D}_{\mathbb{N}}}(\mathrm{id}_{Y^{n}}\otimes \mathrm{del}_{Y^{\mathbb{N}}}) &= \prob{P}_C^{\RV{Y}_{[n]}\combbreak \RV{D}_{[n]}}\otimes \mathrm{del}_{Y^{\mathbb{N}}}
\end{align}
\end{definition}

\begin{theorem}[Existence of $\mathbb{N}$-combs]
Given a probability set $\prob{P}_C$ with variables $\RV{Y}_i:\Omega\to Y$ and $\RV{D}_i:\Omega\to D$ for $i\in \mathbb{N}$ and uniform conditional probabilities $\{\RV{P}_C^{\RV{Y}_i|\RV{D}_{[i]}\RV{Y}_{[i-1]}}|i\in \mathbb{N}\}$, a uniform $\mathbb{N}$-comb $\prob{P}_C^{\RV{Y}_{\mathbb{N}}\combbreak \RV{D}_{\mathbb{N}}}:D^\mathbb{N}\kto Y^\mathbb{N}$ exists.
\end{theorem}

\begin{proof}
For each $n\in \mathbb{N}$ $m<n$, we have
\begin{align}
    \prob{P}_C^{\RV{Y}_{[n]}\combbreak \RV{D}_{[n]}}(\mathrm{id}_{Y^{n-m}})\otimes \mathrm{del}_{Y^m}) &= \prob{P}_C^{\RV{Y}_{[n-m]}\combbreak \RV{D}_{[n-m]}}\otimes \mathrm{del}_{Y^m}
\end{align}

Therefore the existence of $\prob{P}_C^{\RV{Y}_{\mathbb{N}}\combbreak \RV{D}_{\mathbb{N}}}$ is a consequence of Lemma \ref{lem:infinitely_extended_kernels}.
\end{proof}

For discrete sets, the insert operation has a compact definition

\begin{definition}[Comb insert - discrete]
Given an $n$-comb $\prob{P}_\alpha^{\RV{Y}_{[n]}\combbreak \RV{D}_{[n]}}$ and an $n-1$ comb $\prob{P}_\alpha^{\RV{D}_{[2,n]}|\RV{Y}_{[n-1]}}$, $(D,\sigalg{D})$ and $(Y,\sigalg{Y})$ discrete, for all $y_i\in Y$ and $d_i\in D$
\begin{align}
    \mathrm{insert}(\prob{P}_\alpha^{\RV{D}_{[2,n]}\combbreak \RV{Y}_{[n-1]}},\prob{P}_\alpha^{\RV{Y}_{[n]}\combbreak \RV{D}_{[n]}})(y_{[n]},d_{[2,n]}|d_1) &= \prob{P}_\alpha^{\RV{Y}_{[n]}\combbreak \RV{D}_{[n]}}(y_n|d_{[2,n]},d_1)\prob{P}_\alpha^{\RV{D}_{[1,n]}\combbreak\RV{Y}_{[n-1]}}(d_{[2,n]}|y_{[n-1]})
\end{align}
\end{definition}

\subsection{Response conditionals in models with data dependent actions}

Theorem \ref{th:response_hdep} generalises Theorem \ref{th:data_ind_CC} to models $(\prob{P}_C,\RV{D},\RV{Y})$ with data-dependent actions, where instead the assumption that the uniform comb $\prob{P}_C^{\RV{Y}\combbreak \RV{D}}$ is causally contractible replaces the assumption that the conditional probability $\prob{P}_C^{\RV{Y}| \RV{D}}$ is causally contractible.

\begin{definition}[Sequential see-do model]
A \emph{sequential see-do model} is a triple $(\prob{P}_C,\RV{D},\RV{Y})$ where $\prob{P}_C$ is a probability set on $(\Omega,\sigalg{F})$, $\RV{D}$ is a sequence of ``inputs'' $\RV{D}:=(\RV{D}_i)_{i\in\mathbb{N}}$ and $\RV{Y}$ is a corresponding sequence of ``outputs'' $\RV{Y}=(\RV{Y}_i)_{i\in\mathbb{N}}$ where $\RV{D}_i:\Omega\to D$ and $\RV{Y}_i:\Omega\to Y$ and $\RV{Y}_i\CI^e_{\prob{P}_C} C|(\RV{D}_{[i]},\RV{Y}_{<i})$.
\end{definition}

\begin{theorem}[]\label{th:response_hdep}
Given a sequential see-do model $(\prob{P}_C',\RV{D}',\RV{Y}')$ on $(\Omega,\sigalg{F})$, then $\prob{P}_C^{\prime \RV{Y}'\combbreak \RV{D}'}$ is causally contractible if and only if there is a latent extension $\prob{P}_C$ of $\prob{P}_C'$ to $(\Omega\times H,\sigalg{F}\otimes\sigalg{Y}^{D\times\mathbb{N}})$ with hypothesis $\RV{H}:\Omega\times H\to H$ such that $\RV{Y}_i\CI^e_{\prob{P}_C'} (\RV{Y}_{<i},\RV{X}_{<i},C)|(\RV{X}_i,\RV{H})$ and $\prob{P}_C^{\RV{Y}_i|\RV{X}_i\RV{H}}=\prob{P}_C^{\RV{Y}_j|\RV{X}_j\RV{H}}$ for all $i,j\in \mathbb{N}$ and $\RV{H}\CI_{\prob{P}_C} (\RV{X},\RV{C})$.
\end{theorem}

\begin{proof}
If:
By assumption, there is some $\kernel{L}:H\times D\kto Y$ such that
\begin{align}
    \prob{P}_C^{\RV{Y}_i|\RV{H}\RV{D}_i} &= \kernel{L}
\end{align}
and $\RV{Y}_i\CI^e_{\prob{P}_C} (\RV{Y}_{<i},\RV{D}_{<i})|(\RV{D}_i,\RV{H})$. Thus
\begin{align}
    \prob{P}_C^{\RV{Y}_i|\RV{H}\RV{D}_i\RV{Y}_{<i}\RV{D}_{<i}} &= \kernel{L}\otimes \text{erase}_{Y^{i-1}\times D^{i-1}}
\end{align}
and so
\begin{align}
    \prob{P}_C^{\RV{Y}\combbreak \RV{D}} &= \tikzfig{do_model_representation}\label{eq:comb_representation_w_CI}
\end{align}
and so by Theorem \ref{th:ciid_rep_kernel}, $\prob{P}_C^{\RV{Y}\combbreak \RV{D}}$ is causally contractible.

Only if:
First, define the extension $\prob{P}_C$. From Theorem \ref{th:ciid_rep_kernel} and causal contractibility of $\prob{P}_C^{\prime \RV{Y}'\combbreak \RV{D}'}$ there is some $H$, $\mu\in \Delta(H)$ and $\kernel{L}:H\times D\kto Y$ such that
\begin{align}
    \prob{P}_C^{\prime \RV{Y}'\combbreak\RV{D}'} &= \tikzfig{do_model_representation_mu}
\end{align}
thus, by the definition of the comb insert operation
\begin{align}
    \prob{P}_\alpha^{\prime\RV{D}'_{[n]} \RV{Y}'_{[n]}} &= \prob{P}_\alpha^{\RV{D}_1}\odot \text{insert}(\prob{P}_\alpha^{\prime \RV{D}'_{[2,n]}\combbreak\RV{Y}'_{[n-1]}}, \prob{P}_C^{\prime \RV{Y}'_{[n]}\combbreak\RV{D}'_{[n]}}) 
\end{align}
Let
\begin{align}
    \prob{P}_C^{\RV{Y}_i|\RV{H}\RV{D}_i} &= \kernel{L}\label{eq:identical_response_assumption}
\end{align}
and let $\RV{Y}_i\CI^e_{\prob{P}_C} (\RV{Y}_{<i},\RV{D}_{<i})|(\RV{D}_i,\RV{H})$, and for all $\alpha$ set $\prob{P}_\alpha^{\RV{W}|\RV{DY}}=\prob{P}_\alpha^{\prime \RV{W}'|\RV{D'Y'}}$ for all $\RV{W}':\Omega\to W$ and $\prob{P}_\alpha^{\RV{D}_i|\RV{Y}_{<i}\RV{D}_{<i}}=\prob{P}_\alpha^{\prime \RV{D}_i'|\RV{Y}_{<i}'\RV{D}_{<i}''}$.

It remains to be shown that $\prob{P}_\alpha^{\RV{DY}}=\prob{P}_\alpha^{\prime \RV{DY}}$.

By Equation \ref{eq:identical_response_assumption} and $\RV{Y}_i\CI^e_{\prob{P}_C} (\RV{Y}_{<i},\RV{D}_{<i})|(\RV{D}_i,\RV{H})$, it follows (for identical reasons as Equation \ref{eq:comb_representation_w_CI}) that
\begin{align}
    \prob{P}_C^{\RV{Y}\combbreak \RV{D}} &= \tikzfig{do_model_representation}\\
    &= \tikzfig{do_model_representation_mu}\\
    &= \prob{P}_C^{\prime \RV{Y}'\combbreak\RV{D}'}
\end{align}

And so for all $n\in \mathbb{N}$
\begin{align}
    \prob{P}_\alpha^{\RV{D}_{[n]} \RV{Y}_{[n]}} &=  \prob{P}_\alpha^{\RV{D}_1}\odot \text{insert}(\prob{P}_\alpha^{ \RV{D}_{[2,n]}\combbreak\RV{Y}_{[n-1]}}, \prob{P}_C^{\prime \RV{Y}_{[n]}\combbreak\RV{D}_{[n]}}) \\
    &= \prob{P}_\alpha^{\RV{D}_1}\odot \text{insert}(\prob{P}_\alpha^{\prime \RV{D}'_{[2,n]}\combbreak\RV{Y}'_{[n-1]}}, \prob{P}_C^{\prime \RV{Y}'_{[n]}\combbreak\RV{D}'_{[n]}}) \\
    &= \prob{P}_\alpha^{\prime\RV{D}'_{[n]} \RV{Y}'_{[n]}}
\end{align}
\end{proof}

In contrast to the data-independent case where causal contractibility of $\prob{P}_C^{\RV{Y}|\RV{X}}$ implies the equivalence of all subsequence conditionals $\prob{P}_C^{\RV{Y}_A|\RV{X}_A}$ for all equally sized $A\subset\mathbb{N}$, a causally contractible comb $\prob{P}_C^{\RV{Y}\combbreak \RV{D}}$ does not generally imply that subsequence combs $\prob{P}_C^{\RV{Y}_A\combbreak \RV{D}_A}$ and $\prob{P}_C^{\RV{Y}_B\combbreak \RV{D}_B}$ are equivalent with $|A|=|B|$.


\subsection{Combs are the output of the ``fix'' operation}

There is a relationship between combs and the ``fix'' operation defined in \citet{richardson_nested_2017}. In particular, suppose we have a probability $\prob{P}_\alpha$ and a comb $\prob{P}_\alpha^{\RV{Y}_{[2]}|\RV{D}_{[2]}}$. Then (assuming discrete sets)
\begin{align}
    \prob{P}_\alpha^{\RV{Y}_{[2]}\combbreak \RV{D}_{[2]}}(y_1,y_2|d_1,d_2) &= \prob{P}_\alpha^{\RV{Y}_1|\RV{D}_1}(y_1|d_1)\prob{P}_\alpha^{\RV{Y}_2|\RV{D}_2}(y_2|d_2)\\
    &= \frac{\prob{P}_\alpha^{\RV{Y}_1|\RV{D}_1}(y_1|d_1)\prob{P}_\alpha^{\RV{D}_2|\RV{Y}_1\RV{D}_1}(d_2|y_1,d_1)\prob{P}_\alpha^{\RV{Y}_2|\RV{D}_2}(y_2|d_2)}{\prob{P}_\alpha^{\RV{D}_2|\RV{Y}_1\RV{D}_1}(d_2|y_1,d_1)}\\
    &= \frac{\prob{P}_\alpha^{\RV{Y}_{[2]}\RV{D}_2|\RV{D}_1}(y_1,y_2,d_2|d_1)}{\prob{P}_\alpha^{\RV{D}_2|\RV{Y}_1\RV{D}_1}(d_2|y_1,d_1)}
\end{align}
That is (at least in this case), the result of ``division by a conditional probability'' used in the fix operation is a comb. We speculate that the output of the fix operation is, in general, an $n$-comb, but we have not proven this.


\section{Weaker assumptions than causal contractibility}

The results so far apply to purely observational models or to models where every ``input'' in the sequence is fixed at the point of choosing $\alpha$ (or a fixed random function is chosen at this point). Most of the interest in causal inference is how to use observational data -- which is plentiful -- to deduce consequences of choices. Suppose in the following that superscripter ``$o$'' refers to observational variables (obtained by some measurement procedure not responsive to choices) and ``$v$'' refers to interventional variables (obtained by some measurement procedure responsive to choices). That is $\RV{Y}^o:=(\RV{Y}_i^o)_{i\in \mathbb{N}}$ is a sequence of observantional variables, $\RV{Y}^v$ a sequence of interventional variables and $\RV{Y}^{o,v}:=(\RV{Y}^o_i,\RV{Y}^v_i)_{i\in\mathbb{N}}$ is a mixed sequence of both observational and interventional variables. $\RV{Y}_i^o$ and $\RV{Y}_i^v$ are assumed to take values in the same set $Y$.

One approach to bridging the gap between observations and interventions is to assume ``causal sufficiency'', which is tantamount (in the data-independent case) to assuming causal contractibility of $\prob{P}_C^{\RV{Y}^{o,v}|\RV{X}^{o,v}\RV{D}^{o,v}}$ with $\RV{D}^v$ responsive to choices and $\RV{X}^v$ unresponsive (see Example \ref{ex:backdoor}). As discussed, this is rarely a reasonable assumption -- it implies interchangeability between observational and interventional samples.

A weaker assumption that is often adopted is to consider models satisfying causal contractibility with respect to $\prob{P}_C^{\RV{Y}^{o,v}|\RV{U}^{o,v}\RV{D}^{o,v}}$, where $\RV{U}^{o,v}$ is unobserved. That is, while $\RV{U}^{o,v}$ appears in the model, it is not associted with any measurement procedure. This model still asserts that $(\RV{U}^o_i,\RV{X}^o_i,\RV{Y}^o_i)$ triples are interchangeable with $(\RV{U}^v_i,\RV{X}^v_i,\RV{Y}^v_i)$ triples, but neither of these are measurement outcomes. On the other hand, $(\RV{D}_i^o,\RV{Y}_i^o)$ pairs are not generally interchangeable with $(\RV{D}_i^v,\RV{Y}_i^v)$.

Consider models that satisfy causal contractibility with respect to $\prob{P}_C^{\RV{Y}^{o,v}|\RV{W}^{o,v}}$, where no comment is made about whether $\RV{W}^{o,v}$ is observed, unobseved or some function of observed and unobserved variables. This is a generalisation of the class of models discussed in the previous paragraph.  In isolation, this assumption is not especially interesting -- for example, the support of $\RV{W}^{o}_i$ and $\RV{W}^v_i$ might be disjoint. Suppose also, then, that $W$ is finite and $\RV{W}^o_i$ has full support. This assumption amounts to the assumption that, no matter what choice is made, ``nothing truly new can be done'' (which we call ``Ecclesiastes' assumption''\footnote{Ecclesiastes 1:9 reads ``Everything that happens has happened before; nothing is new, nothing under the sun.''\citep{noauthor_holy_1995}}). More precisely, for any choice $\alpha\in C$ and any consequence $\RV{Y}_i^v$, there is a random subsequence $\RV{Q}$ of indices $(1,2,3,....)$ such that the distribution $\prob{P}_\alpha^{\RV{Y}^{o,v}}$ is unchanged by permutations that only swap elements in the sequence $(RV{Y}^o_\RV{Q},\RV{Y}^v_i)$.

\begin{theorem}\label{th:condit_exchange}
Given just-do model $\prob{P}_C$ with $\prob{P}_C^{\RV{Y}^{o,v}|\RV{W}^{o,v}}$ causally contractible, $W$ finite and $\prob{P}_C^{\RV{W}^o|\RV{H}}(w|h)>0$ for all $w,h$, define $q:W^{\mathbb{N}}\times W\to (\{*\}\cup \mathscr{P}(\mathbb{N})$ by 
\begin{align}
    q:((w^o_j)_{\mathbb{N}},w^v_i)&\mapsto \{j|w^o_j=w^v_i\}
\end{align}
and take $\RV{Q}:=q\circ(\RV{W}^o,\RV{W}^v_i)$ for arbitrary $i\in \mathbb{N}$. For an index set $U\in\mathbb{N}$ Take $\text{swap}_{\cdot}:Y^{\mathbb{N}}\times Y^{\mathbb{N}}\to Y^{\mathbb{N}}\times Y^{\mathbb{N}}$ to be an arbitrary finite swap that acts as the identity on all indices $(j,x)\not\in \RV{Q}\times \{o\}\cup\{(i,v)\}$. Then $\prob{P}^{\RV{Y}^{o}\RV{Y}^v_i}\text{swap}_{\RV{Q}} = \prob{P}^{\RV{Y}^{o}\RV{Y}^v_i}$.
\end{theorem}

\begin{proof}
Note that for $B_j\in \sigalg{W}$, where $\rho_q:\mathbb{N}\times\{i,v\}\to \mathbb{N}\times\{i,v\}$ is the permutation function associated with $\text{swap}_{q}$
\begin{align}
    \prob{P}_\alpha^{\RV{W}^o\RV{W}^v_i}\text{swap}_{\RV{Q}} (\bigtimes_{j\in\mathbb{N}} B_j) &= \int_{W^{\mathbb{N}}}\int_{\mathscr{P}(\mathbb{N})} \prod_{k\not\in q\times\{o\}\cup\{(i,v)\}} \delta_{w_k}(B_k) \prod_{l\in q\times\{o\}\cup\{(i,v)\}} \delta_{\rho_q(w_l)} (B_l) \prob{P}_\alpha^{\RV{Q}|\RV{W}^o\RV{W}^v_i}(\mathrm{d}q|w)\prob{P}_\alpha^{}(\mathrm{d}w)\\
    &= \int_{W^{\mathbb{N}}}\int_{\mathscr{P}(\mathbb{N})} \prod_{k\not\in q\times\{o\}\cup\{(i,v)\}} \delta_{w_k}(B_k) \prod_{l\in q\times\{o\}\cup\{(i,v)\}} \delta_{w_l} (B_l) \prob{P}_\alpha^{\RV{Q}|\RV{W}^o\RV{W}^v_i}(\mathrm{d}q|w)\prob{P}_\alpha^{}(\mathrm{d}w)\label{eq:all_the_same}\\
    &= \prob{P}_\alpha^{\RV{W}^o\RV{W}^v_i}
\end{align}
where Eq. \ref{eq:all_the_same} follows from the fact that for every $k,l\in q\times\{o\}\cup\{(i,v)\}$, $w_k=w_l$.

Thus for $A\in \sigalg{Y}^{\mathbb{N}}$
\begin{align}
    \prob{P}_\alpha^{\RV{Y}^{o}\RV{Y}^v_i}\text{swap}_{\RV{Q}}(A) &= [\prob{P}_\alpha^{\RV{W}^o\RV{W}^v_i} \prob{P}_\alpha^{\RV{Y}^{o}\RV{Y}^v_i|\RV{Q}\RV{W}^o\RV{W}^v_i}\text{swap}_{\RV{Q}}](A)\\
    &= [\prob{P}_\alpha^{\RV{W}^o\RV{W}^v_i} \text{swap}_{\RV{Q}^{-1}} \prob{P}_\alpha^{\RV{Y}^{o}\RV{Y}^v_i|\RV{W}^o\RV{W}^v_i}\text{swap}_{\RV{Q}}](A)\\
    &= \prob{P}_\alpha^{\RV{Y}^{o}\RV{Y}^v_i}\label{eq:by_cc1}
\end{align}
Where Eq. \ref{eq:by_cc1} follows from causal contractibility of $\prob{P}_\alpha^{\RV{Y}^{o}\RV{Y}^v_i|\RV{W}^o\RV{W}^v_i}$.
\end{proof}

It also follows from Ecclesiastes' assumption and finite $W$ that if some $\RV{X}_i^o$, $\RV{Z}_i^o$ are \emph{deterministically} related given $\RV{W}$, then $\prob{P}_C^{\RV{Z}|\RV{X}}$ is causally contractible.

\begin{theorem}\label{th:det_obs_to_cons}
Given just-do model $\prob{P}_C$ with $\prob{P}_C^{\RV{X}^{o,v}\RV{Z}^{o,v}|\RV{W}^{o,v}}$ causally contractible, $W$ finite and $\prob{P}_C^{\RV{W}^o_i|\RV{H}}(w|h)>0$ for all $w,h$, if $\prob{P}_C^{\RV{Z}^o_0|\RV{X}^o_0\RV{H}}$ is deterministic then $\prob{P}_C^{\RV{Z}^{o,v}|\RV{X}^{o,v}}$ is causally contractible.
\end{theorem}

\begin{proof}
Because $\prob{P}_\alpha^{\RV{W}_0^o}\prob{P}_C^{\RV{Z}^o_0|\RV{X}^o_0\RV{W}^o_0\RV{H}}$ is deterministic, so is $\prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{W}_0\RV{H}}$.

Fix $h\in H$.  Suppose there is some $w,w'\in W$ such that
\begin{align}
    \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{W}_0\RV{H}}(A|x,w,h) &\neq \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{W}_0\RV{H}}(A|x,w',h)
\end{align}
then, by determinism, we can assume without loss of generality
\begin{align}
    \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{W}_0\RV{H}}(A|x,w,h) = 1\\
    \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{W}_0\RV{H}}(A|x,w',h) = 0
\end{align}
but $W$ is finite and $\prob{P}_C^{\RV{W}^o_i|\RV{H}}(w|h)>0$ for all $w$, so there is some $a>0$ such that $\prob{P}_C^{\RV{W}^o_i|\RV{H}}(w|h)\geq a$ for all $w$, and so
\begin{align}
    a \leq \sum_{w\in W} \prob{P}_C^{\RV{W}^o_0|\RV{X}^o_0,\RV{H}}(w|x,h)\prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{W}_0\RV{H}}(A|x,w,h)\leq 1-a
\end{align}
contradicting determinism of $\prob{P}_C^{\RV{Z}^o_0|\RV{X}^o_0\RV{H}}$.

Thus for all $w,w'$
\begin{align}
    \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{W}_0\RV{H}}(A|x,w,h) &= \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{W}_0\RV{H}}(A|x,w',h)
\end{align}
i.e. $\RV{Z}_0\CI^e_{\prob{P}_C} (\RV{W}_0,\RV{C})|(\RV{X}_0,\RV{H})$. But then there is some $\prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{H}}$ such that
\begin{align}
    \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{W}_0\RV{H}} &= \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{H}}\otimes \text{erase}_W\\
    \implies \prob{P}_\alpha^{\RV{Z}^v_i|\RV{X}^v_i\RV{H}} &= \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{H}}
\end{align}
\end{proof}

Theorem \ref{th:det_obs_to_cons} doesn't hold in the case of approximate determinism, however. Intuitively, approximate determinism can hold if there is some value of $\RV{W}$ for which $\RV{Z}$ is not conditionally independent given $\RV{H}$ and $\RV{X}$, but it only ocurrs very rarely in observations. On the other hand, values of $\RV{W}$ rare in observations might, under some choices, become common. 

\begin{example}
Say $\prob{P}_C^{\RV{Z}^o_i|\RV{X}^o_i\RV{H}}$ is \emph{approximately deterministic} if $\prob{P}_C^{\RV{Z}^o_i|\RV{X}^o_i\RV{H}}(A|x,h)\in [0,\epsilon]\cup[1-\epsilon,1]$ for all $A\in\sigalg{Z}$, $x,h\in X\times H$.

Take $Z=X=W=H=\{0,1\}$. Set
\begin{align}
    \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{W}_0\RV{H}}(1|1,1,1) = 1\\
    \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{W}_0\RV{H}}(1|1,0,1) = 0
\end{align}
and
\begin{align}
    \prob{P}_C^{\RV{W}^o_0|\RV{H}}(1|1)=1-\epsilon
\end{align}
then
\begin{align}
    \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{H}}(1|1,1) = 1-\epsilon
\end{align}
however, suppose there is some $\alpha$ such that
\begin{align}
    \prob{P}_\alpha^{\RV{W}^v_i|\RV{H}}(1|1)=0
\end{align}
then
\begin{align}
    \prob{P}_\alpha^{\RV{Z}_0|\RV{X}_0\RV{H}}(1|1,1) = 0\\
    &\neq \prob{P}_C^{\RV{Z}_0|\RV{X}_0\RV{H}}(1|1,1)
\end{align}
\end{example}
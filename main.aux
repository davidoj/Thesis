\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\citation{proctor_history_2012}
\citation{oreskes_merchants_2011}
\citation{fisher_cancer_1958}
\citation{world_health_organisation_tobacco_nodate,wiblin_why_2016}
\citation{world_health_organisation_tobacco_nodate}
\citation{noauthor_cigarettes_nodate}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{5}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Theories of causal inference}{5}{section.1.1}\protected@file@percent }
\citation{krittanawong_association_2020}
\citation{pearl_causality:_2009}
\citation{spirtes_causation_1993}
\citation{woodward_causation_2016}
\citation{shpitser_complete_2008}
\citation{pearl_causality:_2009}
\citation{woodward_causation_2016}
\citation{dawid_decision-theoretic_2020}
\@writefile{tdo}{\contentsline {todo}{I want to revisit the claims about what I actually show, hopefully to add to it}{8}{section*.2}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{21536991}{25948842}
\pgfsyspdfmark {pgfid2}{5997853}{25962949}
\pgfsyspdfmark {pgfid3}{10077468}{25737219}
\@writefile{tdo}{\contentsline {todo}{I commented out an additional section about potential outcomes and closest world counterfactuals, which is a second example of ``opaque causal definitions''. I'm interested if any readers think it would be good to have a second example}{8}{section*.3}\protected@file@percent }
\pgfsyspdfmark {pgfid6}{21857565}{11263326}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Technical Prerequisites}{9}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\contentsline {todo}{Todo: conditional expectation, martingale convergence}{9}{section*.4}\protected@file@percent }
\pgfsyspdfmark {pgfid7}{18318621}{31316025}
\@writefile{tdo}{\contentsline {todo}{Almost sure equality convention}{9}{section*.5}\protected@file@percent }
\pgfsyspdfmark {pgfid8}{18318621}{30103500}
\@writefile{tdo}{\contentsline {todo}{Existence of disintegrations for choosing probability measures}{9}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid9}{18318621}{28890974}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.1}Probability Theory}{9}{subsection.2.0.1}\protected@file@percent }
\citation{clerc_pointless_2017}
\@writefile{toc}{\contentsline {paragraph}{Common $\sigma $ algebras}{10}{section*.7}\protected@file@percent }
\citation{cinlar_probability_2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.2}Product Notation}{11}{subsection.2.0.2}\protected@file@percent }
\newlabel{ssec:product_notation}{{2.0.2}{11}{Product Notation}{subsection.2.0.2}{}}
\citation{cho_disintegration_2019}
\citation{selinger_survey_2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.3}String Diagrams}{12}{subsection.2.0.3}\protected@file@percent }
\newlabel{ssec:mken_diagrams}{{2.0.3}{12}{String Diagrams}{subsection.2.0.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Elements of string diagrams}{12}{section*.8}\protected@file@percent }
\newlabel{sec:string_diagram_elements}{{2.0.3}{12}{Elements of string diagrams}{section*.8}{}}
\newlabel{eq:prob_meas_sd}{{2.7}{12}{Elements of string diagrams}{equation.2.0.7}{}}
\citation{cho_disintegration_2019}
\@writefile{toc}{\contentsline {paragraph}{Elementary operations}{13}{section*.9}\protected@file@percent }
\newlabel{eq:sd_composition}{{2.8}{13}{Elementary operations}{equation.2.0.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Markov kernels with special notation}{14}{section*.10}\protected@file@percent }
\newlabel{eq:identity}{{2.17}{14}{Markov kernels with special notation}{equation.2.0.17}{}}
\newlabel{eq:copy}{{2.25}{14}{Markov kernels with special notation}{equation.2.0.25}{}}
\newlabel{eq:swap}{{2.28}{15}{Markov kernels with special notation}{equation.2.0.28}{}}
\newlabel{eq:discard}{{2.34}{15}{Markov kernels with special notation}{equation.2.0.34}{}}
\newlabel{def:functional_kernel}{{2.0.1}{15}{Kernel associated with a function}{theorem.2.0.1}{}}
\newlabel{lem:pushf_funk}{{2.0.3}{15}{Pushforward kernels are functional kernel products}{theorem.2.0.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Working With String Diagrams}{16}{section*.11}\protected@file@percent }
\newlabel{sssec:string_diagram_manipulation}{{2.0.3}{16}{Working With String Diagrams}{section*.11}{}}
\@writefile{toc}{\contentsline {paragraph}{Axioms of Symmetric Monoidal Categories}{16}{section*.12}\protected@file@percent }
\newlabel{eq:ccom1}{{2.39}{16}{Axioms of Symmetric Monoidal Categories}{equation.2.0.39}{}}
\newlabel{eq:ccom2}{{2.40}{16}{Axioms of Symmetric Monoidal Categories}{equation.2.0.40}{}}
\newlabel{eq:ccom3}{{2.41}{16}{Axioms of Symmetric Monoidal Categories}{equation.2.0.41}{}}
\newlabel{eq:termobj1}{{2.42}{16}{Axioms of Symmetric Monoidal Categories}{equation.2.0.42}{}}
\citation{fong_causal_2013}
\newlabel{eq:A_copymap}{{2.46}{17}{Axioms of Symmetric Monoidal Categories}{equation.2.0.46}{}}
\newlabel{eq:copy_commutes}{{2.47}{17}{Axioms of Symmetric Monoidal Categories}{equation.2.0.47}{}}
\citation{cho_disintegration_2019}
\@writefile{toc}{\contentsline {subsubsection}{Examples}{18}{section*.13}\protected@file@percent }
\newlabel{eq:joint_measure}{{2.52}{18}{Examples}{equation.2.0.52}{}}
\newlabel{eq:marginalisation_graph}{{2.61}{18}{Examples}{equation.2.0.61}{}}
\citation{cinlar_probability_2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.4}Random Variables}{19}{subsection.2.0.4}\protected@file@percent }
\newlabel{ssec:random_variables}{{2.0.4}{19}{Random Variables}{subsection.2.0.4}{}}
\newlabel{eq:disint_example}{{2.62}{19}{Random Variables}{equation.2.0.62}{}}
\newlabel{def:kernel_space}{{2.0.6}{20}{Probability space, Markov kernel space}{theorem.2.0.6}{}}
\newlabel{eq:canonical_extension}{{2.64}{20}{Probability space, Markov kernel space}{equation.2.0.64}{}}
\newlabel{def:random_variable}{{2.0.7}{20}{Random variable}{theorem.2.0.7}{}}
\newlabel{def:domain_variable}{{2.0.8}{20}{Domain variable}{theorem.2.0.8}{}}
\newlabel{def:ctensor}{{2.0.9}{20}{Coupled tensor product $\utimes $}{theorem.2.0.9}{}}
\citation{cinlar_probability_2011}
\newlabel{lem:utimes_assoc}{{2.0.10}{21}{$\utimes $ is associative}{theorem.2.0.10}{}}
\newlabel{def:marginal_distribution}{{2.0.11}{21}{Marginal distribution, marginal kernel}{theorem.2.0.11}{}}
\newlabel{def:joint_distribution}{{2.0.12}{21}{Joint distribution, joint kernel}{theorem.2.0.12}{}}
\newlabel{lem:jdist_cprod}{{2.0.13}{21}{Product marginalisation interchange}{theorem.2.0.13}{}}
\newlabel{corr:rewrite_joint_dist}{{2.0.14}{22}{}{theorem.2.0.14}{}}
\newlabel{def:wl_jprob}{{2.0.15}{22}{Wire labels - joint kernels}{theorem.2.0.15}{}}
\newlabel{eq:labels_express_joint}{{2.76}{22}{Wire labels - joint kernels}{equation.2.0.76}{}}
\newlabel{eq:labels_express_marginal_upper}{{2.77}{22}{Wire labels - joint kernels}{equation.2.0.77}{}}
\newlabel{eq:labels_express_marginal_lower}{{2.78}{22}{Wire labels - joint kernels}{equation.2.0.78}{}}
\newlabel{eq:cannot_marginalise}{{2.79}{22}{Wire labels - joint kernels}{equation.2.0.79}{}}
\newlabel{def:disintegration}{{2.0.17}{23}{Disintegration}{theorem.2.0.17}{}}
\newlabel{eq:ordinary_disint}{{2.86}{23}{Disintegration}{equation.2.0.86}{}}
\newlabel{eq:def_k_disint}{{2.87}{24}{Disintegration}{equation.2.0.87}{}}
\newlabel{def:wl_disint}{{2.0.18}{24}{Wire labels -- input}{theorem.2.0.18}{}}
\newlabel{dia:kernel_l}{{2.88}{24}{Wire labels -- input}{equation.2.0.88}{}}
\newlabel{eq:const_from_m}{{2.90}{24}{Wire labels -- input}{equation.2.0.90}{}}
\newlabel{th:iterated_disint}{{2.0.20}{25}{Iterated disintegration}{theorem.2.0.20}{}}
\newlabel{lem:representation_of_kernels}{{2.0.21}{26}{}{theorem.2.0.21}{}}
\citation{cinlar_probability_2011}
\@writefile{toc}{\contentsline {subsubsection}{Existence of Disintegrations}{27}{section*.14}\protected@file@percent }
\newlabel{th:disintegration_exist}{{2.0.22}{27}{Disintegration existence - probability space}{theorem.2.0.22}{}}
\newlabel{eq:non_measurable_disint}{{2.107}{27}{Existence of Disintegrations}{equation.2.0.107}{}}
\citation{pearl_causality:_2009}
\newlabel{eq:cbn_cont2}{{2.112}{29}{Existence of Disintegrations}{equation.2.0.112}{}}
\newlabel{th:existence_continous}{{2.0.24}{29}{Existence of disintegrations on kernel spaces: uniform normalised continuous kernel}{theorem.2.0.24}{}}
\newlabel{eq:agrement_on_jsub}{{2.119}{30}{Existence of Disintegrations}{equation.2.0.119}{}}
\citation{cinlar_probability_2011}
\@writefile{tdo}{\contentsline {todo}{which I'll add here next}{32}{section*.15}\protected@file@percent }
\pgfsyspdfmark {pgfid190}{21857565}{34510987}
\citation{cinlar_probability_2011}
\newlabel{lem:absolute_continuity}{{2.0.26}{33}{}{theorem.2.0.26}{}}
\@writefile{tdo}{\contentsline {todo}{todo}{33}{section*.16}\protected@file@percent }
\pgfsyspdfmark {pgfid191}{18318621}{37513511}
\newlabel{lem:uniform_integrability}{{2.0.27}{33}{}{theorem.2.0.27}{}}
\@writefile{tdo}{\contentsline {todo}{todo; a proof for an analagous fact is given in \cite  {cinlar_probability_2011}}{33}{section*.17}\protected@file@percent }
\pgfsyspdfmark {pgfid192}{18318621}{31019262}
\@writefile{tdo}{\contentsline {todo}{show...}{33}{section*.18}\protected@file@percent }
\pgfsyspdfmark {pgfid193}{18318621}{21379286}
\@writefile{tdo}{\contentsline {todo}{better name}{33}{section*.19}\protected@file@percent }
\pgfsyspdfmark {pgfid194}{18318621}{16689551}
\newlabel{lem:agree_disint}{{2.0.30}{33}{Agreement of disintegrations}{theorem.2.0.30}{}}
\newlabel{eq:prob_disint_in_kernel_disint}{{2.141}{34}{Existence of Disintegrations}{equation.2.0.141}{}}
\@writefile{toc}{\contentsline {subsubsection}{Conditional Independence}{35}{section*.20}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Almost sure equality}{36}{section*.21}\protected@file@percent }
\pgfsyspdfmark {pgfid211}{21857565}{41784253}
\newlabel{th:ci_equivalence}{{2.0.33}{36}{Definitions are equivalent}{theorem.2.0.33}{}}
\newlabel{def:conditional_probability_existence}{{2.0.34}{37}{Conditional probability existence}{theorem.2.0.34}{}}
\newlabel{def:conditional_independence}{{2.0.35}{37}{Conditional Independence}{theorem.2.0.35}{}}
\@writefile{tdo}{\contentsline {todo}{Almost sure equality}{37}{section*.22}\protected@file@percent }
\pgfsyspdfmark {pgfid230}{18318621}{35328690}
\newlabel{eq:splitter_preserves_name}{{2.163}{37}{Diagrammatic consequences of labels}{equation.2.0.163}{}}
\newlabel{eq:composition}{{2.167}{38}{Conditional Independence}{equation.2.0.167}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Two player statistical models and see-do models}{39}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\contentsline {todo}{These are ``todo'' notes. All such notes that involve theoretical development are also collected in an unordered list of outstanding theoretical questions}{39}{section*.23}\protected@file@percent }
\pgfsyspdfmark {pgfid265}{18318621}{29366033}
\citation{fisher_statistical_1992,le_cam_comparison_1996,freedman_asymptotic_1963,de_finetti_foresight_1992,vapnik_nature_2013,wald_statistical_1950}
\citation{steele_decision_2020}
\@writefile{tdo}{\contentsline {todo}{Note to proof readers: I moved the discussion of decomposability to the next chapter so I can introduce it alongside the result that uses it}{41}{section*.24}\protected@file@percent }
\pgfsyspdfmark {pgfid266}{18318621}{34313149}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Two player statistical models and see-do models}{41}{section.3.1}\protected@file@percent }
\newlabel{def:2p_stat}{{3.1.1}{41}{Two player statistical model}{theorem.3.1.1}{}}
\citation{hajek_interpretations_2019}
\newlabel{def:seedo}{{3.1.2}{42}{See-Do model}{theorem.3.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Frequentist random variables and Bayesian forecasts}{42}{section.3.2}\protected@file@percent }
\citation{pearl_causality:_2009}
\citation{pearl_causality:_2009}
\citation{de_finetti_foresight_1992}
\newlabel{def:permut_swap}{{3.2.3}{45}{Permutations and swaps}{theorem.3.2.3}{}}
\newlabel{eq:determ_commute}{{3.9}{45}{Frequentist random variables and Bayesian forecasts}{equation.3.2.9}{}}
\newlabel{eq:function_composition}{{3.10}{45}{Frequentist random variables and Bayesian forecasts}{equation.3.2.10}{}}
\@writefile{tdo}{\contentsline {todo}{lemmafy, move to chapter 2}{46}{section*.25}\protected@file@percent }
\pgfsyspdfmark {pgfid277}{21857565}{34027180}
\newlabel{def:partial_freq}{{3.2.4}{46}{Partial frequencies}{theorem.3.2.4}{}}
\newlabel{def:exchange_sig_alb}{{3.2.5}{46}{Exchangeable $\sigma $-algebra}{theorem.3.2.5}{}}
\newlabel{lem:partial_representation}{{3.2.8}{47}{Infinitely exchangeably extendable forecasts}{theorem.3.2.8}{}}
\citation{cinlar_probability_2011}
\newlabel{eq:permutation_invertible}{{3.16}{48}{Frequentist random variables and Bayesian forecasts}{equation.3.2.16}{}}
\newlabel{eq:using_pushforward}{{3.17}{48}{Frequentist random variables and Bayesian forecasts}{equation.3.2.17}{}}
\newlabel{eq:closure_under_permutation}{{3.18}{48}{Frequentist random variables and Bayesian forecasts}{equation.3.2.18}{}}
\newlabel{eq:cond_expectation_first}{{3.19}{48}{Frequentist random variables and Bayesian forecasts}{equation.3.2.19}{}}
\newlabel{eq:cond_expectation}{{3.23}{48}{Frequentist random variables and Bayesian forecasts}{equation.3.2.23}{}}
\newlabel{eq:permutation_invertible}{{3.28}{49}{Frequentist random variables and Bayesian forecasts}{equation.3.2.28}{}}
\newlabel{eq:using_pushforward}{{3.29}{49}{Frequentist random variables and Bayesian forecasts}{equation.3.2.29}{}}
\newlabel{eq:closure_under_permutation}{{3.30}{49}{Frequentist random variables and Bayesian forecasts}{equation.3.2.30}{}}
\newlabel{eq:cond_expectation_first}{{3.31}{49}{Frequentist random variables and Bayesian forecasts}{equation.3.2.31}{}}
\newlabel{eq:h_measurable}{{3.41}{50}{Frequentist random variables and Bayesian forecasts}{equation.3.2.41}{}}
\newlabel{th:rep_seedo_obs}{{3.2.9}{51}{Representation of infinitely exchangeably extendable see-do forecasts}{theorem.3.2.9}{}}
\newlabel{lem:f-ex2ex}{{3.2.11}{56}{Functionally exchangeable see-do models with exchangeable choices induce exchangeable see do models}{theorem.3.2.11}{}}
\newlabel{lem:rep_fex_sdf}{{3.2.12}{57}{Representation of functionally exchangeable do forecasts}{theorem.3.2.12}{}}
\@writefile{tdo}{\contentsline {todo}{semigraphoid axioms}{57}{section*.26}\protected@file@percent }
\pgfsyspdfmark {pgfid303}{18318621}{33110377}
\newlabel{th:rep_dex_sdf}{{3.2.13}{57}{Representation of doubly exchangeable see-do forecasts}{theorem.3.2.13}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Statistical Decision Theory}{61}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}A see-do model with a utility is a statistical decision problem}{61}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Decision functions}{61}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Risk}{61}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Reachable consequences}{61}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Decision rules}{61}{subsection.4.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}Comparison of experiments and actuators}{62}{subsection.4.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.6}Equivalence of see-do models}{62}{subsection.4.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Scraps to be moved into skeleton above}{62}{section.4.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Currently a disorganised cut and paste}{62}{section*.27}\protected@file@percent }
\pgfsyspdfmark {pgfid312}{21857565}{27956263}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Decomposability}{62}{subsection.4.2.1}\protected@file@percent }
\newlabel{def:decomposability}{{4.2.1}{62}{decomposability}{theorem.4.2.1}{}}
\newlabel{th:obs_cmaps}{{4.2.2}{62}{Observation and Consequence models}{theorem.4.2.2}{}}
\@writefile{tdo}{\contentsline {todo}{Maybe moves proofs out of main text}{63}{section*.28}\protected@file@percent }
\pgfsyspdfmark {pgfid315}{18318621}{35151535}
\newlabel{corr:decomp_representation}{{4.2.3}{64}{}{theorem.4.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Examples of decomposable and indecomposable see-do models}{64}{section*.29}\protected@file@percent }
\citation{pearl_causality:_2009}
\citation{pearl_book_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Causal questions and decision functions}{65}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Example}{66}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Avoiding indecomposability with decision functions}{66}{section*.31}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Show that a decision problem with a indecomposable model induces an equivalent decision problem with a decomposable model with an expanded set of choices, subject to some conditions.}{66}{section*.32}\protected@file@percent }
\pgfsyspdfmark {pgfid327}{21857565}{24689567}
\@writefile{toc}{\contentsline {subsubsection}{Decision rules}{66}{section*.33}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Define deterministic Markov kernels}{66}{section*.34}\protected@file@percent }
\pgfsyspdfmark {pgfid328}{21857565}{8373618}
\citation{wald_statistical_1950}
\citation{toutenburg_ferguson_1967}
\@writefile{tdo}{\contentsline {todo}{Statistical decision problems usually define the risk via the loss, but it is only possible to define a loss with a decomposable model. We don't actually need a loss, though: the complete class theorem still holds via the induced risk and Bayes risk}{67}{section*.35}\protected@file@percent }
\pgfsyspdfmark {pgfid329}{18318621}{25086393}
\newlabel{def:stat_expt}{{4.2.12}{68}{Statistical Experiment}{theorem.4.2.12}{}}
\citation{loomes_regret_1982}
\newlabel{def:causal_theory}{{4.2.16}{69}{Causal Theory}{theorem.4.2.16}{}}
\newlabel{def:CSDP}{{4.2.17}{69}{Causal Statistical Decision Problem}{theorem.4.2.17}{}}
\newlabel{eq:canonical_loss}{{4.7}{69}{Decision rules}{equation.4.2.7}{}}
\newlabel{th:csdps_are_sdps}{{4.2.18}{70}{CSDPs are a special case of SDPs}{theorem.4.2.18}{}}
\newlabel{def:red_sdp_CSDP}{{4.2.19}{70}{Reduction}{theorem.4.2.19}{}}
\citation{toutenburg_ferguson_1967}
\newlabel{th:csdps_represent_sdps}{{4.2.20}{71}{SDP can be reduced to a CSDP}{theorem.4.2.20}{}}
\newlabel{th:complete_class}{{4.2.21}{71}{Complete class theorem (CSDP)}{theorem.4.2.21}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}See-do models, interventions and counterfactuals}{73}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:4}{{5}{73}{See-do models, interventions and counterfactuals}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}How do see-do models relate to other approaches to causal inference?}{73}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Interpretations of the choice set}{73}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Causal Bayesian Networks as see-do models}{73}{section.5.3}\protected@file@percent }
\citation{rubin_causal_2005}
\citation{pearl_causality:_2009,rubin_causal_2005,richardson2013single}
\citation{pearl_causality:_2009}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Unit Potential Outcomes models}{74}{section.5.4}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{This chapter is currently a disorganised cut and paste}{74}{section*.36}\protected@file@percent }
\pgfsyspdfmark {pgfid330}{21857565}{20684718}
\citation{rubin_causal_2005}
\citation{wald_statistical_1950}
\citation{savage_foundations_1972}
\citation{richardson2013single}
\citation{lattimore_replacing_2019}
\citation{pearl_causality:_2009}
\@writefile{tdo}{\contentsline {todo}{But the proof is still in my notebook}{75}{section*.37}\protected@file@percent }
\pgfsyspdfmark {pgfid331}{18318621}{27715429}
\@writefile{tdo}{\contentsline {todo}{Interestingly, it seems to be possible to construct a see-do model where the ``hypothesis'' is a quantum state, and quantum mechanics + locality seems to rule out parallel choices in such models in a manner similar to Bell's theorem. ``Seems to'' because I haven't actually proven any of these things.}{75}{section*.38}\protected@file@percent }
\pgfsyspdfmark {pgfid332}{18318621}{25331467}
\@writefile{tdo}{\contentsline {todo}{Where to discuss the connections to statistical decision theory?}{75}{section*.39}\protected@file@percent }
\pgfsyspdfmark {pgfid333}{18318621}{20385124}
\citation{wald_statistical_1950,savage_foundations_1972}
\citation{nilsson_evaluating_2013}
\citation{dawid_influence_2002}
\citation{pearl_causality:_2009}
\citation{heckerman_decision-theoretic_1995}
\citation{heckerman_decision-theoretic_1995}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}D-causation}{77}{subsection.5.4.1}\protected@file@percent }
\newlabel{def:d_cause}{{5.4.1}{78}{$D$-causation}{theorem.5.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}D-causation vs Limited Unresponsiveness}{78}{subsection.5.4.2}\protected@file@percent }
\citation{heckerman_decision-theoretic_1995}
\@writefile{tdo}{\contentsline {todo}{define this}{79}{section*.40}\protected@file@percent }
\pgfsyspdfmark {pgfid336}{20222211}{33437434}
\pgfsyspdfmark {pgfid339}{34178333}{33451541}
\pgfsyspdfmark {pgfid340}{38257948}{33225811}
\@writefile{tdo}{\contentsline {todo}{define this}{79}{section*.41}\protected@file@percent }
\pgfsyspdfmark {pgfid345}{20162173}{13622419}
\pgfsyspdfmark {pgfid348}{34178333}{13636526}
\pgfsyspdfmark {pgfid349}{38257948}{13410796}
\newlabel{th:univ_d_causation}{{5.4.4}{80}{Universal $D$-causation}{theorem.5.4.4}{}}
\newlabel{eq:decompose_condi_x}{{5.13}{80}{D-causation vs Limited Unresponsiveness}{equation.5.4.13}{}}
\newlabel{eq:is_conditional}{{5.19}{80}{D-causation vs Limited Unresponsiveness}{equation.5.4.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Properties of D-causation}{81}{subsection.5.4.3}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Pearl's ``front door adjustment'' and general identification results make use of composing ``sub-consequence-kernels'' like this. Show, if possible, that Pearl's ``sub-consequence-kernels'' obey $D$-causation like relations}{81}{section*.42}\protected@file@percent }
\pgfsyspdfmark {pgfid377}{18318621}{16794599}
\@writefile{tdo}{\contentsline {todo}{Does this ``weak D-causation'' respect mixing under the same conditions as regular D-causation?}{81}{section*.43}\protected@file@percent }
\pgfsyspdfmark {pgfid378}{18318621}{14455408}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Decision sequences and parallel decisions}{81}{subsection.5.4.4}\protected@file@percent }
\citation{pearl_causality:_2009}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Existence of counterfactuals}{82}{section.5.5}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{I'm struggling with how to explain this well.}{82}{section*.44}\protected@file@percent }
\pgfsyspdfmark {pgfid379}{21857565}{42043543}
\@writefile{tdo}{\contentsline {todo}{The real solution here is that Pearl's ``variable sets'' are actually ``coupled variables'', see Definition \ref  {def:ctensor}, but I'd rather not change his definitions if I can avoid it}{82}{section*.45}\protected@file@percent }
\pgfsyspdfmark {pgfid380}{21857565}{32977837}
\@writefile{tdo}{\contentsline {todo}{put the following inside a quote environment somehow, the regular quote environment fails due to too much markup}{82}{section*.46}\protected@file@percent }
\pgfsyspdfmark {pgfid381}{21857565}{30730241}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.1 (Causal Model)}{82}{section*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.2 (Submodel)}{82}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.3 (Effect of Action)}{83}{section*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.4 (Potential Response)}{83}{section*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.6 (Probabilistic Causal Model)}{83}{section*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.5 (Counterfactual)}{84}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Imitablity and inferring causes from data}{85}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:6}{{6}{85}{Imitablity and inferring causes from data}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Assumptions enabling learning}{85}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Imitability}{85}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Identification with imitability}{85}{section.6.3}\protected@file@percent }
\citation{peters_causal_2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Causal relationships on God's computer}{87}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:6}{{7}{87}{Causal relationships on God's computer}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Are we trying to understand consequences or actions or objective causal relationships?}{87}{section.7.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Disorganised cut and paste follows}{88}{section*.53}\protected@file@percent }
\pgfsyspdfmark {pgfid382}{21857565}{43419011}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Necessary relationships}{88}{subsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Recursive Structural Causal Models}{89}{subsection.7.1.2}\protected@file@percent }
\newlabel{def:acSCM}{{7.1.1}{89}{Recursive Structural Causal Model}{theorem.7.1.1}{}}
\newlabel{eq:gen_base}{{7.2}{89}{Observable kernel}{equation.7.1.2}{}}
\newlabel{eq:gen_step}{{7.3}{89}{Observable kernel}{equation.7.1.3}{}}
\newlabel{lem:coupled_product_is_ident}{{7.1.4}{90}{Coupled product of all random variables is the identity}{theorem.7.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.3}Recursive Structural Causal Models with Necessary Relationships}{90}{subsection.7.1.3}\protected@file@percent }
\newlabel{def:cscm}{{7.1.6}{90}{Constrained Recursive Structural Causal Model (CSCM)}{theorem.7.1.6}{}}
\@writefile{tdo}{\contentsline {todo}{The following is a generally useful lemma that should probably be in basic definitions of Markov kernel spaces}{91}{section*.54}\protected@file@percent }
\pgfsyspdfmark {pgfid387}{18318621}{23792284}
\newlabel{lem:proj_and_select}{{7.1.8}{91}{Projection and selectors}{theorem.7.1.8}{}}
\newlabel{eq:def_selector}{{7.26}{92}{Recursive Structural Causal Models with Necessary Relationships}{equation.7.1.26}{}}
\newlabel{lem:hard_dont_affect_early}{{7.1.9}{92}{Hard interventions do not affect the joint distributions of earlier variables}{theorem.7.1.9}{}}
\newlabel{eq:prior_g_equal}{{7.29}{93}{Recursive Structural Causal Models with Necessary Relationships}{equation.7.1.29}{}}
\newlabel{eq:equal_across_d}{{7.30}{93}{Recursive Structural Causal Models with Necessary Relationships}{equation.7.1.30}{}}
\newlabel{eq:marginal_kernel}{{7.31}{93}{Recursive Structural Causal Models with Necessary Relationships}{equation.7.1.31}{}}
\citation{bongers_theoretical_2016}
\newlabel{th:recursive_no_interventions}{{7.1.10}{94}{Undefined hard interventions with cyclic constraints}{theorem.7.1.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.4}Cyclic Structural Causal Models}{94}{subsection.7.1.4}\protected@file@percent }
\citation{bongers_theoretical_2016}
\citation{bongers_theoretical_2016}
\citation{bongers_theoretical_2016}
\@writefile{tdo}{\contentsline {todo}{Haven't done any work from here on}{95}{section*.55}\protected@file@percent }
\pgfsyspdfmark {pgfid424}{18318621}{38638525}
\newlabel{def:SCM}{{7.1.11}{95}{Structural Causal Model}{theorem.7.1.11}{}}
\citation{bongers_theoretical_2016}
\citation{hernan_does_2008}
\citation{pearl_does_2018}
\@writefile{tdo}{\contentsline {todo}{Incidentally, this messiness with random variables can be solved if we use See-Do models.}{96}{section*.56}\protected@file@percent }
\pgfsyspdfmark {pgfid425}{29186707}{21961091}
\pgfsyspdfmark {pgfid426}{5997853}{21975198}
\pgfsyspdfmark {pgfid427}{10077468}{21749468}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.5}Not all variables have well-defined interventions}{96}{subsection.7.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Necessary relationships in cyclic SCMs}{97}{section*.57}\protected@file@percent }
\newlabel{th:no_interventions}{{7.1.18}{98}{Interventions and necessary relationships don't mix}{theorem.7.1.18}{}}
\newlabel{eq:necessary_relationship}{{7.54}{99}{Necessary relationships in cyclic SCMs}{equation.7.1.54}{}}
\@writefile{tdo}{\contentsline {todo}{I can formalise the following, but I'm just writing it out so I can get to the end for now}{99}{section*.58}\protected@file@percent }
\pgfsyspdfmark {pgfid437}{18318621}{24217695}
\@writefile{tdo}{\contentsline {todo}{because interventions are defined in uniquely solvable SCMs and derivation preserves interventions on the old variables}{99}{section*.59}\protected@file@percent }
\pgfsyspdfmark {pgfid438}{17241435}{10956096}
\pgfsyspdfmark {pgfid441}{34178333}{10970203}
\pgfsyspdfmark {pgfid442}{38257948}{10744473}
\@writefile{tdo}{\contentsline {todo}{And necessary? There might be ``degenerate'' necessary relationships that don't harm the possibility of defining interventions, and I'd need to show an equivalence to an SCM in this case}{99}{section*.60}\protected@file@percent }
\pgfsyspdfmark {pgfid443}{18318621}{9223765}
\bibstyle{plainnat}
\bibdata{references}
\bibcite{bongers_theoretical_2016}{{1}{2016}{{Bongers et~al.}}{{Bongers, Peters, Schölkopf, and Mooij}}}
\bibcite{cinlar_probability_2011}{{2}{2011}{{\c {C}inlar}}{{}}}
\bibcite{cho_disintegration_2019}{{3}{2019}{{Cho and Jacobs}}{{}}}
\bibcite{clerc_pointless_2017}{{4}{2017}{{Clerc et~al.}}{{Clerc, Dahlqvist, Danos, and Garnier}}}
\bibcite{dawid_influence_2002}{{5}{2002}{{Dawid}}{{}}}
\bibcite{dawid_decision-theoretic_2020}{{6}{2020}{{Dawid}}{{}}}
\bibcite{de_finetti_foresight_1992}{{7}{1992}{{de~Finetti}}{{}}}
\bibcite{toutenburg_ferguson_1967}{{8}{1967}{{Ferguson}}{{}}}
\bibcite{fisher_statistical_1992}{{9}{1992}{{Fisher}}{{}}}
\bibcite{fisher_cancer_1958}{{10}{1958}{{Fisher}}{{}}}
\bibcite{fong_causal_2013}{{11}{2013}{{Fong}}{{}}}
\bibcite{freedman_asymptotic_1963}{{12}{1963}{{Freedman}}{{}}}
\bibcite{heckerman_decision-theoretic_1995}{{13}{1995}{{Heckerman and Shachter}}{{}}}
\bibcite{hernan_does_2008}{{14}{2008}{{Hernán and Taubman}}{{}}}
\bibcite{hajek_interpretations_2019}{{15}{2019}{{Hájek}}{{}}}
\bibcite{krittanawong_association_2020}{{16}{2020}{{Krittanawong et~al.}}{{Krittanawong, Narasimhan, Wang, Hahn, Virk, Farrell, Zhang, and Tang}}}
\bibcite{lattimore_replacing_2019}{{17}{2019}{{Lattimore and Rohde}}{{}}}
\bibcite{le_cam_comparison_1996}{{18}{1996}{{Le~Cam}}{{}}}
\bibcite{nilsson_evaluating_2013}{{19}{2013}{{Nilsson and Lauritzen}}{{}}}
\bibcite{oreskes_merchants_2011}{{20}{2011}{{Oreskes and Conway}}{{}}}
\bibcite{pearl_causality:_2009}{{21}{2009}{{Pearl}}{{}}}
\bibcite{pearl_does_2018}{{22}{2018}{{Pearl}}{{}}}
\bibcite{pearl_book_2018}{{23}{2018}{{Pearl and Mackenzie}}{{}}}
\bibcite{peters_causal_2016}{{24}{2016}{{Peters et~al.}}{{Peters, Bühlmann, and Meinshausen}}}
\bibcite{proctor_history_2012}{{25}{2012}{{Proctor}}{{}}}
\bibcite{richardson2013single}{{26}{2013}{{Richardson and Robins}}{{}}}
\bibcite{rubin_causal_2005}{{27}{2005}{{Rubin}}{{}}}
\bibcite{savage_foundations_1972}{{28}{1972}{{Savage}}{{}}}
\bibcite{selinger_survey_2010}{{29}{2010}{{Selinger}}{{}}}
\bibcite{shpitser_complete_2008}{{30}{2008}{{Shpitser and Pearl}}{{}}}
\bibcite{spirtes_causation_1993}{{31}{2000}{{Spirtes et~al.}}{{Spirtes, Glymour, Scheines, Heckerman, Meek, Cooper, and Richardson}}}
\bibcite{noauthor_cigarettes_nodate}{{32}{2020}{{Statista}}{{}}}
\bibcite{steele_decision_2020}{{33}{2020}{{Steele and Stefánsson}}{{}}}
\bibcite{vapnik_nature_2013}{{34}{2013}{{Vapnik}}{{}}}
\bibcite{wald_statistical_1950}{{35}{1950}{{Wald}}{{}}}
\bibcite{wiblin_why_2016}{{36}{2016}{{Wiblin}}{{}}}
\bibcite{woodward_causation_2016}{{37}{2016}{{Woodward}}{{}}}
\bibcite{world_health_organisation_tobacco_nodate}{{38}{2018}{{World Health Organisation}}{{}}}

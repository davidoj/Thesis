\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\citation{proctor_history_2012}
\citation{oreskes_merchants_2011}
\citation{fisher_cancer_1958}
\citation{world_health_organisation_tobacco_nodate,wiblin_why_2016}
\citation{world_health_organisation_tobacco_nodate}
\citation{noauthor_cigarettes_nodate}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{5}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Theories of causal inference}{5}{section.1.1}\protected@file@percent }
\citation{krittanawong_association_2020}
\citation{pearl_causality:_2009}
\citation{spirtes_causation_1993}
\citation{woodward_causation_2016}
\citation{shpitser_complete_2008}
\citation{pearl_causality:_2009}
\citation{woodward_causation_2016}
\citation{dawid_decision-theoretic_2020}
\@writefile{tdo}{\contentsline {todo}{I want to revisit the claims about what I actually show, hopefully to add to it}{8}{section*.2}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{21536991}{25948842}
\pgfsyspdfmark {pgfid2}{5997853}{25962949}
\pgfsyspdfmark {pgfid3}{10077468}{25737219}
\@writefile{tdo}{\contentsline {todo}{I commented out an additional section about potential outcomes and closest world counterfactuals, which is a second example of ``opaque causal definitions''. I'm interested if any readers think it would be good to have a second example}{8}{section*.3}\protected@file@percent }
\pgfsyspdfmark {pgfid6}{21857565}{11263326}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Technical Prerequisites}{9}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\contentsline {todo}{Todo: conditional expectation, martingale convergence}{9}{section*.4}\protected@file@percent }
\pgfsyspdfmark {pgfid7}{18318621}{31316025}
\@writefile{tdo}{\contentsline {todo}{Almost sure equality convention}{9}{section*.5}\protected@file@percent }
\pgfsyspdfmark {pgfid8}{18318621}{30103500}
\@writefile{tdo}{\contentsline {todo}{Existence of disintegrations for choosing probability measures}{9}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid9}{18318621}{28890974}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.1}Probability Theory}{9}{subsection.2.0.1}\protected@file@percent }
\citation{clerc_pointless_2017}
\@writefile{toc}{\contentsline {paragraph}{Common $\sigma $ algebras}{10}{section*.7}\protected@file@percent }
\citation{cinlar_probability_2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.2}Product Notation}{11}{subsection.2.0.2}\protected@file@percent }
\newlabel{ssec:product_notation}{{2.0.2}{11}{Product Notation}{subsection.2.0.2}{}}
\citation{cho_disintegration_2019}
\citation{selinger_survey_2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.3}String Diagrams}{12}{subsection.2.0.3}\protected@file@percent }
\newlabel{ssec:mken_diagrams}{{2.0.3}{12}{String Diagrams}{subsection.2.0.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Elements of string diagrams}{12}{section*.8}\protected@file@percent }
\newlabel{sec:string_diagram_elements}{{2.0.3}{12}{Elements of string diagrams}{section*.8}{}}
\newlabel{eq:prob_meas_sd}{{2.7}{12}{Elements of string diagrams}{equation.2.0.7}{}}
\citation{cho_disintegration_2019}
\@writefile{toc}{\contentsline {paragraph}{Elementary operations}{13}{section*.9}\protected@file@percent }
\newlabel{eq:sd_composition}{{2.8}{13}{Elementary operations}{equation.2.0.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Markov kernels with special notation}{14}{section*.10}\protected@file@percent }
\newlabel{eq:identity}{{2.17}{14}{Markov kernels with special notation}{equation.2.0.17}{}}
\newlabel{eq:copy}{{2.25}{14}{Markov kernels with special notation}{equation.2.0.25}{}}
\newlabel{eq:swap}{{2.28}{15}{Markov kernels with special notation}{equation.2.0.28}{}}
\newlabel{eq:discard}{{2.34}{15}{Markov kernels with special notation}{equation.2.0.34}{}}
\newlabel{def:functional_kernel}{{2.0.1}{15}{Kernel associated with a function}{theorem.2.0.1}{}}
\newlabel{lem:pushf_funk}{{2.0.3}{15}{Pushforward kernels are functional kernel products}{theorem.2.0.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Working With String Diagrams}{16}{section*.11}\protected@file@percent }
\newlabel{sssec:string_diagram_manipulation}{{2.0.3}{16}{Working With String Diagrams}{section*.11}{}}
\@writefile{toc}{\contentsline {paragraph}{Axioms of Symmetric Monoidal Categories}{16}{section*.12}\protected@file@percent }
\newlabel{eq:ccom1}{{2.39}{16}{Axioms of Symmetric Monoidal Categories}{equation.2.0.39}{}}
\newlabel{eq:ccom2}{{2.40}{16}{Axioms of Symmetric Monoidal Categories}{equation.2.0.40}{}}
\newlabel{eq:ccom3}{{2.41}{16}{Axioms of Symmetric Monoidal Categories}{equation.2.0.41}{}}
\newlabel{eq:termobj1}{{2.42}{16}{Axioms of Symmetric Monoidal Categories}{equation.2.0.42}{}}
\citation{fong_causal_2013}
\newlabel{eq:A_copymap}{{2.46}{17}{Axioms of Symmetric Monoidal Categories}{equation.2.0.46}{}}
\newlabel{eq:copy_commutes}{{2.47}{17}{Axioms of Symmetric Monoidal Categories}{equation.2.0.47}{}}
\citation{cho_disintegration_2019}
\@writefile{toc}{\contentsline {subsubsection}{Examples}{18}{section*.13}\protected@file@percent }
\newlabel{eq:joint_measure}{{2.52}{18}{Examples}{equation.2.0.52}{}}
\newlabel{eq:marginalisation_graph}{{2.61}{18}{Examples}{equation.2.0.61}{}}
\citation{cinlar_probability_2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.4}Random Variables}{19}{subsection.2.0.4}\protected@file@percent }
\newlabel{ssec:random_variables}{{2.0.4}{19}{Random Variables}{subsection.2.0.4}{}}
\newlabel{eq:disint_example}{{2.62}{19}{Random Variables}{equation.2.0.62}{}}
\newlabel{def:kernel_space}{{2.0.6}{20}{Probability space, Markov kernel space}{theorem.2.0.6}{}}
\newlabel{eq:canonical_extension}{{2.64}{20}{Probability space, Markov kernel space}{equation.2.0.64}{}}
\newlabel{def:random_variable}{{2.0.7}{20}{Random variable}{theorem.2.0.7}{}}
\newlabel{def:domain_variable}{{2.0.8}{20}{Domain variable}{theorem.2.0.8}{}}
\newlabel{def:ctensor}{{2.0.9}{20}{Coupled tensor product $\utimes $}{theorem.2.0.9}{}}
\citation{cinlar_probability_2011}
\newlabel{lem:utimes_assoc}{{2.0.10}{21}{$\utimes $ is associative}{theorem.2.0.10}{}}
\newlabel{def:marginal_distribution}{{2.0.11}{21}{Marginal distribution, marginal kernel}{theorem.2.0.11}{}}
\newlabel{def:joint_distribution}{{2.0.12}{21}{Joint distribution, joint kernel}{theorem.2.0.12}{}}
\newlabel{lem:jdist_cprod}{{2.0.13}{21}{Product marginalisation interchange}{theorem.2.0.13}{}}
\newlabel{corr:rewrite_joint_dist}{{2.0.14}{22}{}{theorem.2.0.14}{}}
\newlabel{def:wl_jprob}{{2.0.15}{22}{Wire labels - joint kernels}{theorem.2.0.15}{}}
\newlabel{eq:labels_express_joint}{{2.76}{22}{Wire labels - joint kernels}{equation.2.0.76}{}}
\newlabel{eq:labels_express_marginal_upper}{{2.77}{22}{Wire labels - joint kernels}{equation.2.0.77}{}}
\newlabel{eq:labels_express_marginal_lower}{{2.78}{22}{Wire labels - joint kernels}{equation.2.0.78}{}}
\newlabel{eq:cannot_marginalise}{{2.79}{22}{Wire labels - joint kernels}{equation.2.0.79}{}}
\newlabel{def:disintegration}{{2.0.17}{23}{Disintegration}{theorem.2.0.17}{}}
\newlabel{eq:ordinary_disint}{{2.86}{23}{Disintegration}{equation.2.0.86}{}}
\newlabel{eq:def_k_disint}{{2.87}{24}{Disintegration}{equation.2.0.87}{}}
\newlabel{def:wl_disint}{{2.0.18}{24}{Wire labels -- input}{theorem.2.0.18}{}}
\newlabel{dia:kernel_l}{{2.88}{24}{Wire labels -- input}{equation.2.0.88}{}}
\newlabel{eq:const_from_m}{{2.90}{24}{Wire labels -- input}{equation.2.0.90}{}}
\newlabel{th:iterated_disint}{{2.0.20}{25}{Iterated disintegration}{theorem.2.0.20}{}}
\newlabel{lem:representation_of_kernels}{{2.0.21}{26}{}{theorem.2.0.21}{}}
\citation{cinlar_probability_2011}
\@writefile{toc}{\contentsline {subsubsection}{Existence of Disintegrations}{27}{section*.14}\protected@file@percent }
\newlabel{th:disintegration_exist}{{2.0.22}{27}{Disintegration existence - probability space}{theorem.2.0.22}{}}
\newlabel{eq:non_measurable_disint}{{2.107}{27}{Existence of Disintegrations}{equation.2.0.107}{}}
\citation{pearl_causality:_2009}
\newlabel{eq:cbn_cont2}{{2.112}{29}{Existence of Disintegrations}{equation.2.0.112}{}}
\newlabel{th:existence_continous}{{2.0.24}{29}{Existence of disintegrations on kernel spaces: uniform normalised continuous kernel}{theorem.2.0.24}{}}
\newlabel{eq:agrement_on_jsub}{{2.119}{30}{Existence of Disintegrations}{equation.2.0.119}{}}
\citation{cinlar_probability_2011}
\@writefile{tdo}{\contentsline {todo}{which I'll add here next}{32}{section*.15}\protected@file@percent }
\pgfsyspdfmark {pgfid190}{21857565}{34510987}
\citation{cinlar_probability_2011}
\newlabel{lem:absolute_continuity}{{2.0.26}{33}{}{theorem.2.0.26}{}}
\@writefile{tdo}{\contentsline {todo}{todo}{33}{section*.16}\protected@file@percent }
\pgfsyspdfmark {pgfid191}{18318621}{37513511}
\newlabel{lem:uniform_integrability}{{2.0.27}{33}{}{theorem.2.0.27}{}}
\@writefile{tdo}{\contentsline {todo}{todo; a proof for an analagous fact is given in \cite  {cinlar_probability_2011}}{33}{section*.17}\protected@file@percent }
\pgfsyspdfmark {pgfid192}{18318621}{31019262}
\@writefile{tdo}{\contentsline {todo}{show...}{33}{section*.18}\protected@file@percent }
\pgfsyspdfmark {pgfid193}{18318621}{21379286}
\@writefile{tdo}{\contentsline {todo}{better name}{33}{section*.19}\protected@file@percent }
\pgfsyspdfmark {pgfid194}{18318621}{16689551}
\newlabel{lem:agree_disint}{{2.0.30}{33}{Agreement of disintegrations}{theorem.2.0.30}{}}
\newlabel{eq:prob_disint_in_kernel_disint}{{2.141}{34}{Existence of Disintegrations}{equation.2.0.141}{}}
\@writefile{toc}{\contentsline {subsubsection}{Conditional Independence}{35}{section*.20}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Almost sure equality}{36}{section*.21}\protected@file@percent }
\pgfsyspdfmark {pgfid211}{21857565}{41784253}
\newlabel{th:ci_equivalence}{{2.0.33}{36}{Definitions are equivalent}{theorem.2.0.33}{}}
\newlabel{def:conditional_probability_existence}{{2.0.34}{37}{Conditional probability existence}{theorem.2.0.34}{}}
\newlabel{def:conditional_independence}{{2.0.35}{37}{Conditional Independence}{theorem.2.0.35}{}}
\@writefile{tdo}{\contentsline {todo}{Almost sure equality}{37}{section*.22}\protected@file@percent }
\pgfsyspdfmark {pgfid230}{18318621}{35328690}
\newlabel{eq:splitter_preserves_name}{{2.163}{37}{Diagrammatic consequences of labels}{equation.2.0.163}{}}
\newlabel{eq:composition}{{2.167}{38}{Conditional Independence}{equation.2.0.167}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Two player statistical models and see-do models}{39}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\contentsline {todo}{These are ``todo'' notes. All such notes that involve theoretical development are also collected in an unordered list of outstanding theoretical questions}{39}{section*.23}\protected@file@percent }
\pgfsyspdfmark {pgfid265}{18318621}{29366033}
\citation{fisher_statistical_1992,le_cam_comparison_1996,freedman_asymptotic_1963,de_finetti_foresight_1992,vapnik_nature_2013,wald_statistical_1950}
\citation{steele_decision_2020}
\@writefile{tdo}{\contentsline {todo}{Note to proof readers: I moved the discussion of decomposability to the next chapter so I can introduce it alongside the result that uses it}{41}{section*.24}\protected@file@percent }
\pgfsyspdfmark {pgfid266}{18318621}{34313149}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Two player statistical models and see-do models}{41}{section.3.1}\protected@file@percent }
\newlabel{def:2p_stat}{{3.1.1}{41}{Two player statistical model}{theorem.3.1.1}{}}
\citation{hajek_interpretations_2019}
\newlabel{def:seedo}{{3.1.2}{42}{See-Do model}{theorem.3.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Frequentist random variables and Bayesian forecasts}{42}{section.3.2}\protected@file@percent }
\citation{walley_statistical_1991}
\citation{pearl_causality:_2009}
\citation{walley_statistical_1991}
\citation{de_finetti_foresight_1992}
\newlabel{def:permut_swap}{{3.2.3}{46}{Permutations and swaps}{theorem.3.2.3}{}}
\newlabel{eq:determ_commute}{{3.9}{46}{Frequentist random variables and Bayesian forecasts}{equation.3.2.9}{}}
\newlabel{eq:function_composition}{{3.10}{46}{Frequentist random variables and Bayesian forecasts}{equation.3.2.10}{}}
\@writefile{tdo}{\contentsline {todo}{lemmafy, move to chapter 2}{47}{section*.25}\protected@file@percent }
\pgfsyspdfmark {pgfid277}{18318621}{36084003}
\newlabel{def:partial_freq}{{3.2.4}{47}{Partial frequencies}{theorem.3.2.4}{}}
\newlabel{def:exchange_sig_alb}{{3.2.5}{47}{Exchangeable $\sigma $-algebra}{theorem.3.2.5}{}}
\newlabel{lem:partial_representation}{{3.2.8}{48}{Infinitely exchangeably extendable forecasts}{theorem.3.2.8}{}}
\citation{cinlar_probability_2011}
\newlabel{eq:permutation_invertible}{{3.16}{49}{Frequentist random variables and Bayesian forecasts}{equation.3.2.16}{}}
\newlabel{eq:using_pushforward}{{3.17}{49}{Frequentist random variables and Bayesian forecasts}{equation.3.2.17}{}}
\newlabel{eq:closure_under_permutation}{{3.18}{49}{Frequentist random variables and Bayesian forecasts}{equation.3.2.18}{}}
\newlabel{eq:cond_expectation_first}{{3.19}{49}{Frequentist random variables and Bayesian forecasts}{equation.3.2.19}{}}
\newlabel{eq:cond_expectation}{{3.23}{49}{Frequentist random variables and Bayesian forecasts}{equation.3.2.23}{}}
\newlabel{eq:permutation_invertible}{{3.28}{50}{Frequentist random variables and Bayesian forecasts}{equation.3.2.28}{}}
\newlabel{eq:using_pushforward}{{3.29}{50}{Frequentist random variables and Bayesian forecasts}{equation.3.2.29}{}}
\newlabel{eq:closure_under_permutation}{{3.30}{50}{Frequentist random variables and Bayesian forecasts}{equation.3.2.30}{}}
\newlabel{eq:cond_expectation_first}{{3.31}{50}{Frequentist random variables and Bayesian forecasts}{equation.3.2.31}{}}
\newlabel{eq:h_measurable}{{3.41}{51}{Frequentist random variables and Bayesian forecasts}{equation.3.2.41}{}}
\citation{cinlar_probability_2011}
\newlabel{lem:iid_rvs}{{3.2.9}{52}{Independent and identically distributed random variables}{theorem.3.2.9}{}}
\newlabel{lem:rep_seedo_obs}{{3.2.10}{52}{Representation of infinitely exchangeably extendable see-do forecasts}{theorem.3.2.10}{}}
\citation{de_finetti_foresight_1992,hewitt_symmetric_1955}
\@writefile{tdo}{\contentsline {todo}{Maybe include a diagram here? I think the pictorial representation is quite nice, though it's hard to state as rigorously}{55}{section*.26}\protected@file@percent }
\pgfsyspdfmark {pgfid279}{18318621}{40133638}
\newlabel{lem:f-ex2ex}{{3.2.12}{55}{Functionally exchangeable see-do models with exchangeable choices induce exchangeable see do models}{theorem.3.2.12}{}}
\newlabel{th:rep_dex_sdf}{{3.2.13}{55}{Representation of doubly exchangeable see-do forecasts}{theorem.3.2.13}{}}
\newlabel{eq:fex_copyrep}{{3.78}{58}{Frequentist random variables and Bayesian forecasts}{equation.3.2.78}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Statistical Decision Theory}{63}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}A see-do model with a utility is a statistical decision problem}{63}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Decision functions}{63}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Risk}{63}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Reachable consequences}{63}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Decision rules}{63}{subsection.4.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}Comparison of experiments and actuators}{64}{subsection.4.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.6}Equivalence of see-do models}{64}{subsection.4.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Scraps to be moved into skeleton above}{64}{section.4.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Currently a disorganised cut and paste}{64}{section*.27}\protected@file@percent }
\pgfsyspdfmark {pgfid312}{21857565}{27956263}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Decomposability}{64}{subsection.4.2.1}\protected@file@percent }
\newlabel{def:decomposability}{{4.2.1}{64}{decomposability}{theorem.4.2.1}{}}
\newlabel{th:obs_cmaps}{{4.2.2}{64}{Observation and Consequence models}{theorem.4.2.2}{}}
\@writefile{tdo}{\contentsline {todo}{Maybe moves proofs out of main text}{65}{section*.28}\protected@file@percent }
\pgfsyspdfmark {pgfid315}{18318621}{35151535}
\newlabel{corr:decomp_representation}{{4.2.3}{66}{}{theorem.4.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Examples of decomposable and indecomposable see-do models}{66}{section*.29}\protected@file@percent }
\citation{pearl_causality:_2009}
\citation{pearl_book_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Causal questions and decision functions}{67}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Example}{68}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Avoiding indecomposability with decision functions}{68}{section*.31}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Show that a decision problem with a indecomposable model induces an equivalent decision problem with a decomposable model with an expanded set of choices, subject to some conditions.}{68}{section*.32}\protected@file@percent }
\pgfsyspdfmark {pgfid327}{21857565}{24689567}
\@writefile{toc}{\contentsline {subsubsection}{Decision rules}{68}{section*.33}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Define deterministic Markov kernels}{68}{section*.34}\protected@file@percent }
\pgfsyspdfmark {pgfid328}{21857565}{8373618}
\citation{wald_statistical_1950}
\citation{toutenburg_ferguson_1967}
\@writefile{tdo}{\contentsline {todo}{Statistical decision problems usually define the risk via the loss, but it is only possible to define a loss with a decomposable model. We don't actually need a loss, though: the complete class theorem still holds via the induced risk and Bayes risk}{69}{section*.35}\protected@file@percent }
\pgfsyspdfmark {pgfid329}{18318621}{25086393}
\newlabel{def:stat_expt}{{4.2.12}{70}{Statistical Experiment}{theorem.4.2.12}{}}
\citation{loomes_regret_1982}
\newlabel{def:causal_theory}{{4.2.16}{71}{Causal Theory}{theorem.4.2.16}{}}
\newlabel{def:CSDP}{{4.2.17}{71}{Causal Statistical Decision Problem}{theorem.4.2.17}{}}
\newlabel{eq:canonical_loss}{{4.7}{71}{Decision rules}{equation.4.2.7}{}}
\newlabel{th:csdps_are_sdps}{{4.2.18}{72}{CSDPs are a special case of SDPs}{theorem.4.2.18}{}}
\newlabel{def:red_sdp_CSDP}{{4.2.19}{72}{Reduction}{theorem.4.2.19}{}}
\citation{toutenburg_ferguson_1967}
\newlabel{th:csdps_represent_sdps}{{4.2.20}{73}{SDP can be reduced to a CSDP}{theorem.4.2.20}{}}
\newlabel{th:complete_class}{{4.2.21}{73}{Complete class theorem (CSDP)}{theorem.4.2.21}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}See-do models, interventions and counterfactuals}{75}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:ints_counterfactuals}{{5}{75}{See-do models, interventions and counterfactuals}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}How do see-do models relate to other approaches to causal inference?}{75}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Interpretations of the choice set}{75}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Causal Bayesian Networks as see-do models}{75}{section.5.3}\protected@file@percent }
\citation{rubin_causal_2005}
\citation{pearl_causality:_2009,rubin_causal_2005,richardson2013single}
\citation{pearl_causality:_2009}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Unit Potential Outcomes models}{76}{section.5.4}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{This chapter is currently a disorganised cut and paste}{76}{section*.36}\protected@file@percent }
\pgfsyspdfmark {pgfid330}{21857565}{20684718}
\citation{rubin_causal_2005}
\citation{wald_statistical_1950}
\citation{savage_foundations_1972}
\citation{richardson2013single}
\citation{lattimore_replacing_2019}
\citation{pearl_causality:_2009}
\@writefile{tdo}{\contentsline {todo}{But the proof is still in my notebook}{77}{section*.37}\protected@file@percent }
\pgfsyspdfmark {pgfid331}{18318621}{27715429}
\@writefile{tdo}{\contentsline {todo}{Interestingly, it seems to be possible to construct a see-do model where the ``hypothesis'' is a quantum state, and quantum mechanics + locality seems to rule out parallel choices in such models in a manner similar to Bell's theorem. ``Seems to'' because I haven't actually proven any of these things.}{77}{section*.38}\protected@file@percent }
\pgfsyspdfmark {pgfid332}{18318621}{25331467}
\@writefile{tdo}{\contentsline {todo}{Where to discuss the connections to statistical decision theory?}{77}{section*.39}\protected@file@percent }
\pgfsyspdfmark {pgfid333}{18318621}{20385124}
\citation{wald_statistical_1950,savage_foundations_1972}
\citation{nilsson_evaluating_2013}
\citation{dawid_influence_2002}
\citation{pearl_causality:_2009}
\citation{heckerman_decision-theoretic_1995}
\citation{heckerman_decision-theoretic_1995}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}D-causation}{79}{subsection.5.4.1}\protected@file@percent }
\newlabel{def:d_cause}{{5.4.1}{80}{$D$-causation}{theorem.5.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}D-causation vs Limited Unresponsiveness}{80}{subsection.5.4.2}\protected@file@percent }
\citation{heckerman_decision-theoretic_1995}
\@writefile{tdo}{\contentsline {todo}{define this}{81}{section*.40}\protected@file@percent }
\pgfsyspdfmark {pgfid336}{20222211}{33437434}
\pgfsyspdfmark {pgfid339}{34178333}{33451541}
\pgfsyspdfmark {pgfid340}{38257948}{33225811}
\@writefile{tdo}{\contentsline {todo}{define this}{81}{section*.41}\protected@file@percent }
\pgfsyspdfmark {pgfid345}{20162173}{13622419}
\pgfsyspdfmark {pgfid348}{34178333}{13636526}
\pgfsyspdfmark {pgfid349}{38257948}{13410796}
\newlabel{th:univ_d_causation}{{5.4.4}{82}{Universal $D$-causation}{theorem.5.4.4}{}}
\newlabel{eq:decompose_condi_x}{{5.13}{82}{D-causation vs Limited Unresponsiveness}{equation.5.4.13}{}}
\newlabel{eq:is_conditional}{{5.19}{82}{D-causation vs Limited Unresponsiveness}{equation.5.4.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Properties of D-causation}{83}{subsection.5.4.3}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Pearl's ``front door adjustment'' and general identification results make use of composing ``sub-consequence-kernels'' like this. Show, if possible, that Pearl's ``sub-consequence-kernels'' obey $D$-causation like relations}{83}{section*.42}\protected@file@percent }
\pgfsyspdfmark {pgfid377}{18318621}{16794599}
\@writefile{tdo}{\contentsline {todo}{Does this ``weak D-causation'' respect mixing under the same conditions as regular D-causation?}{83}{section*.43}\protected@file@percent }
\pgfsyspdfmark {pgfid378}{18318621}{14455408}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Decision sequences and parallel decisions}{83}{subsection.5.4.4}\protected@file@percent }
\citation{pearl_causality:_2009}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Existence of counterfactuals}{84}{section.5.5}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{I'm struggling with how to explain this well.}{84}{section*.44}\protected@file@percent }
\pgfsyspdfmark {pgfid379}{21857565}{42043543}
\@writefile{tdo}{\contentsline {todo}{The real solution here is that Pearl's ``variable sets'' are actually ``coupled variables'', see Definition \ref  {def:ctensor}, but I'd rather not change his definitions if I can avoid it}{84}{section*.45}\protected@file@percent }
\pgfsyspdfmark {pgfid380}{21857565}{32977837}
\@writefile{tdo}{\contentsline {todo}{put the following inside a quote environment somehow, the regular quote environment fails due to too much markup}{84}{section*.46}\protected@file@percent }
\pgfsyspdfmark {pgfid381}{21857565}{30730241}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.1 (Causal Model)}{84}{section*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.2 (Submodel)}{84}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.3 (Effect of Action)}{85}{section*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.4 (Potential Response)}{85}{section*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.6 (Probabilistic Causal Model)}{85}{section*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.5 (Counterfactual)}{86}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Imitablity and inferring causes from data}{87}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:6}{{6}{87}{Imitablity and inferring causes from data}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Assumptions enabling learning}{87}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Imitability}{87}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Identification with imitability}{87}{section.6.3}\protected@file@percent }
\citation{peters_causal_2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Causal relationships on God's computer}{89}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:6}{{7}{89}{Causal relationships on God's computer}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Are we trying to understand consequences or actions or objective causal relationships?}{89}{section.7.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Disorganised cut and paste follows}{90}{section*.53}\protected@file@percent }
\pgfsyspdfmark {pgfid382}{21857565}{43419011}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Necessary relationships}{90}{subsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Recursive Structural Causal Models}{91}{subsection.7.1.2}\protected@file@percent }
\newlabel{def:acSCM}{{7.1.1}{91}{Recursive Structural Causal Model}{theorem.7.1.1}{}}
\newlabel{eq:gen_base}{{7.2}{91}{Observable kernel}{equation.7.1.2}{}}
\newlabel{eq:gen_step}{{7.3}{91}{Observable kernel}{equation.7.1.3}{}}
\newlabel{lem:coupled_product_is_ident}{{7.1.4}{92}{Coupled product of all random variables is the identity}{theorem.7.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.3}Recursive Structural Causal Models with Necessary Relationships}{92}{subsection.7.1.3}\protected@file@percent }
\newlabel{def:cscm}{{7.1.6}{92}{Constrained Recursive Structural Causal Model (CSCM)}{theorem.7.1.6}{}}
\@writefile{tdo}{\contentsline {todo}{The following is a generally useful lemma that should probably be in basic definitions of Markov kernel spaces}{93}{section*.54}\protected@file@percent }
\p
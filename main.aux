\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\citation{proctor_history_2012}
\citation{oreskes_merchants_2011}
\citation{fisher_cancer_1958}
\citation{world_health_organisation_tobacco_nodate,wiblin_why_2016}
\citation{world_health_organisation_tobacco_nodate}
\citation{noauthor_cigarettes_nodate}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{5}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Theories of causal inference}{5}{section.1.1}\protected@file@percent }
\citation{krittanawong_association_2020}
\citation{pearl_causality:_2009}
\citation{spirtes_causation_1993}
\citation{woodward_causation_2016}
\citation{shpitser_complete_2008}
\citation{pearl_causality:_2009}
\citation{woodward_causation_2016}
\citation{dawid_decision-theoretic_2020}
\@writefile{tdo}{\contentsline {todo}{I want to revisit the claims about what I actually show, hopefully to add to it}{8}{section*.2}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{21536991}{25948842}
\pgfsyspdfmark {pgfid2}{5997853}{25962949}
\pgfsyspdfmark {pgfid3}{10077468}{25737219}
\@writefile{tdo}{\contentsline {todo}{I commented out an additional section about potential outcomes and closest world counterfactuals, which is a second example of ``opaque causal definitions''. I'm interested if any readers think it would be good to have a second example}{8}{section*.3}\protected@file@percent }
\pgfsyspdfmark {pgfid6}{21857565}{11263326}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Technical Prerequisites}{9}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\contentsline {todo}{Todo: conditional expectation, martingale convergence}{9}{section*.4}\protected@file@percent }
\pgfsyspdfmark {pgfid7}{18318621}{31375502}
\@writefile{tdo}{\contentsline {todo}{Almost sure equality convention}{9}{section*.5}\protected@file@percent }
\pgfsyspdfmark {pgfid8}{18318621}{30182802}
\@writefile{tdo}{\contentsline {todo}{Existence of disintegrations for choosing probability measures}{9}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid9}{18318621}{28990102}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Probability Theory}{9}{section.2.1}\protected@file@percent }
\citation{clerc_pointless_2017}
\@writefile{toc}{\contentsline {paragraph}{Common $\sigma $ algebras}{10}{section*.7}\protected@file@percent }
\citation{cinlar_probability_2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Product Notation}{11}{subsection.2.1.1}\protected@file@percent }
\newlabel{ssec:product_notation}{{2.1.1}{11}{Product Notation}{subsection.2.1.1}{}}
\citation{cho_disintegration_2019}
\citation{selinger_survey_2010}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}String Diagrams}{12}{section.2.2}\protected@file@percent }
\newlabel{ssec:mken_diagrams}{{2.2}{12}{String Diagrams}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Elements of string diagrams}{12}{subsection.2.2.1}\protected@file@percent }
\newlabel{sec:string_diagram_elements}{{2.2.1}{12}{Elements of string diagrams}{subsection.2.2.1}{}}
\newlabel{eq:prob_meas_sd}{{2.7}{12}{Elements of string diagrams}{equation.2.2.7}{}}
\citation{cho_disintegration_2019}
\@writefile{toc}{\contentsline {paragraph}{Elementary operations}{13}{section*.8}\protected@file@percent }
\newlabel{eq:sd_composition}{{2.8}{13}{Elementary operations}{equation.2.2.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Markov kernels with special notation}{14}{section*.9}\protected@file@percent }
\newlabel{eq:identity}{{2.17}{14}{Markov kernels with special notation}{equation.2.2.17}{}}
\newlabel{eq:copy}{{2.25}{14}{Markov kernels with special notation}{equation.2.2.25}{}}
\newlabel{eq:swap}{{2.28}{15}{Markov kernels with special notation}{equation.2.2.28}{}}
\newlabel{eq:discard}{{2.34}{15}{Markov kernels with special notation}{equation.2.2.34}{}}
\newlabel{def:functional_kernel}{{2.2.1}{15}{Kernel associated with a function}{theorem.2.2.1}{}}
\newlabel{lem:pushf_funk}{{2.2.3}{15}{Pushforward kernels are functional kernel products}{theorem.2.2.3}{}}
\newlabel{lem:func_kern_product}{{2.2.4}{16}{Products of functional kernels yield function composition}{theorem.2.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Manipulating String Diagrams}{16}{subsection.2.2.2}\protected@file@percent }
\newlabel{sssec:string_diagram_manipulation}{{2.2.2}{16}{Manipulating String Diagrams}{subsection.2.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Axioms of Symmetric Monoidal Categories}{16}{section*.10}\protected@file@percent }
\newlabel{eq:ccom1}{{2.43}{16}{Axioms of Symmetric Monoidal Categories}{equation.2.2.43}{}}
\newlabel{eq:ccom2}{{2.44}{17}{Axioms of Symmetric Monoidal Categories}{equation.2.2.44}{}}
\newlabel{eq:ccom3}{{2.45}{17}{Axioms of Symmetric Monoidal Categories}{equation.2.2.45}{}}
\newlabel{eq:termobj1}{{2.46}{17}{Axioms of Symmetric Monoidal Categories}{equation.2.2.46}{}}
\newlabel{eq:A_copymap}{{2.50}{17}{Axioms of Symmetric Monoidal Categories}{equation.2.2.50}{}}
\citation{fong_causal_2013}
\citation{cho_disintegration_2019}
\newlabel{eq:copy_commutes}{{2.51}{18}{Axioms of Symmetric Monoidal Categories}{equation.2.2.51}{}}
\@writefile{toc}{\contentsline {subsubsection}{Examples}{18}{section*.11}\protected@file@percent }
\newlabel{eq:joint_measure}{{2.56}{18}{Examples}{equation.2.2.56}{}}
\newlabel{eq:marginalisation_graph}{{2.65}{19}{Examples}{equation.2.2.65}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Random Variables}{19}{subsection.2.2.3}\protected@file@percent }
\newlabel{ssec:random_variables}{{2.2.3}{19}{Random Variables}{subsection.2.2.3}{}}
\newlabel{eq:disint_example}{{2.66}{19}{Random Variables}{equation.2.2.66}{}}
\citation{cinlar_probability_2011}
\newlabel{def:kernel_space}{{2.2.7}{20}{Markov kernel space}{theorem.2.2.7}{}}
\newlabel{def:prob_space}{{2.2.8}{20}{Probability space}{theorem.2.2.8}{}}
\newlabel{def:domain_extension}{{2.2.9}{20}{Domain extension}{theorem.2.2.9}{}}
\newlabel{eq:canonical_extension}{{2.68}{20}{Domain extension}{equation.2.2.68}{}}
\newlabel{def:random_variable}{{2.2.10}{20}{Random variable}{theorem.2.2.10}{}}
\newlabel{def:domain_variable}{{2.2.11}{20}{Domain variable}{theorem.2.2.11}{}}
\newlabel{def:ctensor}{{2.2.12}{20}{Coupled tensor product $\utimes $}{theorem.2.2.12}{}}
\newlabel{lem:utimes_assoc}{{2.2.13}{21}{$\utimes $ is associative}{theorem.2.2.13}{}}
\newlabel{def:vec_notation}{{2.2.14}{21}{Vector notation}{theorem.2.2.14}{}}
\newlabel{def:marginal_distribution}{{2.2.15}{21}{Marginal distribution, marginal kernel}{theorem.2.2.15}{}}
\citation{cinlar_probability_2011}
\newlabel{def:joint_distribution}{{2.2.16}{22}{Joint distribution, joint kernel}{theorem.2.2.16}{}}
\newlabel{lem:jdist_cprod}{{2.2.17}{22}{Product marginalisation interchange}{theorem.2.2.17}{}}
\newlabel{corr:rewrite_joint_dist}{{2.2.18}{22}{}{theorem.2.2.18}{}}
\newlabel{def:wl_jprob}{{2.2.19}{22}{Wire labels - joint kernels}{theorem.2.2.19}{}}
\newlabel{eq:labels_express_joint}{{2.80}{22}{Wire labels - joint kernels}{equation.2.2.80}{}}
\newlabel{eq:labels_express_marginal_upper}{{2.81}{23}{Wire labels - joint kernels}{equation.2.2.81}{}}
\newlabel{eq:labels_express_marginal_lower}{{2.82}{23}{Wire labels - joint kernels}{equation.2.2.82}{}}
\newlabel{eq:cannot_marginalise}{{2.83}{23}{Wire labels - joint kernels}{equation.2.2.83}{}}
\newlabel{def:disintegration}{{2.2.21}{24}{Disintegration}{theorem.2.2.21}{}}
\newlabel{eq:ordinary_disint}{{2.90}{24}{Disintegration}{equation.2.2.90}{}}
\newlabel{eq:def_k_disint}{{2.91}{24}{Disintegration}{equation.2.2.91}{}}
\newlabel{def:wl_disint}{{2.2.22}{24}{Wire labels -- input}{theorem.2.2.22}{}}
\newlabel{dia:kernel_l}{{2.92}{24}{Wire labels -- input}{equation.2.2.92}{}}
\newlabel{eq:const_from_m}{{2.94}{25}{Wire labels -- input}{equation.2.2.94}{}}
\newlabel{th:iterated_disint}{{2.2.24}{25}{Iterated disintegration}{theorem.2.2.24}{}}
\citation{cinlar_probability_2011}
\newlabel{lem:representation_of_kernels}{{2.2.25}{27}{}{theorem.2.2.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Existence of Disintegrations}{27}{subsection.2.2.4}\protected@file@percent }
\newlabel{th:disintegration_exist}{{2.2.26}{27}{Disintegration existence - probability space}{theorem.2.2.26}{}}
\citation{pearl_causality:_2009}
\newlabel{eq:non_measurable_disint}{{2.111}{28}{Existence of Disintegrations}{equation.2.2.111}{}}
\newlabel{eq:cbn_cont2}{{2.116}{29}{Existence of Disintegrations}{equation.2.2.116}{}}
\newlabel{th:existence_continous}{{2.2.28}{30}{Existence of disintegrations on kernel spaces: uniform normalised continuous kernel}{theorem.2.2.28}{}}
\newlabel{eq:agrement_on_jsub}{{2.123}{30}{Existence of Disintegrations}{equation.2.2.123}{}}
\citation{cinlar_probability_2011}
\@writefile{tdo}{\contentsline {todo}{which I'll add here next}{32}{section*.12}\protected@file@percent }
\pgfsyspdfmark {pgfid190}{21857565}{22353465}
\citation{cinlar_probability_2011}
\newlabel{lem:absolute_continuity}{{2.2.30}{33}{}{theorem.2.2.30}{}}
\@writefile{tdo}{\contentsline {todo}{todo}{33}{section*.13}\protected@file@percent }
\pgfsyspdfmark {pgfid191}{18318621}{23870603}
\newlabel{lem:uniform_integrability}{{2.2.31}{33}{}{theorem.2.2.31}{}}
\@writefile{tdo}{\contentsline {todo}{todo; a proof for an analagous fact is given in \cite  {cinlar_probability_2011}}{33}{section*.14}\protected@file@percent }
\pgfsyspdfmark {pgfid192}{18318621}{18130558}
\@writefile{tdo}{\contentsline {todo}{show...}{33}{section*.15}\protected@file@percent }
\pgfsyspdfmark {pgfid193}{18318621}{9244786}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Kernel spaces related to one another}{34}{subsection.2.2.5}\protected@file@percent }
\newlabel{def:left_extension}{{2.2.33}{34}{Left extension}{theorem.2.2.33}{}}
\newlabel{def:left_extension_RVs}{{2.2.34}{34}{Random variables on a left extension}{theorem.2.2.34}{}}
\newlabel{lem:le_pres_disint}{{2.2.35}{34}{Left extension preserves disintegrations}{theorem.2.2.35}{}}
\newlabel{lem:agree_disint}{{2.2.36}{34}{Left extension with a strictly positive kernel yields agreement of disintegrations}{theorem.2.2.36}{}}
\newlabel{corr:disint_space}{{2.2.37}{35}{Disintegration space}{theorem.2.2.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Conditional Independence}{36}{subsection.2.2.6}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Almost sure equality}{36}{section*.16}\protected@file@percent }
\pgfsyspdfmark {pgfid206}{21857565}{29653447}
\newlabel{th:ci_equivalence}{{2.2.40}{36}{Definitions are equivalent}{theorem.2.2.40}{}}
\newlabel{def:conditional_probability_existence}{{2.2.41}{37}{Conditional probability existence}{theorem.2.2.41}{}}
\newlabel{def:conditional_independence}{{2.2.42}{37}{Conditional Independence}{theorem.2.2.42}{}}
\@writefile{tdo}{\contentsline {todo}{Almost sure equality}{37}{section*.17}\protected@file@percent }
\pgfsyspdfmark {pgfid225}{18318621}{22719120}
\newlabel{eq:splitter_preserves_name}{{2.165}{38}{Diagrammatic consequences of labels}{equation.2.2.165}{}}
\newlabel{eq:composition}{{2.169}{38}{Conditional Independence}{equation.2.2.169}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Statistical models with consequences}{39}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:2p_statmodels}{{3}{39}{Statistical models with consequences}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Summary}{39}{section.3.1}\protected@file@percent }
\citation{Goodfellow-et-al-2016,vapnik_nature_2013,bishop_pattern_2006,le_cam_comparison_1996,freedman_asymptotic_1963,wald_statistical_1950,de_finetti_foresight_1992,fisher_statistical_1992}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Modelling observations, choices and consequences}{40}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Modelling observations with statistical models}{40}{subsection.3.2.1}\protected@file@percent }
\newlabel{def:statistical model}{{3.2.1}{40}{Statistical model}{theorem.3.2.1}{}}
\newlabel{def:state_outcome}{{3.2.2}{40}{State and outcome variables}{theorem.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Modelling choices and consequences with two-player statistical models}{41}{subsection.3.2.2}\protected@file@percent }
\newlabel{def:2p_stat}{{3.2.3}{42}{Two player statistical model}{theorem.3.2.3}{}}
\newlabel{def:seedo}{{3.2.4}{42}{See-Do model}{theorem.3.2.4}{}}
\newlabel{eq:see_do_independence_requirement}{{3.1}{42}{See-Do model}{equation.3.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Repeatable experiments and actions}{43}{section.3.3}\protected@file@percent }
\newlabel{sec:repeatable_experiments}{{3.3}{43}{Repeatable experiments and actions}{section.3.3}{}}
\newlabel{def:ciid_cifi}{{3.3.1}{44}{Conditionally independent and functionally identical}{theorem.3.3.1}{}}
\citation{hajek_interpretations_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Justifications for ``independent and identically distributed'' type assumptions}{45}{subsection.3.3.1}\protected@file@percent }
\citation{pearl_causality:_2009}
\citation{walley_statistical_1991}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}A representation theorem for see-do models}{47}{subsection.3.3.2}\protected@file@percent }
\newlabel{def:permutation}{{3.3.2}{47}{Permutations}{theorem.3.3.2}{}}
\newlabel{def:swap}{{3.3.3}{48}{Swap function}{theorem.3.3.3}{}}
\newlabel{eq:determ_commute}{{3.4}{48}{A representation theorem for see-do models}{equation.3.3.4}{}}
\newlabel{eq:function_composition}{{3.5}{48}{A representation theorem for see-do models}{equation.3.3.5}{}}
\newlabel{def:exchangeability}{{3.3.4}{48}{Exchangeability}{theorem.3.3.4}{}}
\citation{de_finetti_foresight_1992,hewitt_symmetric_1955}
\citation{de_finetti_foresight_1992}
\newlabel{th:de_finetti_rep_thm}{{3.3.6}{49}{Representation}{theorem.3.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{See-do models with priors}{50}{section*.18}\protected@file@percent }
\newlabel{def:do_forecast}{{3.3.7}{50}{Forecasts, see-do forecast}{theorem.3.3.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{Functional exchangeability}{51}{section*.19}\protected@file@percent }
\citation{diaconis_finite_1980,kerns_definettis_2006}
\newlabel{lem:f-ex2ex}{{3.3.11}{52}{Functionally exchangeable see-do models with exchangeable choices induce exchangeable probability distributions}{theorem.3.3.11}{}}
\newlabel{def:extension}{{3.3.12}{52}{Extension}{theorem.3.3.12}{}}
\newlabel{th:rep_dex_sdf}{{3.3.13}{52}{Representation of doubly exchangeable see-do forecasts}{theorem.3.3.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{Proof of Theorem \ref  {th:de_finetti_rep_thm}}{53}{section*.20}\protected@file@percent }
\newlabel{sec:de_finetti_rep_thm}{{3.3.2}{53}{Proof of Theorem \ref {th:de_finetti_rep_thm}}{section*.20}{}}
\newlabel{def:partial_freq}{{3.3.14}{53}{Partial relative frequencies}{theorem.3.3.14}{}}
\newlabel{def:exchange_sig_alb}{{3.3.15}{53}{Exchangeable $\sigma $-algebra}{theorem.3.3.15}{}}
\citation{cinlar_probability_2011}
\newlabel{eq:permutation_invertible}{{3.30}{55}{Proof of Theorem \ref {th:de_finetti_rep_thm}}{equation.3.3.30}{}}
\newlabel{eq:using_push2}{{3.31}{55}{Proof of Theorem \ref {th:de_finetti_rep_thm}}{equation.3.3.31}{}}
\newlabel{eq:closure_under_permutation}{{3.32}{55}{Proof of Theorem \ref {th:de_finetti_rep_thm}}{equation.3.3.32}{}}
\newlabel{eq:cond_expectation_first}{{3.33}{55}{Proof of Theorem \ref {th:de_finetti_rep_thm}}{equation.3.3.33}{}}
\newlabel{eq:cond_expectation}{{3.37}{55}{Proof of Theorem \ref {th:de_finetti_rep_thm}}{equation.3.3.37}{}}
\newlabel{eq:using_pushforward}{{3.43}{56}{Proof of Theorem \ref {th:de_finetti_rep_thm}}{equation.3.3.43}{}}
\newlabel{eq:closure_under_permutation2}{{3.44}{56}{Proof of Theorem \ref {th:de_finetti_rep_thm}}{equation.3.3.44}{}}
\newlabel{eq:cond_expectation_first2}{{3.45}{56}{Proof of Theorem \ref {th:de_finetti_rep_thm}}{equation.3.3.45}{}}
\newlabel{eq:h_measurable}{{3.55}{57}{Proof of Theorem \ref {th:de_finetti_rep_thm}}{equation.3.3.55}{}}
\@writefile{toc}{\contentsline {subsubsection}{Proof of Theorem \ref  {th:rep_dex_sdf}}{58}{section*.21}\protected@file@percent }
\newlabel{sec:rep_dex_sdf}{{3.3.2}{58}{Proof of Theorem \ref {th:rep_dex_sdf}}{section*.21}{}}
\newlabel{lem:rep_seedo_obs}{{3.3.17}{58}{Representation of infinitely exchangeably extendable see-do forecasts}{theorem.3.3.17}{}}
\newlabel{eq:IID}{{3.84}{63}{Proof of Theorem \ref {th:rep_dex_sdf}}{equation.3.3.84}{}}
\newlabel{eq:IFI}{{3.85}{63}{Proof of Theorem \ref {th:rep_dex_sdf}}{equation.3.3.85}{}}
\citation{jacobs_causal_2019}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Statistical Decision Theory}{65}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:evaluating_decisions}{{4}{65}{Statistical Decision Theory}{chapter.4}{}}
\@writefile{tdo}{\contentsline {todo}{I think I've got a good idea for a result that is relevant to the discussion below}{65}{section*.22}\protected@file@percent }
\pgfsyspdfmark {pgfid287}{18318621}{31229724}
\@writefile{tdo}{\contentsline {todo}{End of the sketch of the result}{66}{section*.23}\protected@file@percent }
\pgfsyspdfmark {pgfid288}{21857565}{25168137}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Representing prior knowledge in decision problems}{66}{section.4.1}\protected@file@percent }
\citation{wald_statistical_1950}
\citation{vapnik_nature_2013}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}How should knowledge be represented in decision problems?}{67}{subsection.4.1.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{sort this out, obviously}{67}{section*.24}\protected@file@percent }
\pgfsyspdfmark {pgfid289}{23297544}{15444082}
\pgfsyspdfmark {pgfid292}{34178333}{15458189}
\pgfsyspdfmark {pgfid293}{38257948}{15232459}
\citation{von_neumann_theory_1944}
\citation{steele_decision_2020}
\@writefile{toc}{\contentsline {subsubsection}{von Neumann-Morgenstern utility}{68}{section*.25}\protected@file@percent }
\citation{savage_foundations_1954}
\citation{jeffrey_logic_1990}
\citation{bolker_functions_1966}
\citation{bolker_functions_1966}
\@writefile{tdo}{\contentsline {todo}{Is this worth stating as a theorem?}{69}{section*.26}\protected@file@percent }
\pgfsyspdfmark {pgfid294}{18318621}{39285545}
\@writefile{toc}{\contentsline {subsubsection}{Savage's decision theory}{69}{section*.27}\protected@file@percent }
\newlabel{eq:savage_utility}{{4.1}{69}{Savage's decision theory}{equation.4.1.1}{}}
\newlabel{eq:savage_utility2}{{4.3}{69}{Savage's decision theory}{equation.4.1.3}{}}
\@writefile{tdo}{\contentsline {todo}{Is this worth stating as a theorem?}{69}{section*.28}\protected@file@percent }
\pgfsyspdfmark {pgfid295}{18318621}{8437333}
\@writefile{toc}{\contentsline {subsubsection}{Jeffrey's decision theory}{70}{section*.29}\protected@file@percent }
\newlabel{eq:ev_dec_theory}{{4.4}{70}{Jeffrey's decision theory}{equation.4.1.4}{}}
\citation{wald_statistical_1950}
\@writefile{tdo}{\contentsline {todo}{Which has only just occurred to me}{71}{section*.30}\protected@file@percent }
\pgfsyspdfmark {pgfid296}{18318621}{17041505}
\@writefile{toc}{\contentsline {subsubsection}{Causal decision theory}{71}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Decision functions}{72}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Risk}{72}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Reachable consequences}{72}{subsection.4.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}Decision rules}{72}{subsection.4.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.6}Comparison of experiments and actuators}{72}{subsection.4.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.7}Equivalence of see-do models}{72}{subsection.4.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Scraps to be moved into skeleton above}{73}{section.4.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Currently a disorganised cut and paste}{73}{section*.32}\protected@file@percent }
\pgfsyspdfmark {pgfid297}{18318621}{41748543}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Decomposability}{73}{subsection.4.2.1}\protected@file@percent }
\newlabel{def:decomposability}{{4.2.1}{73}{decomposability}{theorem.4.2.1}{}}
\newlabel{th:obs_cmaps}{{4.2.2}{73}{Observation and Consequence models}{theorem.4.2.2}{}}
\@writefile{tdo}{\contentsline {todo}{Maybe moves proofs out of main text}{73}{section*.33}\protected@file@percent }
\pgfsyspdfmark {pgfid300}{18318621}{10314297}
\newlabel{corr:decomp_representation}{{4.2.3}{74}{}{theorem.4.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Examples of decomposable and indecomposable see-do models}{74}{section*.34}\protected@file@percent }
\citation{pearl_causality:_2009}
\citation{pearl_book_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Causal questions and decision functions}{76}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Example}{76}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Avoiding indecomposability with decision functions}{77}{section*.36}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Show that a decision problem with a indecomposable model induces an equivalent decision problem with a decomposable model with an expanded set of choices, subject to some conditions.}{77}{section*.37}\protected@file@percent }
\pgfsyspdfmark {pgfid312}{18318621}{31030493}
\@writefile{toc}{\contentsline {subsubsection}{Decision rules}{77}{section*.38}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Define deterministic Markov kernels}{77}{section*.39}\protected@file@percent }
\pgfsyspdfmark {pgfid313}{18318621}{14222396}
\citation{wald_statistical_1950}
\citation{toutenburg_ferguson_1967}
\@writefile{tdo}{\contentsline {todo}{Statistical decision problems usually define the risk via the loss, but it is only possible to define a loss with a decomposable model. We don't actually need a loss, though: the complete class theorem still holds via the induced risk and Bayes risk}{78}{section*.40}\protected@file@percent }
\pgfsyspdfmark {pgfid314}{21857565}{31356296}
\newlabel{def:stat_expt}{{4.2.12}{79}{Statistical Experiment}{theorem.4.2.12}{}}
\citation{loomes_regret_1982}
\newlabel{def:causal_theory}{{4.2.16}{80}{Causal Theory}{theorem.4.2.16}{}}
\newlabel{def:CSDP}{{4.2.17}{80}{Causal Statistical Decision Problem}{theorem.4.2.17}{}}
\newlabel{eq:canonical_loss}{{4.11}{80}{Decision rules}{equation.4.2.11}{}}
\newlabel{th:csdps_are_sdps}{{4.2.18}{81}{CSDPs are a special case of SDPs}{theorem.4.2.18}{}}
\newlabel{def:red_sdp_CSDP}{{4.2.19}{81}{Reduction}{theorem.4.2.19}{}}
\newlabel{th:csdps_represent_sdps}{{4.2.20}{81}{SDP can be reduced to a CSDP}{theorem.4.2.20}{}}
\citation{toutenburg_ferguson_1967}
\newlabel{th:complete_class}{{4.2.21}{82}{Complete class theorem (CSDP)}{theorem.4.2.21}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}See-do models, interventions and counterfactuals}{83}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:ints_counterfactuals}{{5}{83}{See-do models, interventions and counterfactuals}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}How do see-do models relate to other approaches to causal inference?}{83}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Interpretations of the choice set}{83}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Causal Bayesian Networks as see-do models}{83}{section.5.3}\protected@file@percent }
\citation{rubin_causal_2005}
\citation{pearl_causality:_2009,rubin_causal_2005,richardson2013single}
\citation{pearl_causality:_2009}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Unit Potential Outcomes models}{84}{section.5.4}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{This chapter is currently a disorganised cut and paste}{84}{section*.41}\protected@file@percent }
\pgfsyspdfmark {pgfid315}{21857565}{20684718}
\citation{rubin_causal_2005}
\citation{wald_statistical_1950}
\citation{savage_foundations_1954}
\citation{richardson2013single}
\citation{lattimore_replacing_2019}
\citation{pearl_causality:_2009}
\@writefile{tdo}{\contentsline {todo}{But the proof is still in my notebook}{85}{section*.42}\protected@file@percent }
\pgfsyspdfmark {pgfid316}{18318621}{27715429}
\@writefile{tdo}{\contentsline {todo}{Interestingly, it seems to be possible to construct a see-do model where the ``hypothesis'' is a quantum state, and quantum mechanics + locality seems to rule out parallel choices in such models in a manner similar to Bell's theorem. ``Seems to'' because I haven't actually proven any of these things.}{85}{section*.43}\protected@file@percent }
\pgfsyspdfmark {pgfid317}{18318621}{25331467}
\@writefile{tdo}{\contentsline {todo}{Where to discuss the connections to statistical decision theory?}{85}{section*.44}\protected@file@percent }
\pgfsyspdfmark {pgfid318}{18318621}{20385124}
\citation{wald_statistical_1950,savage_foundations_1972}
\citation{nilsson_evaluating_2013}
\citation{dawid_influence_2002}
\citation{pearl_causality:_2009}
\citation{heckerman_decision-theoretic_1995}
\citation{heckerman_decision-theoretic_1995}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}D-causation}{87}{subsection.5.4.1}\protected@file@percent }
\newlabel{def:d_cause}{{5.4.1}{88}{$D$-causation}{theorem.5.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}D-causation vs Limited Unresponsiveness}{88}{subsection.5.4.2}\protected@file@percent }
\citation{heckerman_decision-theoretic_1995}
\@writefile{tdo}{\contentsline {todo}{define this}{89}{section*.45}\protected@file@percent }
\pgfsyspdfmark {pgfid321}{20222211}{33437434}
\pgfsyspdfmark {pgfid324}{34178333}{33451541}
\pgfsyspdfmark {pgfid325}{38257948}{33225811}
\@writefile{tdo}{\contentsline {todo}{define this}{89}{section*.46}\protected@file@percent }
\pgfsyspdfmark {pgfid330}{20162173}{13622419}
\pgfsyspdfmark {pgfid333}{34178333}{13636526}
\pgfsyspdfmark {pgfid334}{38257948}{13410796}
\newlabel{th:univ_d_causation}{{5.4.4}{90}{Universal $D$-causation}{theorem.5.4.4}{}}
\newlabel{eq:decompose_condi_x}{{5.13}{90}{D-causation vs Limited Unresponsiveness}{equation.5.4.13}{}}
\newlabel{eq:is_conditional}{{5.19}{90}{D-causation vs Limited Unresponsiveness}{equation.5.4.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Properties of D-causation}{91}{subsection.5.4.3}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Pearl's ``front door adjustment'' and general identification results make use of composing ``sub-consequence-kernels'' like this. Show, if possible, that Pearl's ``sub-consequence-kernels'' obey $D$-causation like relations}{91}{section*.47}\protected@file@percent }
\pgfsyspdfmark {pgfid362}{18318621}{16794599}
\@writefile{tdo}{\contentsline {todo}{Does this ``weak D-causation'' respect mixing under the same conditions as regular D-causation?}{91}{section*.48}\protected@file@percent }
\pgfsyspdfmark {pgfid363}{18318621}{14455408}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Decision sequences and parallel decisions}{91}{subsection.5.4.4}\protected@file@percent }
\citation{pearl_causality:_2009}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Existence of counterfactuals}{92}{section.5.5}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{I'm struggling with how to explain this well.}{92}{section*.49}\protected@file@percent }
\pgfsyspdfmark {pgfid364}{21857565}{42043543}
\@writefile{tdo}{\contentsline {todo}{The real solution here is that Pearl's ``variable sets'' are actually ``coupled variables'', see Definition \ref  {def:ctensor}, but I'd rather not change his definitions if I can avoid it}{92}{section*.50}\protected@file@percent }
\pgfsyspdfmark {pgfid365}{21857565}{32977837}
\@writefile{tdo}{\contentsline {todo}{put the following inside a quote environment somehow, the regular quote environment fails due to too much markup}{92}{section*.51}\protected@file@percent }
\pgfsyspdfmark {pgfid366}{21857565}{30730241}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.1 (Causal Model)}{92}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.2 (Submodel)}{92}{section*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.3 (Effect of Action)}{93}{section*.54}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.4 (Potential Response)}{93}{section*.55}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.6 (Probabilistic Causal Model)}{93}{section*.56}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1.5 (Counterfactual)}{94}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Imitablity and inferring causes from data}{95}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:inferring_causes}{{6}{95}{Imitablity and inferring causes from data}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Does the decision set matter?}{95}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Imitability}{96}{subsection.6.1.1}\protected@file@percent }
\newlabel{lem:first_observation}{{6.1.2}{96}{Imitability is equivalent to imitability of first observation}{theorem.6.1.2}{}}
\citation{peters_causal_2016}
\@writefile{tdo}{\contentsline {todo}{To be continued}{97}{section*.58}\protected@file@percent }
\pgfsyspdfmark {pgfid372}{18318621}{9160050}
\citation{peters_causal_2016}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Assumptions enabling learning}{98}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Imitability}{98}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Identification with imitability}{98}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Causal relationships on God's computer}{99}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:6}{{7}{99}{Causal relationships on God's computer}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Are we trying to understand consequences or actions or objective causal relationships?}{99}{section.7.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Disorganised cut and paste follows}{100}{section*.59}\protected@file@percent }
\pgfsyspdfmark {pgfid373}{21857565}{43419011}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Necessary relationships}{100}{subsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Recursive Structural Causal Models}{101}{subsection.7.1.2}\protected@file@percent }
\newlabel{def:acSCM}{{7.1.1}{101}{Recursive Structural Causal Model}{theorem.7.1.1}{}}
\newlabel{eq:gen_base}{{7.2}{101}{Observable kernel}{equation.7.1.2}{}}
\newlabel{eq:gen_step}{{7.3}{101}{Observable kernel}{equation.7.1.3}{}}
\newlabel{lem:coupled_product_is_ident}{{7.1.4}{102}{Coupled product of all random variables is the identity}{theorem.7.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.3}Recursive Structural Causal Models with Necessary Relationships}{102}{subsection.7.1.3}\protected@file@percent }
\newlabel{def:cscm}{{7.1.6}{102}{Constrained Recursive Structural Causal Model (CSCM)}{theorem.7.1.6}{}}
\@writefile{tdo}{\contentsline {todo}{The following is a generally useful lemma that should probably be in basic definitions of Markov kernel spaces}{103}{section*.60}\protected@file@percent }
\pgfsyspdfmark {pgfid378}{18318621}{23792284}
\newlabel{lem:proj_and_select}{{7.1.8}{103}{Projection and selectors}{theorem.7.1.8}{}}
\newlabel{eq:def_selector}{{7.26}{104}{Recursive Structural Causal Models with Necessary Relationships}{equation.7.1.26}{}}
\newlabel{lem:hard_dont_affect_early}{{7.1.9}{104}{Hard interventions do not affect the joint distributions of earlier variables}{theorem.7.1.9}{}}
\newlabel{eq:prior_g_equal}{{7.29}{105}{Recursive Structural Causal Models with Necessary Relationships}{equation.7.1.29}{}}
\newlabel{eq:equal_across_d}{{7.30}{105}{Recursive Structural Causal Models with Necessary Relationships}{equation.7.1.30}{}}
\newlabel{eq:marginal_kernel}{{7.31}{105}{Recursive Structural Causal Models with Necessary Relationships}{equation.7.1.31}{}}
\citation{bongers_theoretical_2016}
\newlabel{th:recursive_no_interventions}{{7.1.10}{106}{Undefined hard interventions with cyclic constraints}{theorem.7.1.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.4}Cyclic Structural Causal Models}{106}{subsection.7.1.4}\protected@file@percent }
\citation{bongers_theoretical_2016}
\citation{bongers_theoretical_2016}
\citation{bongers_theoretical_2016}
\@writefile{tdo}{\contentsline {todo}{Haven't done any work from here on}{107}{section*.61}\protected@file@percent }
\pgfsyspdfmark {pgfid415}{18318621}{38638525}
\newlabel{def:SCM}{{7.1.11}{107}{Structural Causal Model}{theorem.7.1.11}{}}
\citation{bongers_theoretical_2016}
\citation{hernan_does_2008}
\citation{pearl_does_2018}
\@writefile{tdo}{\contentsline {todo}{Incidentally, this messiness with random variables can be solved if we use See-Do models.}{108}{section*.62}\protected@file@percent }
\pgfsyspdfmark {pgfid416}{29186707}{21961091}
\pgfsyspdfmark {pgfid417}{5997853}{21975198}
\pgfsyspdfmark {pgfid418}{10077468}{21749468}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.5}Not all variables have well-defined interventions}{108}{subsection.7.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Necessary relationships in cyclic SCMs}{109}{section*.63}\protected@file@percent }
\newlabel{th:no_interventions}{{7.1.18}{110}{Interventions and necessary relationships don't mix}{theorem.7.1.18}{}}
\newlabel{eq:necessary_relationship}{{7.54}{111}{Necessary relationships in cyclic SCMs}{equation.7.1.54}{}}
\@writefile{tdo}{\contentsline {todo}{I can formalise the following, but I'm just writing it out so I can get to the end for now}{111}{section*.64}\protected@file@percent }
\pgfsyspdfmark {pgfid428}{18318621}{24217695}
\@writefile{tdo}{\contentsline {todo}{because interventions are defined in uniquely solvable SCMs and derivation preserves interventions on the old variables}{111}{section*.65}\protected@file@percent }
\pgfsyspdfmark {pgfid429}{17241435}{10956096}
\pgfsyspdfmark {pgfid432}{34178333}{10970203}
\pgfsyspdfmark {pgfid433}{38257948}{10744473}
\@writefile{tdo}{\contentsline {todo}{And necessary? There might be ``degenerate'' necessary relationships that don't harm the possibility of defining interventions, and I'd need to show an equivalence to an SCM in this case}{111}{section*.66}\protected@file@percent }
\pgfsyspdfmark {pgfid434}{18318621}{9223765}
\bibstyle{plainnat}
\bibdata{references}
\bibcite{bishop_pattern_2006}{{1}{2006}{{Bishop}}{{}}}
\bibcite{bolker_functions_1966}{{2}{1966}{{Bolker}}{{}}}
\bibcite{bongers_theoretical_2016}{{3}{2016}{{Bongers et~al.}}{{Bongers, Peters, Schölkopf, and Mooij}}}
\bibcite{cinlar_probability_2011}{{4}{2011}{{\c {C}inlar}}{{}}}
\bibcite{cho_disintegration_2019}{{5}{2019}{{Cho and Jacobs}}{{}}}
\bibcite{clerc_pointless_2017}{{6}{2017}{{Clerc et~al.}}{{Clerc, Dahlqvist, Danos, and Garnier}}}
\bibcite{dawid_influence_2002}{{7}{2002}{{Dawid}}{{}}}
\bibcite{dawid_decision-theoretic_2020}{{8}{2020}{{Dawid}}{{}}}
\bibcite{de_finetti_foresight_1992}{{9}{[1937] 1992}{{de~Finetti}}{{}}}
\bibcite{diaconis_finite_1980}{{10}{1980}{{Diaconis and Freedman}}{{}}}
\bibcite{toutenburg_ferguson_1967}{{11}{1967}{{Ferguson}}{{}}}
\bibcite{fisher_statistical_1992}{{12}{[1925] 1992}{{Fisher}}{{}}}
\bibcite{fisher_cancer_1958}{{13}{1958}{{Fisher}}{{}}}
\bibcite{fong_causal_2013}{{14}{2013}{{Fong}}{{}}}
\bibcite{freedman_asymptotic_1963}{{15}{1963}{{Freedman}}{{}}}
\bibcite{Goodfellow-et-al-2016}{{16}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio, and Courville}}}
\bibcite{heckerman_decision-theoretic_1995}{{17}{1995}{{Heckerman and Shachter}}{{}}}
\bibcite{hernan_does_2008}{{18}{2008}{{Hernán and Taubman}}{{}}}
\bibcite{hewitt_symmetric_1955}{{19}{1955}{{Hewitt and Savage}}{{}}}
\bibcite{hajek_interpretations_2019}{{20}{2019}{{Hájek}}{{}}}
\bibcite{jacobs_causal_2019}{{21}{2019}{{Jacobs et~al.}}{{Jacobs, Kissinger, and Zanasi}}}
\bibcite{jeffrey_logic_1990}{{22}{1965}{{Jeffrey}}{{}}}
\bibcite{kerns_definettis_2006}{{23}{2006}{{Kerns and Székely}}{{}}}
\bibcite{krittanawong_association_2020}{{24}{2020}{{Krittanawong et~al.}}{{Krittanawong, Narasimhan, Wang, Hahn, Virk, Farrell, Zhang, and Tang}}}
\bibcite{lattimore_replacing_2019}{{25}{2019}{{Lattimore and Rohde}}{{}}}
\bibcite{le_cam_comparison_1996}{{26}{1996}{{Le~Cam}}{{}}}
\bibcite{loomes_regret_1982}{{27}{1982}{{Loomes and Sugden}}{{}}}
\bibcite{nilsson_evaluating_2013}{{28}{2013}{{Nilsson and Lauritzen}}{{}}}
\bibcite{oreskes_merchants_2011}{{29}{2011}{{Oreskes and Conway}}{{}}}
\bibcite{pearl_causality:_2009}{{30}{2009}{{Pearl}}{{}}}
\bibcite{pearl_does_2018}{{31}{2018}{{Pearl}}{{}}}
\bibcite{pearl_book_2018}{{32}{2018}{{Pearl and Mackenzie}}{{}}}
\bibcite{peters_causal_2016}{{33}{2016}{{Peters et~al.}}{{Peters, Bühlmann, and Meinshausen}}}
\bibcite{proctor_history_2012}{{34}{2012}{{Proctor}}{{}}}
\bibcite{richardson2013single}{{35}{2013}{{Richardson and Robins}}{{}}}
\bibcite{rubin_causal_2005}{{36}{2005}{{Rubin}}{{}}}
\bibcite{savage_foundations_1954}{{37}{1954}{{Savage}}{{}}}
\bibcite{selinger_survey_2010}{{38}{2010}{{Selinger}}{{}}}
\bibcite{shpitser_complete_2008}{{39}{2008}{{Shpitser and Pearl}}{{}}}
\bibcite{spirtes_causation_1993}{{40}{2000}{{Spirtes et~al.}}{{Spirtes, Glymour, Scheines, Heckerman, Meek, Cooper, and Richardson}}}
\bibcite{noauthor_cigarettes_nodate}{{41}{2020}{{Statista}}{{}}}
\bibcite{steele_decision_2020}{{42}{2020}{{Steele and Stefánsson}}{{}}}
\bibcite{vapnik_nature_2013}{{43}{2013}{{Vapnik}}{{}}}
\bibcite{von_neumann_theory_1944}{{44}{1944}{{Von~Neumann and Morgenstern}}{{}}}
\bibcite{wald_statistical_1950}{{45}{1950}{{Wald}}{{}}}
\bibcite{walley_statistical_1991}{{46}{1991}{{Walley}}{{}}}
\bibcite{wiblin_why_2016}{{47}{2016}{{Wiblin}}{{}}}
\bibcite{woodward_causation_2016}{{48}{2016}{{Woodward}}{{}}}
\bibcite{world_health_organisation_tobacco_nodate}{{49}{2018}{{World Health Organisation}}{{}}}
